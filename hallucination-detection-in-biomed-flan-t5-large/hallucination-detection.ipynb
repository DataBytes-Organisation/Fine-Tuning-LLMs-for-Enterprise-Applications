{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557e8dba-7be5-45ab-b90b-b615eb27b431",
   "metadata": {},
   "source": [
    "# Hallucination detection progress using Flan-T5-Large\n",
    "### Student Name:\n",
    "Samin Adhikari\n",
    "\n",
    "### Student ID:\n",
    "223606554\n",
    "\n",
    "### Traget Score:\n",
    "Credit\n",
    "\n",
    "### What's in this file.\n",
    "- Progress upto benchmarking of normal vs parameterized model.\n",
    "- Uses Hugging Face model downloaded using token and run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a527219d-add3-4633-892c-c5375d86078d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /opt/anaconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-score in /opt/anaconda3/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (2.6.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (4.51.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (4.66.5)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (2.2.2)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (4.66.5)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=45680515c9d304beae616e4714261c35a468699c53960167922b5989d781fc1a\n",
      "  Stored in directory: /Users/rvlife-samin/Library/Caches/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "# Install deps\n",
    "!pip install transformers torch\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install absl-py\n",
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e1612d9-a82d-4eb0-8ab8-36ff2332abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the modules used for the project\n",
    "import transformers\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import evaluate\n",
    "from huggingface_hub import login\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress logging\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78e1af16-903b-44f3-b7af-f13e8aefe0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face token config\n",
    "token = \"<placeholder>\"\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fff9ec16-eced-44ed-817b-6294b0a1e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model - default is google's flan-t5-large\n",
    "def load_model_and_tokenizer(model_name=\"google/flan-t5-large\"):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Default model used throuhout\n",
    "def get_default_model_tokenizer():\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Model with no specific hyperparameter\n",
    "def generate_response(model, tokenizer, input_text, max_length=50):    \n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "      inputs[\"input_ids\"],\n",
    "      max_length=max_length\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Some parameter tuning along with prompt addition\n",
    "def generate_parameterized_response(model, tokenizer, input_text, max_length=100, temperature=0.3):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "      Answer the following medical question using evidence-based clinical guidelines from trusted sources like PubMed, FDA, ACOG, WHO, etc. Provide relevant recommendations from these sources and explain the reasoning behind the answer. Include any conditions, risks, or precautions, and clearly state if further consultation is needed. If no evidence is available, explain the limitations of the available data.\n",
    "\n",
    "      Question: {input_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "      inputs[\"input_ids\"],\n",
    "      max_length=max_length,\n",
    "      temperature=temperature,\n",
    "      do_sample=True, # Disables randomness for more reliable outputs\n",
    "      num_beams=5, # Increases search space for high-quality answers\n",
    "      repetition_penalty=1.2,  # Reduces hallucination by discouraging word overuse\n",
    "      length_penalty=1.0,  # Maintains natural sentence flow\n",
    "      early_stopping=True,  # Stops generation when an answer is complete\n",
    "      num_return_sequences=1  # Returns only the best response\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bdf7eca8-aa57-4342-8993-e3f732759c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Benchmarching\n",
    "# Load all required Hugging Face metrics\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "def evaluate_metrics(predictions, references):\n",
    "    # BLEU expects references as list of list of tokens\n",
    "    bleu_result = bleu_metric.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "    meteor_result = meteor_metric.compute(predictions=predictions, references=references)\n",
    "    rouge_result = rouge_metric.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "    bert_result = bertscore_metric.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu_result[\"bleu\"],\n",
    "        \"METEOR\": meteor_result[\"meteor\"],\n",
    "        \"ROUGE-1\": rouge_result[\"rouge1\"],\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
    "        \"BERTScore-F1\": sum(bert_result[\"f1\"]) / len(bert_result[\"f1\"]),\n",
    "    }\n",
    "\n",
    "def benchmark_model(generate_func, model, tokenizer, data):\n",
    "    predictions, references = [], []\n",
    "\n",
    "    for qa in tqdm(data):\n",
    "        question = qa[\"question\"]\n",
    "        reference = qa[\"answer\"]\n",
    "        generated = generate_func(model, tokenizer, question)\n",
    "        predictions.append(generated)\n",
    "        references.append(reference)\n",
    "\n",
    "    return evaluate_metrics(predictions, references)\n",
    "\n",
    "def load_benchmark_data(path=\"data/question.json\", limit=50):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3bcd2f5-518c-45b0-9a85-9b76b05c6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option:\n",
      "1: Load default model\n",
      "2: Benchmark default and parameterized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to your choice:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading data...\n",
      "\n",
      "[1] Benchmarking default model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:48<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Results:\n",
      "BLEU: 0.0038\n",
      "METEOR: 0.0577\n",
      "ROUGE-1: 0.1205\n",
      "ROUGE-L: 0.1086\n",
      "BERTScore-F1: 0.8448\n",
      "\n",
      "[2] Benchmarking parameterized model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [08:45<00:00, 10.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameterized Results:\n",
      "BLEU: 0.0512\n",
      "METEOR: 0.2239\n",
      "ROUGE-1: 0.2532\n",
      "ROUGE-L: 0.1998\n",
      "BERTScore-F1: 0.8727\n",
      "\n",
      "--- COMPARISON ---\n",
      "BLEU: Δ 0.0475 (Improvement: Yes)\n",
      "METEOR: Δ 0.1662 (Improvement: Yes)\n",
      "ROUGE-1: Δ 0.1326 (Improvement: Yes)\n",
      "ROUGE-L: Δ 0.0912 (Improvement: Yes)\n",
      "BERTScore-F1: Δ 0.0279 (Improvement: Yes)\n"
     ]
    }
   ],
   "source": [
    "# Main execution step for the application\n",
    "\n",
    "# Starts default unparameterized model\n",
    "def start_default_qa_system():\n",
    "    model, tokenizer = get_default_model_tokenizer()\n",
    "    print(\"Welcome to the Medical QA system. Ask your medical question (or type 'exit' to quit).\")\n",
    "    \n",
    "    while True:\n",
    "        # Ask the user for a question\n",
    "        input_text = input(\"Please enter your medical question: \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if input_text.lower() == \"exit\":\n",
    "            print(\"Exiting the Medical QA system. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Generate and display the answer\n",
    "        response = generate_response(model, tokenizer, input_text)\n",
    "        print(\"\\nAnswer:\", response)\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "# Starts benchmarking of default vs parameterized model\n",
    "def start_benchmark_system():\n",
    "    print(\"Loading model...\")\n",
    "    model, tokenizer = get_default_model_tokenizer()\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    data = load_benchmark_data()\n",
    "\n",
    "    print(\"\\n[1] Benchmarking default model...\")\n",
    "    default_results = benchmark_model(generate_response, model, tokenizer, data)\n",
    "    print(\"\\nDefault Results:\")\n",
    "    for k, v in default_results.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\n[2] Benchmarking parameterized model...\")\n",
    "    param_results = benchmark_model(generate_parameterized_response, model, tokenizer, data)\n",
    "    print(\"\\nParameterized Results:\")\n",
    "    for k, v in param_results.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\n--- COMPARISON ---\")\n",
    "    for metric in default_results:\n",
    "        diff = param_results[metric] - default_results[metric]\n",
    "        print(f\"{metric}: Δ {diff:.4f} (Improvement: {'Yes' if diff > 0 else 'No'})\")\n",
    "\n",
    "# Main Call\n",
    "print(\"Choose an option:\")\n",
    "print(\"1: Load default model\")\n",
    "print(\"2: Benchmark default and parameterized model\")\n",
    "choice = input(\"Enter the number corresponding to your choice: \")\n",
    "\n",
    "if choice == '1':\n",
    "    start_default_qa_system()\n",
    "elif choice == '2':\n",
    "    start_benchmark_system()\n",
    "else:\n",
    "    print(\"Invalid choice! Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6138a-126b-4cc9-9413-73985b9a136c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
