{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557e8dba-7be5-45ab-b90b-b615eb27b431",
   "metadata": {},
   "source": [
    "# Hallucination detection progress using Flan-T5-Large\n",
    "### Student Name:\n",
    "Samin Adhikari\n",
    "\n",
    "### Student ID:\n",
    "223606554\n",
    "\n",
    "### Traget Score:\n",
    "Credit\n",
    "\n",
    "### What's in this file.\n",
    "- Progress upto benchmarking of normal vs parameterized model.\n",
    "- Uses Hugging Face model downloaded using token and run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a527219d-add3-4633-892c-c5375d86078d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: bert-score in /opt/anaconda3/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (2.6.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (4.51.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (4.66.5)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert-score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: rouge-score in /opt/anaconda3/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (2.2.2)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge-score) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "# Install deps\n",
    "!pip install transformers torch\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install absl-py\n",
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e1612d9-a82d-4eb0-8ab8-36ff2332abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the modules used for the project\n",
    "import transformers\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import evaluate\n",
    "from huggingface_hub import login\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress logging\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78e1af16-903b-44f3-b7af-f13e8aefe0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face token config\n",
    "token = \"\"\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fff9ec16-eced-44ed-817b-6294b0a1e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model - default is google's flan-t5-large\n",
    "def load_model_and_tokenizer(model_name=\"google/flan-t5-large\"):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Default model used throuhout\n",
    "def get_default_model_tokenizer():\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Model with no specific hyperparameter\n",
    "def generate_response(model, tokenizer, input_text, max_length=50):   \n",
    "    # prompt = f\"Please explain this: {input_text}\"\n",
    "    # inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "      inputs[\"input_ids\"],\n",
    "      max_length=max_length\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Some parameter tuning along with prompt addition\n",
    "def generate_parameterized_response(model, tokenizer, input_text, max_length=100, temperature=0.3):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "      Answer the following medical question using evidence-based clinical guidelines from trusted sources like PubMed, FDA, ACOG, WHO, etc. Provide relevant recommendations from these sources and explain the reasoning behind the answer. Include any conditions, risks, or precautions, and clearly state if further consultation is needed. If no evidence is available, explain the limitations of the available data.\n",
    "\n",
    "      Question: {input_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "      inputs[\"input_ids\"],\n",
    "      max_length=max_length,\n",
    "      temperature=temperature,\n",
    "      do_sample=True, # Disables randomness for more reliable outputs\n",
    "      num_beams=5, # Increases search space for high-quality answers\n",
    "      repetition_penalty=1.2,  # Reduces hallucination by discouraging word overuse\n",
    "      length_penalty=1.0,  # Maintains natural sentence flow\n",
    "      early_stopping=True,  # Stops generation when an answer is complete\n",
    "      num_return_sequences=1  # Returns only the best response\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf7eca8-aa57-4342-8993-e3f732759c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Benchmarching\n",
    "# Load all required Hugging Face metrics\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "def evaluate_metrics(predictions, references):\n",
    "    # BLEU expects references as list of list of tokens\n",
    "    bleu_result = bleu_metric.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "    meteor_result = meteor_metric.compute(predictions=predictions, references=references)\n",
    "    rouge_result = rouge_metric.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "    bert_result = bertscore_metric.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu_result[\"bleu\"],\n",
    "        \"METEOR\": meteor_result[\"meteor\"],\n",
    "        \"ROUGE-1\": rouge_result[\"rouge1\"],\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
    "        \"BERTScore-F1\": sum(bert_result[\"f1\"]) / len(bert_result[\"f1\"]),\n",
    "    }\n",
    "\n",
    "def benchmark_model(generate_func, model, tokenizer, data):\n",
    "    predictions, references = [], []\n",
    "\n",
    "    for qa in tqdm(data):\n",
    "        question = qa[\"question\"]\n",
    "        reference = qa[\"answer\"]\n",
    "        generated = generate_func(model, tokenizer, question)\n",
    "        predictions.append(generated)\n",
    "        references.append(reference)\n",
    "\n",
    "    return evaluate_metrics(predictions, references)\n",
    "\n",
    "def load_benchmark_data(path=\"data/question.json\", limit=50):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3bcd2f5-518c-45b0-9a85-9b76b05c6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option:\n",
      "1: Load default model\n",
      "2: Benchmark default and parameterized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to your choice:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading data...\n",
      "\n",
      "[1] Benchmarking default model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:48<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Results:\n",
      "BLEU: 0.0038\n",
      "METEOR: 0.0577\n",
      "ROUGE-1: 0.1205\n",
      "ROUGE-L: 0.1086\n",
      "BERTScore-F1: 0.8448\n",
      "\n",
      "[2] Benchmarking parameterized model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [08:45<00:00, 10.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameterized Results:\n",
      "BLEU: 0.0512\n",
      "METEOR: 0.2239\n",
      "ROUGE-1: 0.2532\n",
      "ROUGE-L: 0.1998\n",
      "BERTScore-F1: 0.8727\n",
      "\n",
      "--- COMPARISON ---\n",
      "BLEU: Δ 0.0475 (Improvement: Yes)\n",
      "METEOR: Δ 0.1662 (Improvement: Yes)\n",
      "ROUGE-1: Δ 0.1326 (Improvement: Yes)\n",
      "ROUGE-L: Δ 0.0912 (Improvement: Yes)\n",
      "BERTScore-F1: Δ 0.0279 (Improvement: Yes)\n"
     ]
    }
   ],
   "source": [
    "# Main execution step for the application\n",
    "\n",
    "# Starts default unparameterized model\n",
    "def start_default_qa_system():\n",
    "    model, tokenizer = get_default_model_tokenizer()\n",
    "    print(\"Welcome to the Medical QA system. Ask your medical question (or type 'exit' to quit).\")\n",
    "    \n",
    "    while True:\n",
    "        # Ask the user for a question\n",
    "        input_text = input(\"Please enter your medical question: \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if input_text.lower() == \"exit\":\n",
    "            print(\"Exiting the Medical QA system. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Generate and display the answer\n",
    "        response = generate_response(model, tokenizer, input_text)\n",
    "        print(\"\\nAnswer:\", response)\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "# Starts benchmarking of default vs parameterized model\n",
    "def start_benchmark_system():\n",
    "    print(\"Loading model...\")\n",
    "    model, tokenizer = get_default_model_tokenizer()\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    data = load_benchmark_data()\n",
    "\n",
    "    print(\"\\n[1] Benchmarking default model...\")\n",
    "    default_results = benchmark_model(generate_response, model, tokenizer, data)\n",
    "    print(\"\\nDefault Results:\")\n",
    "    for k, v in default_results.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\n[2] Benchmarking parameterized model...\")\n",
    "    param_results = benchmark_model(generate_parameterized_response, model, tokenizer, data)\n",
    "    print(\"\\nParameterized Results:\")\n",
    "    for k, v in param_results.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\n--- COMPARISON ---\")\n",
    "    for metric in default_results:\n",
    "        diff = param_results[metric] - default_results[metric]\n",
    "        print(f\"{metric}: Δ {diff:.4f} (Improvement: {'Yes' if diff > 0 else 'No'})\")\n",
    "\n",
    "# Main Call\n",
    "print(\"Choose an option:\")\n",
    "print(\"1: Load default model\")\n",
    "print(\"2: Benchmark default and parameterized model\")\n",
    "choice = input(\"Enter the number corresponding to your choice: \")\n",
    "\n",
    "if choice == '1':\n",
    "    start_default_qa_system()\n",
    "elif choice == '2':\n",
    "    start_benchmark_system()\n",
    "else:\n",
    "    print(\"Invalid choice! Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2f36c5-4e6e-4a6a-bb18-bde745adb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: peft in /opt/anaconda3/lib/python3.12/site-packages (0.15.2)\n",
      "Requirement already satisfied: bitsandbytes in /opt/anaconda3/lib/python3.12/site-packages (0.42.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Additional package install for next training\n",
    "!pip install transformers torch datasets accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f9d9d0d-54b5-456c-a687-19833c251279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.9.2\n",
      "Uninstalling keras-3.9.2:\n",
      "  Successfully uninstalled keras-3.9.2\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-cpu==2.16.1 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-cpu==2.16.1\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting tf-keras==2.16.0\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n"
     ]
    }
   ],
   "source": [
    "# Fix issue with tensorflow module import\n",
    "!pip uninstall keras -y\n",
    "!pip install tensorflow-cpu==2.16.1\n",
    "!pip install tf-keras==2.16.0 --no-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b59f16f-ee09-4108-83b7-03c18cbef20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable Tensorflow completely\n",
    "# os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "# os.environ[\"USE_TF\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54643ab4-939b-40c1-97d2-2cad217060bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lora and SFT training imports\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6f3cfe8-b2da-45e4-89a6-bd250b388414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40\n",
      "Test size: 10\n"
     ]
    }
   ],
   "source": [
    "# Get random data by default for initial testing with 20% training set\n",
    "def load_random_benchmark_data(path=\"data/question.json\", limit=50):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    limited_data = data[:limit]\n",
    "\n",
    "    split_point = int(0.2 * limit)\n",
    "    test_data = limited_data[:split_point]\n",
    "    train_data = limited_data[split_point:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Load 5 random QnA pairs\n",
    "train_data, test_data = load_random_benchmark_data(limit=50)\n",
    "print(\"Train size:\", len(train_data))  # 20\n",
    "print(\"Test size:\", len(test_data)) # 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22bd84bb-893c-419e-ab4a-709d64e9e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14,155,776 || all params: 797,305,856 || trainable%: 1.7755\n"
     ]
    }
   ],
   "source": [
    "# Load FLAN-T5-Large\n",
    "model_name = \"google/flan-t5-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.float32)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # Increased rank for richer adaptations\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\", \"k\", \"dense_h_to_4h\"],  # Additional attention heads and FFN layers\n",
    "    lora_dropout=0.1,  # Slightly higher dropout to prevent overfitting\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3ef03e5-c644-486c-af5d-33fb61388939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d30e08fa564fd4bb094250d98c1290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wrap into HuggingFace Dataset\n",
    "dataset = Dataset.from_list(train_data)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(example):\n",
    "    prompt = example['question']\n",
    "    target = example['answer']\n",
    "\n",
    "    inputs = tokenizer(prompt, padding=\"max_length\", truncation=True, max_length=100)\n",
    "    targets = tokenizer(target, padding=\"max_length\", truncation=True, max_length=100)\n",
    "\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d84b91f1-b536-431a-8d04-748e6ab01613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/t_4gf1354nd55y_07y5sc_ch0000gn/T/ipykernel_10278/1671258669.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 03:37, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=5.913037719726563, metrics={'train_runtime': 218.2729, 'train_samples_per_second': 3.665, 'train_steps_per_second': 1.833, 'total_flos': 366914764800000.0, 'train_loss': 5.913037719726563, 'epoch': 20.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=20,\n",
    "    learning_rate=1e-4,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    # fp16=False,  # Disable fp16 to reduce calculation time or due to computation limit\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87f0c707-132e-44f8-9b5a-c18d3eb1689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./lora_finetuned/tokenizer_config.json',\n",
       " './lora_finetuned/special_tokens_map.json',\n",
       " './lora_finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained and finetuned data\n",
    "model.save_pretrained(\"./lora_finetuned\")\n",
    "tokenizer.save_pretrained(\"./lora_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "705c8cf0-3577-4b38-8f40-9023ced6d3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default model: google/flan-t5-large\n",
      "\n",
      "=== Example 1 ===\n",
      "Question      : What are good dietary sources of iron?\n",
      "True Answer   : Good sources include red meat, poultry, lentils, beans, leafy green vegetables, and iron-fortified cereals.\n",
      "Default Model Answer : iron-rich foods\n",
      "Model Answer  : Nutritional iron supplements include iron supplements, iron supplements, and iron supplements.\n",
      "========================================\n",
      "\n",
      "=== Example 2 ===\n",
      "Question      : What are signs that you should see a doctor for stomach pain?\n",
      "True Answer   : Signs include severe pain, pain that lasts several days, accompanying fever, difficulty breathing, vomiting, and signs of dehydration.\n",
      "Default Model Answer : If you have a sour taste in your mouth, a burning sensation in your stomach, or a burning sensation in your intestines\n",
      "Model Answer  : symptoms of GERD include abdominal pain, abdominal tenderness, and abdominal tenderness.\n",
      "========================================\n",
      "\n",
      "=== Example 3 ===\n",
      "Question      : How do you safely dispose of expired medications in Australia?\n",
      "True Answer   : Expired medications can be returned to any pharmacy for safe disposal under the 'Return Unwanted Medicines' program in Australia.\n",
      "Default Model Answer : You can dispose of expired medications in a landfill.\n",
      "Model Answer  : Recycling expired medications is a good practice.\n",
      "========================================\n",
      "\n",
      "=== Example 4 ===\n",
      "Question      : How can you manage lower cholesterol without medication?\n",
      "True Answer   : Managing cholesterol without medication can involve dietary changes like increasing fiber and reducing fats, regular physical activity, and smoking cessation.\n",
      "Default Model Answer : You can reduce your cholesterol by eating a diet of fruits and vegetables.\n",
      "Model Answer  : Healthy lifestyle changes can help lower cholesterol naturally.\n",
      "========================================\n",
      "\n",
      "=== Example 5 ===\n",
      "Question      : What home remedies are effective for relieving headaches?\n",
      "True Answer   : Effective remedies include hydration, rest, applying a cold or warm compress to the head, and practicing stress-reduction techniques such as meditation or gentle stretching.\n",
      "Default Model Answer : Drinking a cup of hot water and a cup of lemon juice can help with headaches.\n",
      "Model Answer  : Yoga, meditation, and relaxation techniques can all help ease headaches.\n",
      "========================================\n",
      "\n",
      "=== Example 6 ===\n",
      "Question      : What drugs are prescribed for treating ADHD in adults?\n",
      "True Answer   : Medications prescribed for ADHD in adults include stimulants such as Adderall and Ritalin, as well as non-stimulant options like Strattera and Guanfacine.\n",
      "Default Model Answer : amitriptyline\n",
      "Model Answer  : ADHD medications include stimulants, anticonvulsants, and antipsychotics.\n",
      "========================================\n",
      "\n",
      "=== Example 7 ===\n",
      "Question      : What should you do if you experience side effects from a medication in Australia?\n",
      "True Answer   : Report any side effects to your healthcare provider and the Therapeutic Goods Administration (TGA) through their adverse event reporting system.\n",
      "Default Model Answer : You should contact your doctor.\n",
      "Model Answer  : Avoid taking the medication for a long period of time.\n",
      "========================================\n",
      "\n",
      "=== Example 8 ===\n",
      "Question      : What drugs are used to treat bipolar disorder?\n",
      "True Answer   : Drugs used to treat bipolar disorder include mood stabilizers like lithium and valproate, antipsychotics, and, occasionally, antidepressants.\n",
      "Default Model Answer : benzodiazepines\n",
      "Model Answer  : Drugs used to treat bipolar disorder include antidepressants, antipsychotics, antidepressants, anti-depressants, anti-anxiety medications, anti-depressants, anti-anxiety medications, anti-depressants, anti-anxiety medications, anti-anxiety medications, anti-anxiety medications, anti-anxiety medications, anti-anxiety medications, anti-anxiety medications, anti\n",
      "========================================\n",
      "\n",
      "=== Example 9 ===\n",
      "Question      : How can regular exercise benefit mental health?\n",
      "True Answer   : Regular exercise can reduce symptoms of depression and anxiety, help manage stress, enhance mood, improve self-esteem, and increase brain sensitivity for serotonin and norepinephrine.\n",
      "Default Model Answer : reducing stress\n",
      "Model Answer  : Exercise can help with mood swings, anxiety, and depression. Regular exercise can also help with sleep disturbances, anxiety, and depression. Regular exercise can also help with cardiovascular disease, such as heart disease, diabetes, and cancer. Regular exercise can also help with the symptoms of depression, anxiety, and addiction disorders. Regular exercise can also help with the symptoms of diabetes, cardiovascular disease, and addiction disorders. Regular exercise can also help with the symptoms of diabetes, cardiovascular disease, and addiction disorders\n",
      "========================================\n",
      "\n",
      "=== Example 10 ===\n",
      "Question      : What should you know about antibiotic use in Australia?\n",
      "True Answer   : Antibiotics should only be used as prescribed by a healthcare provider to combat antibiotic resistance. They are not effective against viral infections like the common cold or flu.\n",
      "Default Model Answer : Antibiotics are used to treat bacterial infections.\n",
      "Model Answer  : Pharmaceutical companies are required to disclose the use of antibiotics in their products and services.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# 1. Load your fine-tuned model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./lora_finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./lora_finetuned\")\n",
    "\n",
    "# 2. Create a text2text-generation pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=100)\n",
    "# pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "recheck_train = train_data[:10]\n",
    "\n",
    "# 5. Also check answer with default uuparameterized model\n",
    "default_model, default_tokenizer = get_default_model_tokenizer()\n",
    "\n",
    "# 6. Test and print each question, true answer, and model answer\n",
    "for i, example in enumerate(recheck_train):\n",
    "    question = example[\"question\"]\n",
    "    true_answer = example[\"answer\"]\n",
    "    \n",
    "    retrained_model_output = pipe(question)[0]['generated_text']\n",
    "    # model_output = pipe(question, max_new_tokens=50)[0]['generated_text']\n",
    "    default_model_output = generate_response(default_model, default_tokenizer, question, device)\n",
    "    \n",
    "    print(f\"\\n=== Example {i+1} ===\")\n",
    "    print(f\"Question      : {question}\")\n",
    "    print(f\"True Answer   : {true_answer}\")\n",
    "    print(f\"Default Model Answer : {default_model_output}\")\n",
    "    print(f\"Model Answer  : {retrained_model_output}\")\n",
    "    print(\"=\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc657edd-cf7b-4021-a397-197e02e3134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading default model: google/flan-t5-large\n",
      "\n",
      "Benchmarking default model on recheck_train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU...\n",
      "Calculating METEOR...\n",
      "Calculating ROUGE...\n",
      "Calculating BERTScore...\n",
      "\n",
      "Benchmarking retrained model on recheck_train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU...\n",
      "Calculating METEOR...\n",
      "Calculating ROUGE...\n",
      "Calculating BERTScore...\n",
      "\n",
      "--- RECHECK_TRAIN COMPARISON ---\n",
      "BLEU: Default Model - 0.0000, Retrained Model - 0.0631, Δ +0.0631 (Improvement: Yes)\n",
      "METEOR: Default Model - 0.0618, Retrained Model - 0.2043, Δ +0.1425 (Improvement: Yes)\n",
      "ROUGE-1: Default Model - 0.1113, Retrained Model - 0.2174, Δ +0.1061 (Improvement: Yes)\n",
      "ROUGE-L: Default Model - 0.0929, Retrained Model - 0.1689, Δ +0.0760 (Improvement: Yes)\n",
      "BERTScore-F1: Default Model - 0.8509, Retrained Model - 0.8664, Δ +0.0155 (Improvement: Yes)\n",
      "\n",
      "Benchmarking default model on test_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU...\n",
      "Calculating METEOR...\n",
      "Calculating ROUGE...\n",
      "Calculating BERTScore...\n",
      "\n",
      "Benchmarking retrained model on test_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rvlife-\n",
      "[nltk_data]     samin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU...\n",
      "Calculating METEOR...\n",
      "Calculating ROUGE...\n",
      "Calculating BERTScore...\n",
      "\n",
      "--- TEST_DATA COMPARISON ---\n",
      "BLEU: Default Model - 0.0000, Retrained Model - 0.0524, Δ +0.0524 (Improvement: Yes)\n",
      "METEOR: Default Model - 0.0579, Retrained Model - 0.2235, Δ +0.1656 (Improvement: Yes)\n",
      "ROUGE-1: Default Model - 0.1100, Retrained Model - 0.2104, Δ +0.1004 (Improvement: Yes)\n",
      "ROUGE-L: Default Model - 0.0924, Retrained Model - 0.1695, Δ +0.0771 (Improvement: Yes)\n",
      "BERTScore-F1: Default Model - 0.8489, Retrained Model - 0.8612, Δ +0.0123 (Improvement: Yes)\n",
      "\n",
      "Benchmarking finished.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Added: Device detection ---\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# --- End Added ---\n",
    "\n",
    "# 1. Load the fine-tuned model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./lora_finetuned\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./lora_finetuned\")\n",
    "\n",
    "# 2. Create a text2text-generation pipeline for retrained model (Optional, not used in benchmarking loop below)\n",
    "# If you wanted to use the pipeline, you'd specify the device here too:\n",
    "# pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=100, device=device)\n",
    "\n",
    "# 3. Benchmarking function using evaluate\n",
    "def benchmark_model(model_to_bench, tokenizer_to_use, dataset): # Renamed args for clarity\n",
    "    # Initialize the evaluate library metrics\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    meteor = evaluate.load(\"meteor\")\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    # Ensure bertscore uses the correct device if available\n",
    "    bertscore = evaluate.load(\"bertscore\") # Removed device=device, let bertscore handle internal device logic or defaults\n",
    "\n",
    "    predictions = []\n",
    "    true_answers = []\n",
    "\n",
    "    # Ensure model is in evaluation mode and on the correct device\n",
    "    model_to_bench.eval()\n",
    "    model_to_bench.to(device) # Ensure it's on the correct device within the function scope too\n",
    "\n",
    "    # Disable gradient calculation for efficiency during inference\n",
    "    with torch.no_grad():\n",
    "        for example in dataset:\n",
    "            question = example[\"question\"]\n",
    "            true_answer = example[\"answer\"]\n",
    "\n",
    "            # Generate output from the model\n",
    "            # Pass the device to the generation function\n",
    "            model_output = generate_response(model_to_bench, tokenizer_to_use, question, device)\n",
    "\n",
    "            predictions.append(model_output)\n",
    "            true_answers.append(true_answer)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    # Note: Some metrics might be slow on MPS, run on CPU if needed by moving tensors back\n",
    "    # However, let's try default first. If bertscore specifically fails/is slow, adjust it.\n",
    "    print(\"Calculating BLEU...\")\n",
    "    bleu_result = bleu.compute(predictions=predictions, references=[[ans] for ans in true_answers])\n",
    "    print(\"Calculating METEOR...\")\n",
    "    meteor_result = meteor.compute(predictions=predictions, references=true_answers)\n",
    "    print(\"Calculating ROUGE...\")\n",
    "    rouge_result = rouge.compute(predictions=predictions, references=[[ans] for ans in true_answers])\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    # BERTScore might need explicit CPU usage if MPS causes issues\n",
    "    try:\n",
    "        bertscore_result = bertscore.compute(predictions=predictions, references=true_answers, lang='en', device=device)\n",
    "        bertscore_f1_mean = torch.mean(torch.tensor(bertscore_result[\"f1\"])).item()\n",
    "    except Exception as e:\n",
    "        print(f\"BERTScore failed on {device}, attempting CPU: {e}\")\n",
    "        # If bertscore fails on MPS/GPU, try running it on CPU\n",
    "        bertscore_result = bertscore.compute(predictions=predictions, references=true_answers, lang='en', device='cpu') # Force CPU\n",
    "        bertscore_f1_mean = torch.mean(torch.tensor(bertscore_result[\"f1\"])).item()\n",
    "\n",
    "\n",
    "    # Collect all results\n",
    "    results = {\n",
    "        \"BLEU\": bleu_result[\"bleu\"],\n",
    "        \"METEOR\": meteor_result[\"meteor\"],\n",
    "        \"ROUGE-1\": rouge_result[\"rouge1\"],\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
    "        \"BERTScore-F1\": bertscore_f1_mean\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# 4. Function to generate the response (for both models)\n",
    "def generate_response(model_gen, tokenizer_gen, question, device_gen):\n",
    "    inputs = tokenizer_gen(question, return_tensors=\"pt\").to(device_gen) # Move inputs to the specified device\n",
    "    outputs = model_gen.generate(**inputs, max_length=100) # Use **inputs to pass both input_ids and attention_mask if present\n",
    "    return tokenizer_gen.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Helper function to load the default model - recreated to avoid running old cell which didn't consider device type\n",
    "def get_default_model_tokenizer(model_name=\"google/flan-t5-large\"):\n",
    "    print(f\"Loading default model: {model_name}\")\n",
    "    default_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "    default_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return default_model, default_tokenizer\n",
    "\n",
    "# 5. Compare default model vs retrained model on recheck_train and test_data\n",
    "def compare_models_on_data(recheck_train, test_data): # Pass data as arguments\n",
    "    # Load default model\n",
    "    # IMPORTANT: Make sure 't5-small' here matches the base model used for your LoRA fine-tuning\n",
    "    default_model, default_tokenizer = get_default_model_tokenizer(\"google/flan-t5-large\") # <<< CHANGE IF NEEDED\n",
    "\n",
    "    # Benchmark on recheck_train\n",
    "    print(\"\\nBenchmarking default model on recheck_train...\")\n",
    "    default_results = benchmark_model(default_model, default_tokenizer, recheck_train)\n",
    "    print(\"\\nBenchmarking retrained model on recheck_train...\")\n",
    "    retrained_results = benchmark_model(model, tokenizer, recheck_train) # model is already loaded and on device\n",
    "\n",
    "    print(\"\\n--- RECHECK_TRAIN COMPARISON ---\")\n",
    "    for metric in default_results:\n",
    "        diff = retrained_results[metric] - default_results[metric]\n",
    "        print(f\"{metric}: Default Model - {default_results[metric]:.4f}, Retrained Model - {retrained_results[metric]:.4f}, Δ {diff:+.4f} (Improvement: {'Yes' if diff > 0 else 'No'})\")\n",
    "\n",
    "    # Benchmark on test_data\n",
    "    print(\"\\nBenchmarking default model on test_data...\")\n",
    "    default_results_test = benchmark_model(default_model, default_tokenizer, test_data)\n",
    "    print(\"\\nBenchmarking retrained model on test_data...\")\n",
    "    retrained_results_test = benchmark_model(model, tokenizer, test_data)\n",
    "\n",
    "    print(\"\\n--- TEST_DATA COMPARISON ---\")\n",
    "    for metric in default_results_test:\n",
    "        diff = retrained_results_test[metric] - default_results_test[metric]\n",
    "        print(f\"{metric}: Default Model - {default_results_test[metric]:.4f}, Retrained Model - {retrained_results_test[metric]:.4f}, Δ {diff:+.4f} (Improvement: {'Yes' if diff > 0 else 'No'})\")\n",
    "\n",
    "# 6. Main execution for comparing the models\n",
    "compare_models_on_data(recheck_train, test_data) # Pass loaded data\n",
    "\n",
    "print(\"\\nBenchmarking finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46266a1-110d-4cf6-9a51-705aa0f97c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
