{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-huggingface\n",
    "%pip install llama-index-llms-huggingface-api\n",
    "%pip install llama-index\n",
    "%pip install python-dotenv\n",
    "%pip install llama-index-llms-deepseek\n",
    "%pip install transformers\n",
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To infinity, and **beyond!**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-2.0-flash\")\n",
    "# Test case to see if lllm is working\n",
    "# response = llm.complete(\"To infinity, and\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset preview:\n",
      "                                               tweet  \\\n",
      "0  People with OCD experience intensely negative,...   \n",
      "1  Hello all I'm Erika an @IOCDF grassroots advoc...   \n",
      "2  In light of last week's OCD Awareness week, we...   \n",
      "3  The GIFS now have over 1.4 million views on GI...   \n",
      "4  The 2022 #OCDweek events, activities, and live...   \n",
      "\n",
      "                                     tokenised_tweet  \\\n",
      "0  ['people', 'ocd', 'experience', 'intensely', '...   \n",
      "1  ['hello', 'erika', 'iocdf', 'grassroots', 'adv...   \n",
      "2  ['light', 'last', 'week', 'ocd', 'awareness', ...   \n",
      "3  ['gifs', 'million', 'views', 'giphy', 'hope', ...   \n",
      "4  ['ocdweek', 'events', 'activities', 'livestrea...   \n",
      "\n",
      "                                    sentiment_scores  compound_score  \n",
      "0  {'neg': 0.242, 'neu': 0.645, 'pos': 0.113, 'co...         -0.8111  \n",
      "1  {'neg': 0.043, 'neu': 0.821, 'pos': 0.136, 'co...          0.6981  \n",
      "2  {'neg': 0.0, 'neu': 0.925, 'pos': 0.075, 'comp...          0.3400  \n",
      "3  {'neg': 0.0, 'neu': 0.848, 'pos': 0.152, 'comp...          0.7840  \n",
      "4  {'neg': 0.0, 'neu': 0.786, 'pos': 0.214, 'comp...          0.8689  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset and choose relevant columns\n",
    "df = pd.read_csv(\"MH_Campaign_Tweets_Sentiment_Scored.csv\")\n",
    "df = df[[\"tweet\", \"tokenised_tweet\", \"sentiment_scores\", \"compound_score\"]]\n",
    "df.drop_duplicates(subset=[\"tweet\"], inplace=True)\n",
    "\n",
    "# Preview the cleaned dataset\n",
    "print(\"Cleaned dataset preview:\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  People with OCD experience intensely negative,...   \n",
      "1  Hello all I'm Erika an @IOCDF grassroots advoc...   \n",
      "2  In light of last week's OCD Awareness week, we...   \n",
      "3  The GIFS now have over 1.4 million views on GI...   \n",
      "4  The 2022 #OCDweek events, activities, and live...   \n",
      "\n",
      "                                     tokenised_tweet  \\\n",
      "0  ['people', 'ocd', 'experience', 'intensely', '...   \n",
      "1  ['hello', 'erika', 'iocdf', 'grassroots', 'adv...   \n",
      "2  ['light', 'last', 'week', 'ocd', 'awareness', ...   \n",
      "3  ['gifs', 'million', 'views', 'giphy', 'hope', ...   \n",
      "4  ['ocdweek', 'events', 'activities', 'livestrea...   \n",
      "\n",
      "                                    sentiment_scores  compound_score  \\\n",
      "0  {'neg': 0.242, 'neu': 0.645, 'pos': 0.113, 'co...         -0.8111   \n",
      "1  {'neg': 0.043, 'neu': 0.821, 'pos': 0.136, 'co...          0.6981   \n",
      "2  {'neg': 0.0, 'neu': 0.925, 'pos': 0.075, 'comp...          0.3400   \n",
      "3  {'neg': 0.0, 'neu': 0.848, 'pos': 0.152, 'comp...          0.7840   \n",
      "4  {'neg': 0.0, 'neu': 0.786, 'pos': 0.214, 'comp...          0.8689   \n",
      "\n",
      "  sentiment_label  \n",
      "0        Negative  \n",
      "1        Positive  \n",
      "2        Positive  \n",
      "3        Positive  \n",
      "4        Positive  \n"
     ]
    }
   ],
   "source": [
    "# Define a function to convert compound sentiment score to Positive/Neutral/Negative label\n",
    "def score_to_label(compound_score: float) -> str:\n",
    "    \"\"\"Convert compound sentiment score to Positive/Neutral/Negative label.\"\"\"\n",
    "    if compound_score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound_score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "\n",
    "# Apply the function to the compound_score column to create a new sentiment_label column\n",
    "df[\"sentiment_label\"] = df[\"compound_score\"].apply(score_to_label)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_configs = {\n",
    "    \"Staff Friendliness\": {\n",
    "        \"keywords\": [\n",
    "            \"staff\",\n",
    "            \"nurse\",\n",
    "            \"doctor\",\n",
    "            \"physician\",\n",
    "            \"receptionist\",\n",
    "            \"hospital staff\",\n",
    "        ],\n",
    "        \"positive_markers\": [\n",
    "            \"friendly\",\n",
    "            \"kind\",\n",
    "            \"helpful\",\n",
    "            \"nice\",\n",
    "            \"caring\",\n",
    "            \"professional\",\n",
    "            \"attentive\",\n",
    "        ],\n",
    "        \"negative_markers\": [\n",
    "            \"rude\",\n",
    "            \"impolite\",\n",
    "            \"unprofessional\",\n",
    "            \"unfriendly\",\n",
    "            \"mean\",\n",
    "            \"disrespectful\",\n",
    "        ],\n",
    "    },\n",
    "    \"Wait Time\": {\n",
    "        \"keywords\": [\"wait\", \"waiting\", \"waited\", \"hours\", \"minutes\", \"time\"],\n",
    "        \"positive_markers\": [\"no wait\", \"quick\", \"quickly\", \"short wait\", \"fast\"],\n",
    "        \"negative_markers\": [\"long wait\", \"waited for\", \"hours\", \"forever\", \"slow\"],\n",
    "    },\n",
    "    \"Overall Experience\": {\n",
    "        \"keywords\": [\"overall experience\", \"overall\", \"experience\"],\n",
    "        \"positive_markers\": [\n",
    "            \"good\",\n",
    "            \"great\",\n",
    "            \"excellent\",\n",
    "            \"amazing\",\n",
    "            \"wonderful\",\n",
    "            \"positive\",\n",
    "        ],\n",
    "        \"negative_markers\": [\"bad\", \"terrible\", \"horrible\", \"awful\", \"negative\"],\n",
    "    },\n",
    "    \"Medication Feedback\": {\n",
    "        \"keywords\": [\n",
    "            \"medication\",\n",
    "            \"medicine\",\n",
    "            \"meds\",\n",
    "            \"treatment\",\n",
    "            \"drug\",\n",
    "            \"prescription\",\n",
    "        ],\n",
    "        \"positive_markers\": [\"effective\", \"worked\", \"helped\", \"effective\", \"relief\"],\n",
    "        \"negative_markers\": [\n",
    "            \"didn't work\",\n",
    "            \"not work\",\n",
    "            \"ineffective\",\n",
    "            \"side effect\",\n",
    "            \"worse\",\n",
    "        ],\n",
    "    },\n",
    "    \"Communication Tone\": {\n",
    "        \"keywords\": [\n",
    "            \"listen\",\n",
    "            \"listened\",\n",
    "            \"listening\",\n",
    "            \"explained\",\n",
    "            \"explain\",\n",
    "            \"explanation\",\n",
    "            \"communicate\",\n",
    "            \"communication\",\n",
    "            \"answered\",\n",
    "            \"answer\",\n",
    "            \"told\",\n",
    "            \"said\",\n",
    "        ],\n",
    "        \"positive_markers\": [\n",
    "            \"listened\",\n",
    "            \"patient\",\n",
    "            \"caring\",\n",
    "            \"attentive\",\n",
    "            \"clear\",\n",
    "            \"explained clearly\",\n",
    "            \"understood\",\n",
    "        ],\n",
    "        \"negative_markers\": [\n",
    "            \"didn't listen\",\n",
    "            \"not listen\",\n",
    "            \"ignored\",\n",
    "            \"rushed\",\n",
    "            \"dismissive\",\n",
    "            \"confusing\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "\n",
    "# Using TextBlob for sentiment analysis as a stand-in for Gemini LLM\n",
    "\n",
    "def classify_sentiment(tweet: str):\n",
    "    \"\"\"\n",
    "\n",
    "    Analyze a tweet's sentiment using an LLM (simulated here with TextBlob).\n",
    "\n",
    "    Returns a dict with overall emotion, intensity, and aspect-based sentiment breakdown.\n",
    "    \"\"\"\n",
    "\n",
    "    text = tweet.lower()\n",
    "\n",
    "    analysis = {}\n",
    "\n",
    "\n",
    "    # Overall sentiment polarity using TextBlob (as a stand-in for Gemini LLM analysis)\n",
    "\n",
    "    blob = TextBlob(tweet)\n",
    "\n",
    "    polarity = (\n",
    "\n",
    "        blob.sentiment.polarity\n",
    "\n",
    "    )  # range [-1.0, 1.0], where >0 = positive sentiment, <0 = negative\n",
    "\n",
    "    # Determine overall emotion category\n",
    "\n",
    "    if polarity > 0.1:\n",
    "\n",
    "        emotion = \"Positive\"\n",
    "\n",
    "    elif polarity < -0.1:\n",
    "\n",
    "        emotion = \"Negative\"\n",
    "\n",
    "    else:\n",
    "\n",
    "        emotion = \"Neutral\"\n",
    "\n",
    "    analysis[\"emotion\"] = emotion\n",
    "\n",
    "\n",
    "    # Determine intensity of sentiment\n",
    "\n",
    "    if emotion == \"Positive\":\n",
    "\n",
    "        intensity = \"Very Positive\" if polarity >= 0.6 else \"Positive\"\n",
    "\n",
    "    elif emotion == \"Negative\":\n",
    "\n",
    "        intensity = \"Very Negative\" if polarity <= -0.6 else \"Negative\"\n",
    "\n",
    "    else:\n",
    "\n",
    "        intensity = \"Neutral\"\n",
    "\n",
    "    analysis[\"intensity\"] = intensity\n",
    "\n",
    "\n",
    "    # Aspect-based sentiment analysis\n",
    "\n",
    "    aspect_sentiments = {}\n",
    "\n",
    "    for aspect, config in aspect_configs.items():\n",
    "\n",
    "        # Check if any aspect keyword is present in the tweet text\n",
    "\n",
    "        if any(keyword in text for keyword in config[\"keywords\"]):\n",
    "\n",
    "            # If aspect context is found, determine sentiment for that aspect\n",
    "\n",
    "            aspect_sent = \"Neutral\"  # default sentiment for aspect\n",
    "\n",
    "            # Check for explicit negative markers first\n",
    "\n",
    "            for marker in config[\"negative_markers\"]:\n",
    "\n",
    "                if marker in text:\n",
    "\n",
    "                    aspect_sent = \"Negative\"\n",
    "\n",
    "                    break\n",
    "\n",
    "            # If no negative sentiment marker was found, check for positive markers\n",
    "\n",
    "            if aspect_sent == \"Neutral\":\n",
    "\n",
    "                for marker in config[\"positive_markers\"]:\n",
    "\n",
    "                    if marker in text:\n",
    "\n",
    "                        aspect_sent = \"Positive\"\n",
    "\n",
    "                        break\n",
    "\n",
    "            aspect_sentiments[aspect] = aspect_sent\n",
    "\n",
    "\n",
    "    analysis[\"aspects\"] = aspect_sentiments\n",
    "\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation:\n",
      "  Accuracy       : 56.07%\n",
      "  Macro F1-score : 45.51%\n",
      "\n",
      "Example Sentiment Analysis on Sample Tweets:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the classifier to each tweet and collect predictions\n",
    "predicted_emotions = []\n",
    "for tweet in df[\"tweet\"]:\n",
    "    result = classify_sentiment(tweet)\n",
    "    predicted_emotions.append(result[\"emotion\"])\n",
    "\n",
    "# Use scikit-learn to evaluate the model's predictions against reference labels\n",
    "y_true = df[\"sentiment_label\"].tolist()  # actual labels from the dataset\n",
    "y_pred = predicted_emotions  # predicted labels from our classifier\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")  # macro-averaged F1 for multi-class\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"  Accuracy       : {:.2f}%\".format(accuracy * 100))\n",
    "print(\"  Macro F1-score : {:.2f}%\".format(f1 * 100))\n",
    "print(\"\\nExample Sentiment Analysis on Sample Tweets:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentiment analysis on sample tweets:\n",
      "\n",
      "Tweet:\n",
      "People with OCD experience intensely negative, repetitive and intrusive thoughts with a chronic feeling of doubt or danger. To calm the anxiety, people with OCD will often repeat an action, these are known as compulsions. If you experience this, therapy can help. #OCDWeek #OCD https://t.co/2MKew1wG4u\n",
      "\n",
      "Overall Sentiment: Neutral 🤔\n",
      "Intensity        : Neutral 🤔\n",
      "Aspect Sentiments:\n",
      "  - Overall Experience: Negative ❌\n",
      "--------------------------------------------------\n",
      "Tweet:\n",
      "Hello all I'm Erika an @IOCDF grassroots advocate that loves to #rockyourvalues by painting rocks to spread awareness and lower stigma about OCD in our community.  Here is a look back from #OCDweek 2022!! Excited for my workshop at the end of Feb! 🫶\n",
      "\n",
      "https://t.co/nzsi43m1gW\n",
      "\n",
      "Overall Sentiment: Positive 😊\n",
      "Intensity        : Positive 😊\n",
      "Aspect Sentiments: (No specific aspects mentioned)\n",
      "--------------------------------------------------\n",
      "Tweet:\n",
      "No one should have to convince others that a health condition is real. \n",
      "\n",
      "But with #OCD it happens all the time. Due to false ideas about OCD, people unknowingly trivialize it.\n",
      "\n",
      "This site can bust myths &amp; transforms \"non-believers\" into advocates: https://t.co/8du4NEJYFt\n",
      "\n",
      "#OCDWeek https://t.co/js7mXtUoNk\n",
      "\n",
      "Overall Sentiment: Negative 😡\n",
      "Intensity        : Negative 😡\n",
      "Aspect Sentiments:\n",
      "  - Wait Time: Neutral 🤔\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Prepare to display output with emojis. If no aspect is relevant, we'll show only overall sentiment.\n",
    "# Define mapping from sentiment label to emoji for convenience\n",
    "emotion_emoji = {\"Positive\": \"😊\", \"Negative\": \"😡\", \"Neutral\": \"🤔\"}\n",
    "\n",
    "# Show a few example tweet outputs with sentiment breakdown and emojis\n",
    "# We'll pick one example from each sentiment category (if available) to demonstrate.\n",
    "examples = []\n",
    "for sentiment in [\"Positive\", \"Negative\", \"Neutral\"]:\n",
    "    # find index of a tweet where the *predicted* emotion matches this sentiment\n",
    "    try:\n",
    "        idx = y_pred.index(sentiment)\n",
    "        examples.append(idx)\n",
    "    except ValueError:\n",
    "        continue  # sentiment not present in predictions\n",
    "\n",
    "# Remove duplicates (in case the first found index overlaps, e.g., if first tweet is positive and index 0 used twice)\n",
    "examples = sorted(set(examples))\n",
    "print(\"Example sentiment analysis on sample tweets:\\n\")\n",
    "for idx in examples:\n",
    "    tweet_text = df.loc[idx, \"tweet\"]\n",
    "    result = classify_sentiment(tweet_text)\n",
    "    overall = result[\"emotion\"]\n",
    "    intensity = result[\"intensity\"]\n",
    "    aspects = result[\"aspects\"]\n",
    "\n",
    "    # Print tweet text with a header\n",
    "    print(\"Tweet:\")\n",
    "    print(tweet_text)\n",
    "    print()  # Blank line for spacing\n",
    "\n",
    "    # Print overall sentiment and intensity with emojis\n",
    "    print(\"Overall Sentiment: {} {}\".format(overall, emotion_emoji.get(overall, \"\")))\n",
    "    print(\"Intensity        : {} {}\".format(intensity, emotion_emoji.get(overall, \"\")))\n",
    "\n",
    "    # Print aspect sentiments (if any)\n",
    "    if aspects:\n",
    "        print(\"Aspect Sentiments:\")\n",
    "        for aspect, sentiment in aspects.items():\n",
    "            emoji = (\n",
    "                \"✅\"\n",
    "                if sentiment == \"Positive\"\n",
    "                else \"❌\" if sentiment == \"Negative\" else \"🤔\"\n",
    "            )\n",
    "            print(\"  - {}: {} {}\".format(aspect, sentiment, emoji))\n",
    "    else:\n",
    "        print(\"Aspect Sentiments: (No specific aspects mentioned)\")\n",
    "\n",
    "    # Print a separator line\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**LLM Response (Streaming)**\n",
       "\n",
       "Okay, let's break down what a Pandas DataFrame is. It's a fundamental data structure in Python, and it's incredibly powerful for working with structured data.\n",
       "\n",
       "**What is a Pandas DataFrame?**\n",
       "\n",
       "At its core, a Pandas DataFrame is like a spreadsheet or a SQL table in Python.  It's a two-dimensional, labeled data structure with columns of potentially different data types.  Think of it as a table where:\n",
       "\n",
       "* **Rows:** Represent individual records or observations.\n",
       "* **Columns:** Represent different attributes or features for those records.\n",
       "* **Labels:** Each row and column has a label (name) that you can use to access and manipulate the data.\n",
       "\n",
       "**Key Characteristics and Features:**\n",
       "\n",
       "1. **Data Types:**  Each column in a DataFrame can hold a different data type (e.g., integers, floats, strings, booleans, dates). This flexibility is a major strength.\n",
       "\n",
       "2. **Labeled Axes:**  The DataFrame has two primary labels:\n",
       "   * **Index:**  Labels for the rows.  This is often (but not always) a numerical sequence, but can be customized.\n",
       "   * **Columns:** Labels for the columns.\n",
       "\n",
       "3. **Heterogeneous Columns:**  As mentioned, columns don't have to be the same type.  A DataFrame might have columns for 'age' (integers), 'name' (strings), and 'salary' (floats).\n",
       "\n",
       "4. **Data Alignment:** Pandas automatically aligns data based on the column labels, making it easy to perform operations on columns with similar names.\n",
       "\n",
       "5. **Powerful Operations:** Pandas provides a vast array of functions and methods for:\n",
       "   * **Data Cleaning:** Handling missing values, removing duplicates, etc.\n",
       "   * **Data Transformation:**  Filtering, sorting, grouping, applying functions to columns.\n",
       "   * **Data Analysis:**  Calculating statistics, creating visualizations.\n",
       "   * **Data I/O:** Reading data from various file formats (CSV, Excel, SQL databases, etc.) and writing data to those formats.\n",
       "\n",
       "**How to Create a DataFrame:**\n",
       "\n",
       "There are several ways to create a DataFrame:\n",
       "\n",
       "* **From a Dictionary:**\n",
       "   ```python\n",
       "   import pandas as pd\n",
       "\n",
       "   data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
       "           'Age': [25, 30, 28],\n",
       "           'City': ['New York', 'London', 'Paris']}\n",
       "\n",
       "   df = pd.DataFrame(data)\n",
       "   print(df)\n",
       "   ```\n",
       "\n",
       "* **From a List of Lists:**\n",
       "   ```python\n",
       "   import pandas as pd\n",
       "\n",
       "   data = [['Alice', 25, 'New York'],\n",
       "           ['Bob', 30, 'London'],\n",
       "           ['Charlie', 28, 'Paris']]\n",
       "\n",
       "   df = pd.DataFrame(data, columns=['Name', 'Age', 'City']) # Specify column names\n",
       "   print(df)\n",
       "   ```\n",
       "\n",
       "* **From a NumPy Array:**\n",
       "   ```python\n",
       "   import pandas as pd\n",
       "   import numpy as np\n",
       "\n",
       "   data = np.random.randn(5, 3)  # Create a 5x3 array of random numbers\n",
       "   df = pd.DataFrame(data, columns=['Col1', 'Col2', 'Col3'])\n",
       "   print(df)\n",
       "   ```\n",
       "\n",
       "**Example Output (from the dictionary example):**\n",
       "\n",
       "```\n",
       "      Name  Age      City\n",
       "0    Alice   25  New York\n",
       "1      Bob   30    London\n",
       "2  Charlie   28     Paris\n",
       "```\n",
       "\n",
       "**Why is Pandas DataFrames so popular?**\n",
       "\n",
       "* **Ease of Use:** Pandas provides a high-level, intuitive interface for working with data.\n",
       "* **Performance:**  It's built on NumPy, which is optimized for numerical computations.\n",
       "* **Integration:** It seamlessly integrates with other Python libraries like NumPy, SciPy, Matplotlib, and Scikit-learn.\n",
       "\n",
       "**Resources for Learning More:**\n",
       "\n",
       "* **Pandas Documentation:** [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)\n",
       "* **Tutorials:** [https://www.datacamp.com/tutorial/pandas](https://www.datacamp.com/tutorial/pandas)\n",
       "* **Real Python Pandas Tutorial:** [https://realpython.com/pandas-dataframe-quickstart/](https://realpython.com/pandas-dataframe-quickstart/)\n",
       "\n",
       "\n",
       "Do you want me to:\n",
       "\n",
       "*   Give you more specific examples of operations you can perform with DataFrames?\n",
       "*   Explain how DataFrames relate to NumPy?\n",
       "*   Help you with a particular task you're trying to accomplish with Pandas?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Testing gemma 3\n",
    "# from IPython.display import display, Markdown, clear_output\n",
    "# import ollama\n",
    "\n",
    "\n",
    "# # Example prompt\n",
    "\n",
    "\n",
    "# prompt = \"What is pandas dataframe?\"\n",
    "\n",
    "\n",
    "# # Call llama.chat with streaming enabled\n",
    "\n",
    "\n",
    "# # Replace 'c' with your LLM client instance\n",
    "\n",
    "\n",
    "# messages = [\n",
    "\n",
    "\n",
    "#     {\"role\": \"user\", \"content\": prompt},\n",
    "\n",
    "\n",
    "# ]\n",
    "\n",
    "\n",
    "# response_stream = ollama.chat(\n",
    "\n",
    "\n",
    "#     model=\"gemma3:latest\", messages=[{\"role\": \"user\", \"content\": prompt}], stream=True\n",
    "\n",
    "\n",
    "# )\n",
    "\n",
    "\n",
    "# # Initialize an empty response string\n",
    "\n",
    "\n",
    "# streamed_response = \"\"\n",
    "\n",
    "\n",
    "# # Iterate over the streamed tokens\n",
    "\n",
    "\n",
    "# for token in response_stream:\n",
    "\n",
    "\n",
    "#     # Append the current token to the response\n",
    "\n",
    "\n",
    "#     streamed_response += token[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "#     # Clear previous output and display the updated response\n",
    "\n",
    "\n",
    "#     clear_output(wait=True)\n",
    "\n",
    "\n",
    "#     display(Markdown(\"**LLM Response (Streaming)**\\n\\n\" + streamed_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
