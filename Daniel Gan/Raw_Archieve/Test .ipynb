{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d476d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d93502b598478da6216e47dc8aa0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Generation time: 165.53 seconds\n",
      "\n",
      " Generated Analysis:\n",
      " You are an expert financial risk analyst. Analyze the provided text for financial risks, and output a structured assessment in JSON format including risk detection, specific risk flags,financial exposure details, and analysis notes. \n",
      "    The Company has entered into a five-year contract to purchase raw materials\n",
      "    from a single supplier in a volatile market. The contract requires minimum\n",
      "    purchases of $10M annually with no cancellation clause. Recent market analysis\n",
      "    suggests potential price fluctuations of up to 40% in the next year.\n",
      "    \n",
      "    The Company has identified the potential financial risks associated with the\n",
      "    contract and has implemented a risk management strategy to mitigate the impact\n",
      "    of price fluctuations. The strategy includes:\n",
      "\n",
      "    - Negotiating a price cap of 10% above the current market rate.\n",
      "    - Implementing a price floor of 5% below the current market rate.\n",
      "    - Maintaining a minimum inventory level of 20% of annual purchases.\n",
      "    - Utilizing financial derivatives to hedge against price fluctuations.\n",
      "    - Reviewing market conditions quarterly and adjusting the risk management\n",
      "      strategy as needed.\n",
      "\n",
      "    The Company has also implemented a financial risk management process to\n",
      "    monitor the contract's financial performance and detect any potential\n",
      "    deviations from the risk management strategy. This process includes:\n",
      "\n",
      "    - Regularly reviewing market conditions and adjusting the risk management\n",
      "      strategy as needed.\n",
      "    - Conducting financial risk assessments quarterly to identify potential\n",
      "      financial exposure.\n",
      "    - Implementing internal controls to ensure compliance with the risk\n",
      "      management strategy.\n",
      "    - Regularly reviewing the contract's financial performance and detecting any\n",
      "      potential deviations from the risk management strategy.\n",
      "\n",
      "    The Company has established a financial risk management committee to oversee\n",
      "    the implementation of the risk management strategy and to provide oversight\n",
      "    for the financial risk management process. The committee includes senior\n",
      "    management and financial risk experts and meets quarterly to review the\n",
      "    contract's financial performance and to identify potential financial exposure.\n",
      "\n",
      "    The Company has also established a financial risk management policy to\n",
      "    provide guidance for the implementation of the risk management strategy and\n",
      "    the financial risk management process. The policy includes:\n",
      "\n",
      "    - Defining the roles and responsibilities of the financial risk management\n",
      "      committee.\n",
      "    - Establishing guidelines for conducting financial risk assessments.\n",
      "    - Providing guidance for the implementation of internal controls.\n",
      "    - Defining the process for reviewing the contract's financial performance.\n",
      "\n",
      "    The Company has established a financial risk management process to monitor\n",
      "    the contract's financial performance and detect any potential deviations from\n",
      "    the risk management strategy. This process includes:\n",
      "\n",
      "    - Regularly reviewing market conditions and adjusting the risk management\n",
      "      strategy as needed.\n",
      "    - Conducting financial risk assessments quarterly to\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import time\n",
    "\n",
    "# Load fine-tuned model and tokenizer\n",
    "base_model_path = \"./Mistral-7B-v0.1\"             # aBase model\n",
    "finetuned_model_path = \"./mistral-risk-finetuned-final\"    # Fine-tuned weights\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load the model with LoRA weights\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"./offload\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, finetuned_model_path)\n",
    "model.eval()\n",
    "\n",
    "# Define your inference function\n",
    "def generate_analysis(input_data: str, max_new_tokens=512, temperature=0.7, top_p=0.95):\n",
    "    prompt = f\"You are an expert financial risk analyst. Analyze the provided text for financial risks, and output a structured assessment in JSON format including risk detection, specific risk flags,financial exposure details, and analysis notes. {input_data}\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"\\n⏱️ Generation time: {end - start:.2f} seconds\")\n",
    "    return result\n",
    "\n",
    "# Example use\n",
    "input_text = \"\"\"\n",
    "    The Company has entered into a five-year contract to purchase raw materials\n",
    "    from a single supplier in a volatile market. The contract requires minimum\n",
    "    purchases of $10M annually with no cancellation clause. Recent market analysis\n",
    "    suggests potential price fluctuations of up to 40% in the next year.\n",
    "    \"\"\"\n",
    "output = generate_analysis(input_text)\n",
    "print(\"\\n Generated Analysis:\\n\", output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8b3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "import Levenshtein\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "from docx import Document\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load evaluation metrics using the evaluate package\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# 100 diverse test prompts for a compliance-focused LLM\n",
    "prompts = [\n",
    "    \"What are the key environmental risks highlighted in this report?\",\n",
    "    \"Summarize key cybersecurity vulnerabilities in the filing.\",\n",
    "    \"Assess financial statement accuracy based on disclosed risks.\",\n",
    "    \"Identify any potential conflicts of interest in governance structures.\",\n",
    "    \"What are the tax risks identified in the latest filing?\",\n",
    "    \"Highlight any liquidity risks mentioned in this filing.\",\n",
    "    \"Evaluate compliance with international anti-bribery laws.\",\n",
    "    \"Analyze the impact of market risk factors disclosed in this report.\",\n",
    "    \"What are the key risks identified in this company’s supply chain?\",\n",
    "    \"Summarize risk factors from the latest 10-Q filing.\",\n",
    "    \"Identify any references to potential violations of the Foreign Corrupt Practices Act (FCPA).\",\n",
    "    \"What governance issues are raised in this proxy statement?\",\n",
    "    \"Detect any conflicts between financial projections and risk disclosures.\",\n",
    "    \"Identify operational inefficiencies highlighted in the filing.\",\n",
    "    \"Summarize management's response to identified risks.\",\n",
    "    \"What mitigation strategies are proposed for identified risks?\",\n",
    "    \"Review the risk management framework outlined in the document.\",\n",
    "    \"Analyze potential strategic risks identified in the report.\",\n",
    "    \"Highlight reputational risks mentioned in the document.\",\n",
    "    \"Identify regulatory penalties or fines discussed in the report.\",\n",
    "    \"Detect any signs of financial misreporting in the filing.\",\n",
    "    \"Analyze the company’s risk appetite based on the disclosed risks.\",\n",
    "    \"Identify political risks related to operations in foreign countries.\",\n",
    "    \"Assess the adequacy of the company’s disaster recovery plans.\",\n",
    "    \"What are the sustainability risks identified in this report?\",\n",
    "    \"Summarize legal proceedings related to risk in this filing.\",\n",
    "    \"Identify insurance coverage gaps discussed in the filing.\",\n",
    "    \"Detect any potential issues with intellectual property management.\",\n",
    "    \"Highlight key fraud risks disclosed in the document.\",\n",
    "    \"Summarize the company’s risk tolerance as outlined in the filing.\",\n",
    "    \"Assess the company’s risk diversification strategy.\",\n",
    "    \"Review how the company plans to handle potential supply chain disruptions.\",\n",
    "    \"Identify reputational risks related to the company’s brand.\",\n",
    "    \"Analyze risk exposure from foreign exchange fluctuations.\",\n",
    "    \"Summarize any risks related to customer concentration.\",\n",
    "    \"Detect conflicts of interest in the company’s executive compensation plan.\",\n",
    "    \"Identify risks related to mergers and acquisitions in the filing.\",\n",
    "    \"Analyze whether the company has adequate legal compliance programs.\",\n",
    "    \"Review how the company addresses regulatory changes in this document.\",\n",
    "    \"Summarize the company’s risk management priorities for the next year.\",\n",
    "    \"Assess risks related to changes in government policy.\",\n",
    "    \"Identify any material weaknesses in internal controls.\",\n",
    "    \"Evaluate the company’s risk management performance over time.\",\n",
    "    \"Highlight risks associated with operational outsourcing.\",\n",
    "    \"Assess the financial impact of risk events disclosed in the filing.\",\n",
    "    \"Summarize risks related to the company’s digital transformation efforts.\",\n",
    "    \"Identify key social risks disclosed in the filing.\",\n",
    "    \"What are the potential risks associated with the company’s new product launch?\",\n",
    "    \"Evaluate the company’s approach to mitigating operational risks.\",\n",
    "    \"Summarize risks related to the company’s leadership transitions.\",\n",
    "    \"Highlight financial risks related to the company’s capital structure.\",\n",
    "    \"What are the potential risks associated with the company’s debt?\",\n",
    "    \"Identify any environmental liabilities discussed in the filing.\",\n",
    "    \"Assess the company’s readiness for changes in tax law.\",\n",
    "    \"What are the key factors contributing to the company’s credit risk?\",\n",
    "    \"Analyze the company’s approach to managing legal risks.\",\n",
    "    \"Highlight risks related to compliance with labor laws.\",\n",
    "    \"What are the financial implications of disclosed risks?\",\n",
    "    \"Assess the company’s approach to managing reputation risk.\",\n",
    "    \"Summarize the company’s governance structure and related risks.\",\n",
    "    \"Identify risks related to competition in the company’s industry.\",\n",
    "    \"Analyze risks associated with the company’s expansion strategy.\",\n",
    "    \"Evaluate how the company mitigates risks from geopolitical tensions.\",\n",
    "    \"Summarize the company’s approach to managing climate-related risks.\",\n",
    "    \"Detect any emerging risks in the company’s business environment.\",\n",
    "    \"What are the risks associated with the company’s reliance on technology?\",\n",
    "    \"Highlight any risks identified in the company’s corporate social responsibility (CSR) reports.\",\n",
    "    \"Identify risks associated with intellectual property infringement.\",\n",
    "    \"Summarize risks related to compliance with the GDPR.\",\n",
    "    \"Evaluate the company’s exposure to risks from commodity price volatility.\",\n",
    "    \"What operational risks are associated with the company’s logistics network?\",\n",
    "    \"Identify key market risks affecting the company’s performance.\",\n",
    "    \"Analyze risks arising from changes in consumer behavior.\",\n",
    "    \"Summarize risks related to the company’s reliance on key suppliers.\",\n",
    "    \"Identify risks related to changes in the regulatory landscape for healthcare.\",\n",
    "    \"Evaluate risks associated with the company’s use of third-party vendors.\",\n",
    "    \"What are the risks related to the company’s employee compensation plans?\",\n",
    "    \"Summarize risks identified in the company’s sustainability reports.\",\n",
    "    \"Identify risks related to the company’s reliance on renewable energy.\",\n",
    "    \"Assess the company’s approach to managing risks from natural disasters.\",\n",
    "    \"What are the risks related to the company’s strategic investments?\",\n",
    "    \"Summarize the risks associated with the company’s real estate holdings.\",\n",
    "    \"What are the company’s plans to address emerging regulatory risks?\",\n",
    "    \"Detect risks associated with the company’s reliance on digital marketing.\",\n",
    "    \"What are the risks associated with the company’s international operations?\",\n",
    "    \"Summarize the company’s approach to managing workforce-related risks.\",\n",
    "    \"Highlight risks related to the company’s pension liabilities.\",\n",
    "    \"Identify risks related to potential supply shortages.\",\n",
    "    \"What are the risks associated with the company’s cybersecurity measures?\",\n",
    "    \"Assess the company’s compliance with industry-specific regulations.\",\n",
    "    \"Summarize risks related to the company’s research and development activities.\",\n",
    "    \"What are the potential risks related to the company’s legal disputes?\",\n",
    "    \"Identify risks related to changes in consumer privacy laws.\",\n",
    "    \"What are the emerging risks in the company’s market?\",\n",
    "    \"Summarize risks related to the company’s debt refinancing efforts.\",\n",
    "    \"Identify risks associated with fluctuations in raw material prices.\",\n",
    "    \"Assess risks related to the company’s foreign investment strategies.\",\n",
    "    \"Summarize the company’s risk management approach to emerging markets.\",\n",
    "    \"Evaluate the company’s risk management framework against best practices.\"\n",
    "]\n",
    "\n",
    "# Number of test runs\n",
    "num_tests = 3\n",
    "win_threshold = 0.5  # BERTScore threshold for Win% calculation\n",
    "\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize summary containers\n",
    "results = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    # Initialize lists for performance metrics per prompt\n",
    "    time_taken_list = []\n",
    "    tokens_per_second_list = []\n",
    "    perplexity_list = []\n",
    "    rouge_scores = []\n",
    "    bleu_scores = []\n",
    "    edit_distance_list = []\n",
    "    bert_score_list = []\n",
    "    win_rate_list = []\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        start_time = time.time()\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_new_tokens=64, temperature=0.7)\n",
    "\n",
    "        decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        time_taken = time.time() - start_time\n",
    "        time_taken_list.append(time_taken)\n",
    "\n",
    "        num_tokens = len(inputs[\"input_ids\"][0]) + 64\n",
    "        tokens_per_second = num_tokens / time_taken\n",
    "        tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            perplexity = torch.exp(loss).item()\n",
    "            perplexity_list.append(perplexity)\n",
    "\n",
    "        rouge_result = rouge.compute(predictions=[decoded_output], references=[prompt])\n",
    "        rouge_scores.append(rouge_result[\"rougeL\"])\n",
    "\n",
    "        bleu_result = bleu.compute(predictions=[decoded_output], references=[prompt])\n",
    "        bleu_scores.append(bleu_result[\"bleu\"])\n",
    "\n",
    "        edit_distance = levenshtein_distance(decoded_output, prompt)\n",
    "        edit_distance_list.append(edit_distance)\n",
    "\n",
    "        P, R, F1 = bert_score([decoded_output], [prompt], lang=\"en\", rescale_with_baseline=True)\n",
    "        f1_score = F1.mean().item()\n",
    "        bert_score_list.append(f1_score)\n",
    "        win_rate_list.append(1 if f1_score >= win_threshold else 0)\n",
    "\n",
    "    # Collect average results for this prompt\n",
    "    results.append({\n",
    "        \"prompt\": prompt,\n",
    "        \"avg_time\": sum(time_taken_list) / num_tests,\n",
    "        \"avg_tps\": sum(tokens_per_second_list) / num_tests,\n",
    "        \"avg_perplexity\": sum(perplexity_list) / num_tests,\n",
    "        \"avg_rouge\": sum(rouge_scores) / num_tests,\n",
    "        \"avg_bleu\": sum(bleu_scores) / num_tests,\n",
    "        \"avg_edit_distance\": sum(edit_distance_list) / num_tests,\n",
    "        \"avg_bert_score\": sum(bert_score_list) / num_tests,\n",
    "        \"win_rate\": sum(win_rate_list) / num_tests * 100\n",
    "    })\n",
    "\n",
    "# Create a Word document\n",
    "doc = Document()\n",
    "doc.add_heading('LLM Compliance Evaluation Report', 0)\n",
    "\n",
    "# Add model and experiment metadata\n",
    "doc.add_paragraph(f\"Model: {model.__class__.__name__}\")\n",
    "doc.add_paragraph(f\"Number of test runs per prompt: {num_tests}\")\n",
    "doc.add_paragraph(f\"BERTScore Win Threshold: {win_threshold}\")\n",
    "\n",
    "# Add results table\n",
    "table = doc.add_table(rows=1, cols=9)\n",
    "table.style = 'Table Grid'\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = 'Prompt'\n",
    "hdr_cells[1].text = 'Time (s)'\n",
    "hdr_cells[2].text = 'Tokens/sec'\n",
    "hdr_cells[3].text = 'Perplexity'\n",
    "hdr_cells[4].text = 'ROUGE-L'\n",
    "hdr_cells[5].text = 'BLEU'\n",
    "hdr_cells[6].text = 'Edit Dist'\n",
    "hdr_cells[7].text = 'BERTScore'\n",
    "hdr_cells[8].text = 'Win Rate (%)'\n",
    "\n",
    "# Add each result to the table\n",
    "for r in results:\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = r['prompt']\n",
    "    row_cells[1].text = f\"{r['avg_time']:.2f}\"\n",
    "    row_cells[2].text = f\"{r['avg_tps']:.2f}\"\n",
    "    row_cells[3].text = f\"{r['avg_perplexity']:.2f}\"\n",
    "    row_cells[4].text = f\"{r['avg_rouge']:.4f}\"\n",
    "    row_cells[5].text = f\"{r['avg_bleu']:.4f}\"\n",
    "    row_cells[6].text = f\"{r['avg_edit_distance']:.2f}\"\n",
    "    row_cells[7].text = f\"{r['avg_bert_score']:.4f}\"\n",
    "    row_cells[8].text = f\"{r['win_rate']:.2f}\"\n",
    "\n",
    "# Save the document\n",
    "doc.save(\"compliance_mistral_finetuned_evaluation.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221d533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1edef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
