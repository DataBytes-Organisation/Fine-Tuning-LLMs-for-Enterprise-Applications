{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb745e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\danie\\anaconda5\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\danie\\anaconda5\\lib\\site-packages (0.19.1)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/4.0 MB 272.3 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.1/4.0 MB 272.3 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.1/4.0 MB 272.3 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.1/4.0 MB 272.3 kB/s eta 0:00:15\n",
      "     - -------------------------------------- 0.2/4.0 MB 403.5 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/4.0 MB 403.5 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/4.0 MB 403.5 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/4.0 MB 403.5 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.3/4.0 MB 431.0 kB/s eta 0:00:09\n",
      "     --- ------------------------------------ 0.4/4.0 MB 586.1 kB/s eta 0:00:07\n",
      "     --- ------------------------------------ 0.4/4.0 MB 586.1 kB/s eta 0:00:07\n",
      "     --- ------------------------------------ 0.4/4.0 MB 586.1 kB/s eta 0:00:07\n",
      "     --- ------------------------------------ 0.4/4.0 MB 586.1 kB/s eta 0:00:07\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     --------------- ------------------------ 1.6/4.0 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 1.6/4.0 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 1.6/4.0 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 1.6/4.0 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 2.1/4.0 MB 1.8 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.0/4.0 MB 2.9 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/4.0 MB 273.8 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.1/4.0 MB 273.8 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.1/4.0 MB 273.8 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.1/4.0 MB 273.8 kB/s eta 0:00:15\n",
      "     - -------------------------------------- 0.2/4.0 MB 393.8 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/4.0 MB 393.8 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/4.0 MB 393.8 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/4.0 MB 393.8 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/4.0 MB 310.8 kB/s eta 0:00:13\n",
      "     --- ------------------------------------ 0.4/4.0 MB 621.7 kB/s eta 0:00:06\n",
      "     --- ------------------------------------ 0.4/4.0 MB 621.7 kB/s eta 0:00:06\n",
      "     --- ------------------------------------ 0.4/4.0 MB 621.7 kB/s eta 0:00:06\n",
      "     --- ------------------------------------ 0.4/4.0 MB 621.7 kB/s eta 0:00:06\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.8/4.0 MB 963.6 kB/s eta 0:00:04\n",
      "     ------------- -------------------------- 1.4/4.0 MB 1.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 1.6/4.0 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 1.6/4.0 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 1.6/4.0 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 1.6/4.0 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.2/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.0/4.0 MB 2.9 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.1%2Bcu118-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 0.9/4.0 MB 29.1 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 2.5/4.0 MB 31.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.0/4.0 MB 32.0 MB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.1%2Bcu118-cp312-cp312-win_amd64.whl (2695.4 MB)\n",
      "     ---------------------------------------- 0.0/2.7 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.7 GB 24.8 MB/s eta 0:01:49\n",
      "     ---------------------------------------- 0.0/2.7 GB 34.7 MB/s eta 0:01:18\n",
      "     ---------------------------------------- 0.0/2.7 GB 32.8 MB/s eta 0:01:22\n",
      "     ---------------------------------------- 0.0/2.7 GB 31.4 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.7 GB 31.3 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.7 GB 30.5 MB/s eta 0:01:29\n",
      "     ---------------------------------------- 0.0/2.7 GB 30.5 MB/s eta 0:01:29\n",
      "     ---------------------------------------- 0.0/2.7 GB 31.2 MB/s eta 0:01:27\n",
      "     ---------------------------------------- 0.0/2.7 GB 29.7 MB/s eta 0:01:31\n",
      "     ---------------------------------------- 0.0/2.7 GB 31.2 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.7 GB 31.2 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.7 GB 31.2 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.7 GB 34.4 MB/s eta 0:01:18\n",
      "     ---------------------------------------- 0.0/2.7 GB 36.3 MB/s eta 0:01:14\n",
      "     ---------------------------------------- 0.0/2.7 GB 36.4 MB/s eta 0:01:14\n",
      "     ---------------------------------------- 0.0/2.7 GB 38.5 MB/s eta 0:01:10\n",
      "     ---------------------------------------- 0.0/2.7 GB 40.9 MB/s eta 0:01:06\n",
      "     ---------------------------------------- 0.0/2.7 GB 43.7 MB/s eta 0:01:02\n",
      "     ---------------------------------------- 0.0/2.7 GB 43.7 MB/s eta 0:01:01\n",
      "     ---------------------------------------- 0.0/2.7 GB 43.7 MB/s eta 0:01:01\n",
      "      --------------------------------------- 0.0/2.7 GB 50.4 MB/s eta 0:00:53\n",
      "      --------------------------------------- 0.0/2.7 GB 50.4 MB/s eta 0:00:53\n",
      "      --------------------------------------- 0.0/2.7 GB 50.4 MB/s eta 0:00:53\n",
      "      --------------------------------------- 0.0/2.7 GB 54.4 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.0/2.7 GB 54.4 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.0/2.7 GB 54.7 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:45\n",
      "      --------------------------------------- 0.1/2.7 GB 54.4 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.1/2.7 GB 54.4 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.1/2.7 GB 54.4 MB/s eta 0:00:49\n",
      "      --------------------------------------- 0.1/2.7 GB 54.4 MB/s eta 0:00:49\n",
      "     - -------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:49\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:45\n",
      "     - -------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:48\n",
      "     - -------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:48\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.5 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.8 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:48\n",
      "     - -------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:48\n",
      "     - -------------------------------------- 0.1/2.7 GB 50.4 MB/s eta 0:00:52\n",
      "     - -------------------------------------- 0.1/2.7 GB 50.4 MB/s eta 0:00:52\n",
      "     - -------------------------------------- 0.1/2.7 GB 46.7 MB/s eta 0:00:56\n",
      "     - -------------------------------------- 0.1/2.7 GB 46.7 MB/s eta 0:00:56\n",
      "     - -------------------------------------- 0.1/2.7 GB 46.7 MB/s eta 0:00:56\n",
      "     - -------------------------------------- 0.1/2.7 GB 46.9 MB/s eta 0:00:55\n",
      "     - -------------------------------------- 0.1/2.7 GB 50.4 MB/s eta 0:00:52\n",
      "     - -------------------------------------- 0.1/2.7 GB 43.7 MB/s eta 0:00:59\n",
      "     - -------------------------------------- 0.1/2.7 GB 43.7 MB/s eta 0:00:59\n",
      "     - -------------------------------------- 0.1/2.7 GB 40.9 MB/s eta 0:01:03\n",
      "     - -------------------------------------- 0.1/2.7 GB 38.6 MB/s eta 0:01:07\n",
      "     - -------------------------------------- 0.1/2.7 GB 36.4 MB/s eta 0:01:11\n",
      "     - -------------------------------------- 0.1/2.7 GB 32.7 MB/s eta 0:01:19\n",
      "     - -------------------------------------- 0.1/2.7 GB 34.4 MB/s eta 0:01:15\n",
      "     - -------------------------------------- 0.1/2.7 GB 38.5 MB/s eta 0:01:07\n",
      "     - -------------------------------------- 0.1/2.7 GB 40.9 MB/s eta 0:01:03\n",
      "     -- ------------------------------------- 0.1/2.7 GB 46.9 MB/s eta 0:00:55\n",
      "     -- ------------------------------------- 0.1/2.7 GB 50.4 MB/s eta 0:00:51\n",
      "     -- ------------------------------------- 0.1/2.7 GB 50.4 MB/s eta 0:00:51\n",
      "     -- ------------------------------------- 0.1/2.7 GB 54.7 MB/s eta 0:00:47\n",
      "     -- ------------------------------------- 0.1/2.7 GB 54.4 MB/s eta 0:00:47\n",
      "     -- ------------------------------------- 0.1/2.7 GB 54.4 MB/s eta 0:00:47\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.8 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 54.7 MB/s eta 0:00:47\n",
      "     -- ------------------------------------- 0.2/2.7 GB 54.7 MB/s eta 0:00:47\n",
      "     -- ------------------------------------- 0.2/2.7 GB 54.7 MB/s eta 0:00:47\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 54.4 MB/s eta 0:00:47\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.8 MB/s eta 0:00:42\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.8 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 54.4 MB/s eta 0:00:46\n",
      "     --- ------------------------------------ 0.2/2.7 GB 50.4 MB/s eta 0:00:49\n",
      "     --- ------------------------------------ 0.2/2.7 GB 50.4 MB/s eta 0:00:49\n",
      "     --- ------------------------------------ 0.2/2.7 GB 50.4 MB/s eta 0:00:49\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.8 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.2/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.5 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.8 MB/s eta 0:00:41\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.8 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:45\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:45\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.4 MB/s eta 0:00:45\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.4 MB/s eta 0:00:44\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:44\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:44\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:44\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.4 MB/s eta 0:00:44\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:44\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:44\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:44\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 54.7 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 54.4 MB/s eta 0:00:44\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 54.4 MB/s eta 0:00:44\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 59.8 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.7 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.7 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 50.4 MB/s eta 0:00:47\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 50.4 MB/s eta 0:00:47\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.7 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 50.4 MB/s eta 0:00:46\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.7 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.7 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:39\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:39\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:43\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 50.1 MB/s eta 0:00:46\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 46.9 MB/s eta 0:00:49\n",
      "     ------ --------------------------------- 0.4/2.7 GB 43.7 MB/s eta 0:00:53\n",
      "     ------ --------------------------------- 0.4/2.7 GB 46.7 MB/s eta 0:00:49\n",
      "     ------ --------------------------------- 0.4/2.7 GB 50.4 MB/s eta 0:00:46\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 50.4 MB/s eta 0:00:46\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 50.1 MB/s eta 0:00:46\n",
      "     ------ --------------------------------- 0.4/2.7 GB 50.4 MB/s eta 0:00:46\n",
      "     ------ --------------------------------- 0.4/2.7 GB 46.9 MB/s eta 0:00:49\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.7 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.7 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------ --------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------ --------------------------------- 0.4/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.4 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:41\n",
      "     ------ --------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------ --------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:41\n",
      "     ------ --------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------ --------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------ --------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.8 MB/s eta 0:00:38\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:38\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 50.4 MB/s eta 0:00:44\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:40\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:40\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:40\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.7 MB/s eta 0:00:40\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.4 MB/s eta 0:00:40\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.8 MB/s eta 0:00:37\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     ------- -------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     ------- -------------------------------- 0.5/2.7 GB 65.6 MB/s eta 0:00:33\n",
      "     -------- ------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     -------- ------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     -------- ------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     -------- ------------------------------- 0.5/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     -------- ------------------------------- 0.6/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     -------- ------------------------------- 0.6/2.7 GB 59.5 MB/s eta 0:00:37\n",
      "     -------- ------------------------------- 0.6/2.7 GB 59.5 MB/s eta 0:00:36\n",
      "     -------- ------------------------------- 0.6/2.7 GB 59.8 MB/s eta 0:00:36\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.7 MB/s eta 0:00:40\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.4 MB/s eta 0:00:40\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.4 MB/s eta 0:00:40\n",
      "     -------- ------------------------------- 0.6/2.7 GB 38.5 MB/s eta 0:00:56\n",
      "     -------- ------------------------------- 0.6/2.7 GB 38.5 MB/s eta 0:00:56\n",
      "     -------- ------------------------------- 0.6/2.7 GB 27.3 MB/s eta 0:01:18\n",
      "     -------- ------------------------------- 0.6/2.7 GB 24.2 MB/s eta 0:01:28\n",
      "     -------- ------------------------------- 0.6/2.7 GB 25.2 MB/s eta 0:01:25\n",
      "     -------- ------------------------------- 0.6/2.7 GB 24.2 MB/s eta 0:01:28\n",
      "     -------- ------------------------------- 0.6/2.7 GB 23.4 MB/s eta 0:01:31\n",
      "     -------- ------------------------------- 0.6/2.7 GB 23.4 MB/s eta 0:01:31\n",
      "     -------- ------------------------------- 0.6/2.7 GB 50.4 MB/s eta 0:00:42\n",
      "     -------- ------------------------------- 0.6/2.7 GB 46.7 MB/s eta 0:00:46\n",
      "     -------- ------------------------------- 0.6/2.7 GB 50.4 MB/s eta 0:00:42\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.4 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 59.5 MB/s eta 0:00:36\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.4 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 59.5 MB/s eta 0:00:36\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.5 MB/s eta 0:00:36\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.5 MB/s eta 0:00:36\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.7 MB/s eta 0:00:39\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.7 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.6/2.7 GB 50.4 MB/s eta 0:00:42\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.4 MB/s eta 0:00:39\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.4 MB/s eta 0:00:39\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.4 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.4 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.7 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.8 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.6/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.8 MB/s eta 0:00:34\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 59.5 MB/s eta 0:00:35\n",
      "     --------- ------------------------------ 0.7/2.7 GB 54.4 MB/s eta 0:00:38\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 54.4 MB/s eta 0:00:38\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 54.4 MB/s eta 0:00:38\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 54.4 MB/s eta 0:00:38\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 54.4 MB/s eta 0:00:37\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.8 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.8 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 54.7 MB/s eta 0:00:37\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.8 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.7/2.7 GB 59.8 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.7/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.7/2.7 GB 54.7 MB/s eta 0:00:36\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 54.4 MB/s eta 0:00:36\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 54.4 MB/s eta 0:00:36\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 54.4 MB/s eta 0:00:36\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.8 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 54.7 MB/s eta 0:00:36\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.8 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.8 MB/s eta 0:00:32\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 54.4 MB/s eta 0:00:35\n",
      "     ------------ --------------------------- 0.8/2.7 GB 54.7 MB/s eta 0:00:35\n",
      "     ------------ --------------------------- 0.8/2.7 GB 54.4 MB/s eta 0:00:35\n",
      "     ------------ --------------------------- 0.8/2.7 GB 54.4 MB/s eta 0:00:35\n",
      "     ------------ --------------------------- 0.8/2.7 GB 54.7 MB/s eta 0:00:35\n",
      "     ------------ --------------------------- 0.8/2.7 GB 54.7 MB/s eta 0:00:35\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.8 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 0.8/2.7 GB 59.5 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.8/2.7 GB 54.7 MB/s eta 0:00:34\n",
      "     ------------ --------------------------- 0.9/2.7 GB 59.8 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 0.9/2.7 GB 54.4 MB/s eta 0:00:34\n",
      "     ------------ --------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 0.9/2.7 GB 65.6 MB/s eta 0:00:28\n",
      "     ------------ --------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 0.9/2.7 GB 59.8 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 54.4 MB/s eta 0:00:34\n",
      "     ------------- -------------------------- 0.9/2.7 GB 54.4 MB/s eta 0:00:34\n",
      "     ------------- -------------------------- 0.9/2.7 GB 54.4 MB/s eta 0:00:34\n",
      "     ------------- -------------------------- 0.9/2.7 GB 54.7 MB/s eta 0:00:33\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 54.7 MB/s eta 0:00:33\n",
      "     ------------- -------------------------- 0.9/2.7 GB 50.4 MB/s eta 0:00:36\n",
      "     ------------- -------------------------- 0.9/2.7 GB 50.4 MB/s eta 0:00:36\n",
      "     ------------- -------------------------- 0.9/2.7 GB 50.4 MB/s eta 0:00:36\n",
      "     ------------- -------------------------- 0.9/2.7 GB 65.2 MB/s eta 0:00:28\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.8 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 50.4 MB/s eta 0:00:36\n",
      "     ------------- -------------------------- 0.9/2.7 GB 50.4 MB/s eta 0:00:36\n",
      "     ------------- -------------------------- 0.9/2.7 GB 50.4 MB/s eta 0:00:36\n",
      "     ------------- -------------------------- 0.9/2.7 GB 50.4 MB/s eta 0:00:36\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 0.9/2.7 GB 59.8 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 0.9/2.7 GB 54.7 MB/s eta 0:00:33\n",
      "     -------------- ------------------------- 0.9/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 0.9/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 50.4 MB/s eta 0:00:35\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 50.4 MB/s eta 0:00:35\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.4 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.4 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 50.4 MB/s eta 0:00:35\n",
      "     -------------- ------------------------- 1.0/2.7 GB 50.4 MB/s eta 0:00:35\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 54.7 MB/s eta 0:00:32\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     --------------- ------------------------ 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     --------------- ------------------------ 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     --------------- ------------------------ 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     --------------- ------------------------ 1.0/2.7 GB 54.7 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 54.7 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 54.7 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 54.7 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 59.5 MB/s eta 0:00:29\n",
      "     --------------- ------------------------ 1.0/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.0/2.7 GB 54.4 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 54.4 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 54.7 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.0/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.0/2.7 GB 65.6 MB/s eta 0:00:26\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     --------------- ------------------------ 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     --------------- ------------------------ 1.1/2.7 GB 54.7 MB/s eta 0:00:30\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     --------------- ------------------------ 1.1/2.7 GB 59.8 MB/s eta 0:00:28\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 65.6 MB/s eta 0:00:25\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:28\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.8 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.4 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.7 MB/s eta 0:00:29\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.5 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.8 MB/s eta 0:00:27\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 54.7 MB/s eta 0:00:29\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 50.1 MB/s eta 0:00:32\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 38.5 MB/s eta 0:00:41\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 38.5 MB/s eta 0:00:41\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 38.5 MB/s eta 0:00:41\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 40.9 MB/s eta 0:00:39\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 65.2 MB/s eta 0:00:24\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 59.8 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.1/2.7 GB 54.7 MB/s eta 0:00:29\n",
      "     ----------------- ---------------------- 1.1/2.7 GB 50.4 MB/s eta 0:00:31\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 50.4 MB/s eta 0:00:31\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 50.4 MB/s eta 0:00:31\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 54.4 MB/s eta 0:00:29\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.8 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.8 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 54.7 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 54.4 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 54.7 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:26\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 54.4 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.8 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 54.7 MB/s eta 0:00:28\n",
      "     ------------------ --------------------- 1.2/2.7 GB 54.7 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.2/2.7 GB 54.7 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.2/2.7 GB 54.4 MB/s eta 0:00:28\n",
      "     ------------------ --------------------- 1.2/2.7 GB 54.4 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.8 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.8 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.2/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.8 MB/s eta 0:00:24\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:25\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------ --------------------- 1.3/2.7 GB 54.7 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.3/2.7 GB 54.4 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 65.6 MB/s eta 0:00:22\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.8 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.8 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     ------------------- -------------------- 1.3/2.7 GB 54.4 MB/s eta 0:00:26\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.8 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.3/2.7 GB 65.6 MB/s eta 0:00:21\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.4 MB/s eta 0:00:25\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.4 MB/s eta 0:00:25\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.4 MB/s eta 0:00:25\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.8 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.7 MB/s eta 0:00:25\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.4 MB/s eta 0:00:25\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.7 MB/s eta 0:00:24\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.7 MB/s eta 0:00:24\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.7 MB/s eta 0:00:24\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.4 MB/s eta 0:00:24\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     -------------------- ------------------- 1.4/2.7 GB 54.4 MB/s eta 0:00:24\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     -------------------- ------------------- 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.8 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 54.7 MB/s eta 0:00:24\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 54.4 MB/s eta 0:00:24\n",
      "     --------------------- ------------------ 1.4/2.7 GB 54.4 MB/s eta 0:00:24\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.8 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.4/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 54.4 MB/s eta 0:00:23\n",
      "     --------------------- ------------------ 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 54.7 MB/s eta 0:00:23\n",
      "     --------------------- ------------------ 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 59.8 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 54.4 MB/s eta 0:00:23\n",
      "     --------------------- ------------------ 1.5/2.7 GB 65.6 MB/s eta 0:00:19\n",
      "     --------------------- ------------------ 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 65.6 MB/s eta 0:00:19\n",
      "     --------------------- ------------------ 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.8 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.7 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.7 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.4 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.4 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.4 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.8 MB/s eta 0:00:20\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.4 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 43.7 MB/s eta 0:00:28\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 36.4 MB/s eta 0:00:33\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 32.7 MB/s eta 0:00:37\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 26.2 MB/s eta 0:00:46\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 26.2 MB/s eta 0:00:46\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 25.2 MB/s eta 0:00:47\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 25.1 MB/s eta 0:00:47\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 25.1 MB/s eta 0:00:47\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.7 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.7 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 50.4 MB/s eta 0:00:24\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.7 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.4 MB/s eta 0:00:22\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 54.7 MB/s eta 0:00:21\n",
      "     ----------------------- ---------------- 1.5/2.7 GB 54.7 MB/s eta 0:00:21\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 54.7 MB/s eta 0:00:21\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 54.4 MB/s eta 0:00:21\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.8 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 54.7 MB/s eta 0:00:21\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 54.4 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 54.4 MB/s eta 0:00:20\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:19\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.8 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.6/2.7 GB 54.4 MB/s eta 0:00:20\n",
      "     ------------------------ --------------- 1.6/2.7 GB 54.4 MB/s eta 0:00:20\n",
      "     ------------------------ --------------- 1.6/2.7 GB 54.4 MB/s eta 0:00:20\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.8 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 54.7 MB/s eta 0:00:20\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 54.7 MB/s eta 0:00:19\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:17\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.7 MB/s eta 0:00:19\n",
      "     ------------------------- -------------- 1.7/2.7 GB 43.7 MB/s eta 0:00:24\n",
      "     ------------------------- -------------- 1.7/2.7 GB 46.7 MB/s eta 0:00:22\n",
      "     ------------------------- -------------- 1.7/2.7 GB 38.5 MB/s eta 0:00:27\n",
      "     ------------------------- -------------- 1.7/2.7 GB 36.3 MB/s eta 0:00:28\n",
      "     ------------------------- -------------- 1.7/2.7 GB 36.4 MB/s eta 0:00:28\n",
      "     ------------------------- -------------- 1.7/2.7 GB 36.4 MB/s eta 0:00:28\n",
      "     ------------------------- -------------- 1.7/2.7 GB 50.4 MB/s eta 0:00:20\n",
      "     ------------------------- -------------- 1.7/2.7 GB 43.7 MB/s eta 0:00:23\n",
      "     ------------------------- -------------- 1.7/2.7 GB 40.9 MB/s eta 0:00:25\n",
      "     ------------------------- -------------- 1.7/2.7 GB 38.5 MB/s eta 0:00:26\n",
      "     ------------------------- -------------- 1.7/2.7 GB 38.5 MB/s eta 0:00:26\n",
      "     ------------------------- -------------- 1.7/2.7 GB 34.4 MB/s eta 0:00:29\n",
      "     ------------------------- -------------- 1.7/2.7 GB 36.4 MB/s eta 0:00:28\n",
      "     ------------------------- -------------- 1.7/2.7 GB 38.6 MB/s eta 0:00:26\n",
      "     ------------------------- -------------- 1.7/2.7 GB 40.9 MB/s eta 0:00:25\n",
      "     ------------------------- -------------- 1.7/2.7 GB 43.7 MB/s eta 0:00:23\n",
      "     ------------------------- -------------- 1.7/2.7 GB 50.4 MB/s eta 0:00:20\n",
      "     ------------------------- -------------- 1.7/2.7 GB 46.7 MB/s eta 0:00:21\n",
      "     ------------------------- -------------- 1.7/2.7 GB 50.4 MB/s eta 0:00:20\n",
      "     ------------------------- -------------- 1.7/2.7 GB 50.4 MB/s eta 0:00:20\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.4 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.4 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.4 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.7 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.7 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:17\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.7 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 59.5 MB/s eta 0:00:16\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.4 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 54.7 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.8/2.7 GB 50.4 MB/s eta 0:00:19\n",
      "     ------------------------- -------------- 1.8/2.7 GB 43.5 MB/s eta 0:00:22\n",
      "     -------------------------- ------------- 1.8/2.7 GB 38.5 MB/s eta 0:00:25\n",
      "     -------------------------- ------------- 1.8/2.7 GB 34.4 MB/s eta 0:00:28\n",
      "     -------------------------- ------------- 1.8/2.7 GB 32.8 MB/s eta 0:00:29\n",
      "     -------------------------- ------------- 1.8/2.7 GB 29.8 MB/s eta 0:00:32\n",
      "     -------------------------- ------------- 1.8/2.7 GB 28.5 MB/s eta 0:00:33\n",
      "     -------------------------- ------------- 1.8/2.7 GB 27.3 MB/s eta 0:00:35\n",
      "     -------------------------- ------------- 1.8/2.7 GB 27.3 MB/s eta 0:00:35\n",
      "     -------------------------- ------------- 1.8/2.7 GB 31.2 MB/s eta 0:00:30\n",
      "     -------------------------- ------------- 1.8/2.7 GB 32.7 MB/s eta 0:00:29\n",
      "     -------------------------- ------------- 1.8/2.7 GB 36.3 MB/s eta 0:00:26\n",
      "     -------------------------- ------------- 1.8/2.7 GB 38.6 MB/s eta 0:00:25\n",
      "     -------------------------- ------------- 1.8/2.7 GB 40.9 MB/s eta 0:00:23\n",
      "     -------------------------- ------------- 1.8/2.7 GB 43.7 MB/s eta 0:00:22\n",
      "     -------------------------- ------------- 1.8/2.7 GB 46.7 MB/s eta 0:00:20\n",
      "     -------------------------- ------------- 1.8/2.7 GB 46.7 MB/s eta 0:00:20\n",
      "     -------------------------- ------------- 1.8/2.7 GB 50.4 MB/s eta 0:00:19\n",
      "     -------------------------- ------------- 1.8/2.7 GB 50.4 MB/s eta 0:00:19\n",
      "     -------------------------- ------------- 1.8/2.7 GB 54.4 MB/s eta 0:00:17\n",
      "     -------------------------- ------------- 1.8/2.7 GB 54.4 MB/s eta 0:00:17\n",
      "     -------------------------- ------------- 1.8/2.7 GB 54.4 MB/s eta 0:00:17\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.5 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.8 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.5 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.5 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     -------------------------- ------------- 1.8/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     -------------------------- ------------- 1.8/2.7 GB 54.4 MB/s eta 0:00:17\n",
      "     -------------------------- ------------- 1.8/2.7 GB 54.7 MB/s eta 0:00:17\n",
      "     -------------------------- ------------- 1.8/2.7 GB 54.7 MB/s eta 0:00:17\n",
      "     --------------------------- ------------ 1.8/2.7 GB 54.7 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.8/2.7 GB 54.7 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.8/2.7 GB 54.4 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.8/2.7 GB 54.4 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.8/2.7 GB 54.4 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.8/2.7 GB 54.4 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.8/2.7 GB 59.8 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.8/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.8/2.7 GB 54.7 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.8/2.7 GB 59.8 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.8/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.9/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.9/2.7 GB 59.5 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.9/2.7 GB 54.4 MB/s eta 0:00:16\n",
      "     --------------------------- ------------ 1.9/2.7 GB 50.4 MB/s eta 0:00:17\n",
      "     --------------------------- ------------ 1.9/2.7 GB 50.4 MB/s eta 0:00:17\n",
      "     --------------------------- ------------ 1.9/2.7 GB 46.7 MB/s eta 0:00:18\n",
      "     --------------------------- ------------ 1.9/2.7 GB 50.4 MB/s eta 0:00:17\n",
      "     --------------------------- ------------ 1.9/2.7 GB 50.4 MB/s eta 0:00:17\n",
      "     --------------------------- ------------ 1.9/2.7 GB 46.7 MB/s eta 0:00:18\n",
      "     --------------------------- ------------ 1.9/2.7 GB 43.7 MB/s eta 0:00:19\n",
      "     --------------------------- ------------ 1.9/2.7 GB 43.7 MB/s eta 0:00:19\n",
      "     --------------------------- ------------ 1.9/2.7 GB 43.5 MB/s eta 0:00:19\n",
      "     --------------------------- ------------ 1.9/2.7 GB 40.9 MB/s eta 0:00:21\n",
      "     --------------------------- ------------ 1.9/2.7 GB 46.7 MB/s eta 0:00:18\n",
      "     --------------------------- ------------ 1.9/2.7 GB 50.4 MB/s eta 0:00:17\n",
      "     --------------------------- ------------ 1.9/2.7 GB 54.7 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.9/2.7 GB 54.7 MB/s eta 0:00:15\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 50.4 MB/s eta 0:00:17\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 46.9 MB/s eta 0:00:18\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 46.7 MB/s eta 0:00:18\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.7 MB/s eta 0:00:19\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 40.9 MB/s eta 0:00:20\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 38.5 MB/s eta 0:00:21\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 38.5 MB/s eta 0:00:21\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.5 MB/s eta 0:00:19\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.7 MB/s eta 0:00:19\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.7 MB/s eta 0:00:19\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.7 MB/s eta 0:00:19\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.7 MB/s eta 0:00:18\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.7 MB/s eta 0:00:18\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 43.5 MB/s eta 0:00:18\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 46.7 MB/s eta 0:00:17\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 46.7 MB/s eta 0:00:17\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 50.4 MB/s eta 0:00:16\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 50.4 MB/s eta 0:00:16\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 50.4 MB/s eta 0:00:16\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 54.7 MB/s eta 0:00:15\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 50.4 MB/s eta 0:00:16\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 50.4 MB/s eta 0:00:16\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 54.7 MB/s eta 0:00:14\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 59.8 MB/s eta 0:00:13\n",
      "     ---------------------------- ----------- 2.0/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ---------------------------- ----------- 2.0/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.4 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:12\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:12\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.4 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:12\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.5 MB/s eta 0:00:12\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 50.4 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 46.7 MB/s eta 0:00:15\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 50.4 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 50.4 MB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.4 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.4 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 54.7 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.0/2.7 GB 59.5 MB/s eta 0:00:12\n",
      "     ------------------------------ --------- 2.0/2.7 GB 50.4 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.0/2.7 GB 46.7 MB/s eta 0:00:15\n",
      "     ------------------------------ --------- 2.0/2.7 GB 46.7 MB/s eta 0:00:15\n",
      "     ------------------------------ --------- 2.0/2.7 GB 54.7 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.0/2.7 GB 46.7 MB/s eta 0:00:15\n",
      "     ------------------------------ --------- 2.0/2.7 GB 38.5 MB/s eta 0:00:18\n",
      "     ------------------------------ --------- 2.0/2.7 GB 34.4 MB/s eta 0:00:20\n",
      "     ------------------------------ --------- 2.0/2.7 GB 29.7 MB/s eta 0:00:23\n",
      "     ------------------------------ --------- 2.0/2.7 GB 28.5 MB/s eta 0:00:24\n",
      "     ------------------------------ --------- 2.0/2.7 GB 25.2 MB/s eta 0:00:27\n",
      "     ------------------------------ --------- 2.0/2.7 GB 25.2 MB/s eta 0:00:27\n",
      "     ------------------------------ --------- 2.0/2.7 GB 23.4 MB/s eta 0:00:29\n",
      "     ------------------------------ --------- 2.0/2.7 GB 23.4 MB/s eta 0:00:29\n",
      "     ------------------------------ --------- 2.0/2.7 GB 22.6 MB/s eta 0:00:29\n",
      "     ------------------------------ --------- 2.0/2.7 GB 43.5 MB/s eta 0:00:15\n",
      "     ------------------------------ --------- 2.0/2.7 GB 43.5 MB/s eta 0:00:15\n",
      "     ------------------------------ --------- 2.0/2.7 GB 46.9 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 43.7 MB/s eta 0:00:15\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.7 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.7 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.7 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.7 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.7 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.7 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.9 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 46.9 MB/s eta 0:00:14\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------ --------- 2.1/2.7 GB 50.4 MB/s eta 0:00:13\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.4 MB/s eta 0:00:12\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.4 MB/s eta 0:00:12\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.8 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.7 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.7 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.7 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 54.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 50.4 MB/s eta 0:00:12\n",
      "     ------------------------------- -------- 2.1/2.7 GB 50.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 50.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 50.4 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.2/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.2/2.7 GB 54.4 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 59.5 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 59.5 MB/s eta 0:00:09\n",
      "     -------------------------------- ------- 2.2/2.7 GB 65.2 MB/s eta 0:00:09\n",
      "     -------------------------------- ------- 2.2/2.7 GB 65.2 MB/s eta 0:00:09\n",
      "     -------------------------------- ------- 2.2/2.7 GB 65.6 MB/s eta 0:00:08\n",
      "     -------------------------------- ------- 2.2/2.7 GB 65.6 MB/s eta 0:00:08\n",
      "     -------------------------------- ------- 2.2/2.7 GB 65.6 MB/s eta 0:00:08\n",
      "     -------------------------------- ------- 2.2/2.7 GB 59.5 MB/s eta 0:00:09\n",
      "     -------------------------------- ------- 2.2/2.7 GB 54.4 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 54.4 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 38.5 MB/s eta 0:00:14\n",
      "     -------------------------------- ------- 2.2/2.7 GB 36.3 MB/s eta 0:00:15\n",
      "     -------------------------------- ------- 2.2/2.7 GB 36.4 MB/s eta 0:00:14\n",
      "     -------------------------------- ------- 2.2/2.7 GB 38.6 MB/s eta 0:00:14\n",
      "     -------------------------------- ------- 2.2/2.7 GB 38.6 MB/s eta 0:00:14\n",
      "     -------------------------------- ------- 2.2/2.7 GB 54.7 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 50.4 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 43.5 MB/s eta 0:00:12\n",
      "     -------------------------------- ------- 2.2/2.7 GB 40.9 MB/s eta 0:00:13\n",
      "     -------------------------------- ------- 2.2/2.7 GB 38.5 MB/s eta 0:00:13\n",
      "     -------------------------------- ------- 2.2/2.7 GB 40.9 MB/s eta 0:00:13\n",
      "     -------------------------------- ------- 2.2/2.7 GB 40.9 MB/s eta 0:00:12\n",
      "     -------------------------------- ------- 2.2/2.7 GB 40.9 MB/s eta 0:00:12\n",
      "     -------------------------------- ------- 2.2/2.7 GB 43.7 MB/s eta 0:00:12\n",
      "     -------------------------------- ------- 2.2/2.7 GB 43.7 MB/s eta 0:00:12\n",
      "     -------------------------------- ------- 2.2/2.7 GB 43.7 MB/s eta 0:00:12\n",
      "     -------------------------------- ------- 2.2/2.7 GB 43.7 MB/s eta 0:00:11\n",
      "     -------------------------------- ------- 2.2/2.7 GB 43.7 MB/s eta 0:00:11\n",
      "     -------------------------------- ------- 2.2/2.7 GB 46.7 MB/s eta 0:00:11\n",
      "     -------------------------------- ------- 2.2/2.7 GB 50.4 MB/s eta 0:00:10\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.4 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.7 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.7 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.7 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.7 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.4 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.4 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.4 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.4 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 54.7 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.3/2.7 GB 54.7 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.5 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.8 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.5 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.5 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.5 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.5 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 54.4 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 50.4 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.3/2.7 GB 50.1 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.3/2.7 GB 50.4 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.3/2.7 GB 54.7 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 54.7 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 54.7 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     --------------------------------- ------ 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.8 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 54.7 MB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 54.7 MB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 54.7 MB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 54.7 MB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 54.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 54.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 54.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.8 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 59.8 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.8 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.8 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.8 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 59.8 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 54.4 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.8 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.8 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.8 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.8 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 54.4 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.8 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 54.7 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 65.6 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 65.6 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.6/2.7 GB 72.6 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.6/2.7 GB 73.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.6/2.7 GB 65.6 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 65.6 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 59.5 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.4 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.4 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.4 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.4 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 50.4 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 38.5 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 34.4 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.6/2.7 GB 31.2 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.6/2.7 GB 26.2 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.6/2.7 GB 25.2 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.6/2.7 GB 24.2 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.6/2.7 GB 23.4 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.6/2.7 GB 23.4 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.6/2.7 GB 46.7 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 50.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 50.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 50.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 59.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 59.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.7 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 50.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 50.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 54.4 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.6/2.7 GB 54.7 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.6/2.7 GB 59.5 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.6/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.6/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.6/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.6/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.6/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.6/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 54.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 54.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 54.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 54.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.7/2.7 GB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1\n",
      "    Uninstalling torch-2.4.1:\n",
      "      Successfully uninstalled torch-2.4.1\n",
      "Successfully installed torch-2.4.1+cu118 torchaudio-2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c6cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers accelerate optimum vllm llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477eedad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.50.3\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from transformers==4.50.3) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from transformers==4.50.3) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (2021.11.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (0.31.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers==4.50.3) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (2024.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers==4.50.3) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers==4.50.3) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers==4.50.3) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers==4.50.3) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers==4.50.3) (1.26.20)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed transformers-4.50.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.50.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8169fc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\danie\\anaconda5\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\danie\\anaconda5\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\danie\\anaconda5\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from accelerate) (2.4.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=2.0.0->accelerate) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\anaconda5\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859b833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\n",
      "  Using cached optimum-1.24.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: transformers>=4.29 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from optimum) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from optimum) (2.4.1+cu118)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\anaconda5\\lib\\site-packages (from optimum) (23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from optimum) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from optimum) (0.30.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.11->optimum) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.11->optimum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.11->optimum) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.11->optimum) (69.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers>=4.29->optimum) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers>=4.29->optimum) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers>=4.29->optimum) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\anaconda5\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.8.0->optimum) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from jinja2->torch>=1.11->optimum) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from sympy->torch>=1.11->optimum) (1.3.0)\n",
      "Using cached optimum-1.24.0-py3-none-any.whl (433 kB)\n",
      "Installing collected packages: optimum\n",
      "Successfully installed optimum-1.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721a48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vllm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "236a161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 510\n"
     ]
    }
   ],
   "source": [
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c65127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Using cached llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from llama-cpp-python) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp312-cp312-win_amd64.whl size=4882383 sha256=4cdb2048c1cb9a0aa6531a7b142248b98b3b405e3b7e7fb176be6b6a0b2d64ab\n",
      "  Stored in directory: c:\\users\\danie\\appdata\\local\\pip\\cache\\wheels\\e4\\16\\e0\\1a8e6feea862ac9be1cc74654663a567fafa55caa19329785f\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60580ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the PyTorch version\n",
    "torch_version = torch.__version__\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"PyTorch version: {torch_version}\")\n",
    "print(f\"CUDA available: {cuda_available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49956193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2afa2ce5904590b61408cb8d61be9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Path to the cloned model directory\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a07e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the key financial risks in SEC filings?\n",
      "\n",
      "The SEC requires companies to disclose the most significant risks and uncertainties that could affect their business. These risks are typically categorized into three main categories: financial, operational, and legal.\n",
      "\n",
      "Financial risks are those that could affect a company’s ability to generate revenue or profit. These risks can include changes in interest rates, currency fluctuations, and changes in the economy.\n",
      "\n",
      "Operational risks are those that could affect a company’s ability to deliver its products or services. These risks can include changes in technology, changes in customer demand, and changes in the competitive landscape.\n",
      "\n",
      "Legal risks are those that could affect a company’s ability to comply with laws and regulations. These risks can include changes in the law, changes in the regulatory environment, and changes in the political landscape.\n",
      "\n",
      "## What are the key financial risks in SEC filings?\n",
      "\n",
      "The SEC requires companies to disclose the most significant risks and uncertainties that could affect their business. These risks are typically categorized into three main categories: financial, operational, and legal.\n",
      "\n",
      "Financial risks are those that could affect a company’s ability to generate revenue or profit. These risks can include changes in interest rates, currency fluctuations,\n",
      "Time taken: 108.66815185546875 sec\n"
     ]
    }
   ],
   "source": [
    "##Pre-emptive test##\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "prompt = \"What are the key financial risks in SEC filings?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(**inputs, max_new_tokens=256, temperature=0.6)\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "print(f\"Time taken: {time.time() - start_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10cab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Generate output\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Measure time taken for inference\u001b[39;00m\n\u001b[0;32m     24\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\transformers\\generation\\utils.py:2326\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[0;32m   2318\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2319\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2320\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2321\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2322\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2323\u001b[0m     )\n\u001b[0;32m   2325\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2326\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2331\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2337\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2339\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2340\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2341\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2342\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2343\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\transformers\\generation\\utils.py:3289\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3287\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3289\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3291\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3292\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3293\u001b[0m     outputs,\n\u001b[0;32m   3294\u001b[0m     model_kwargs,\n\u001b[0;32m   3295\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3296\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\accelerate\\hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:842\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m--> 842\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    856\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:566\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    555\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    556\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    563\u001b[0m         position_embeddings,\n\u001b[0;32m    564\u001b[0m     )\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 566\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\accelerate\\hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:247\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\accelerate\\hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:163\u001b[0m, in \u001b[0;36mMistralAttention.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m    162\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 163\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    164\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    166\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\accelerate\\hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# too long ##\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test prompt\n",
    "prompt = \"What are the key financial risks in SEC filings?\"\n",
    "\n",
    "# Initialize lists to store performance data\n",
    "time_taken_list = []\n",
    "tokens_per_second_list = []\n",
    "\n",
    "# Run multiple tests to gather data for graph\n",
    "num_tests = 10  # Number of tests to run\n",
    "for _ in range(num_tests):\n",
    "    # Start benchmarking\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    output = model.generate(**inputs, max_new_tokens=256)\n",
    "\n",
    "    # Measure time taken for inference\n",
    "    time_taken = time.time() - start_time\n",
    "    time_taken_list.append(time_taken)\n",
    "\n",
    "    # Calculate tokens per second (inference speed)\n",
    "    num_tokens = len(inputs[\"input_ids\"][0]) + 256  # Original input + generated tokens\n",
    "    tokens_per_second = num_tokens / time_taken\n",
    "    tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "# Plotting the performance data\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot time taken\n",
    "ax1.set_xlabel('Test Number')\n",
    "ax1.set_ylabel('Time Taken (sec)', color='tab:blue')\n",
    "ax1.plot(range(1, num_tests + 1), time_taken_list, color='tab:blue', label='Time Taken')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for tokens per second\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Tokens per Second', color='tab:green')\n",
    "ax2.plot(range(1, num_tests + 1), tokens_per_second_list, color='tab:green', label='Tokens per Second')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "\n",
    "# Title and grid\n",
    "plt.title('Inference Performance Benchmark (Time vs Tokens/sec)')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a638ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Test prompt\n",
    "prompt = \"What are the key financial risks in SEC filings?\"\n",
    "\n",
    "# Initialize lists to store performance data\n",
    "time_taken_list = []\n",
    "tokens_per_second_list = []\n",
    "\n",
    "# Number of test runs (reduce if slow)\n",
    "num_tests = 5  \n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Run multiple tests to gather data for graph\n",
    "for _ in range(num_tests):\n",
    "    # Start benchmarking\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate output (Disable gradients for speed-up)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=64)  # Reduced tokens\n",
    "\n",
    "    # Measure time taken for inference\n",
    "    time_taken = time.time() - start_time\n",
    "    time_taken_list.append(time_taken)\n",
    "\n",
    "    # Calculate tokens per second (inference speed)\n",
    "    num_tokens = len(inputs[\"input_ids\"][0]) + 64  # Adjusted for new token limit\n",
    "    tokens_per_second = num_tokens / time_taken\n",
    "    tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "# Plotting the performance data\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot time taken\n",
    "ax1.set_xlabel('Test Number')\n",
    "ax1.set_ylabel('Time Taken (sec)', color='tab:blue')\n",
    "ax1.plot(range(1, num_tests + 1), time_taken_list, color='tab:blue', marker='o', label='Time Taken')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for tokens per second\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Tokens per Second', color='tab:green')\n",
    "ax2.plot(range(1, num_tests + 1), tokens_per_second_list, color='tab:green', marker='s', label='Tokens per Second')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "\n",
    "# Title and grid\n",
    "plt.title('Inference Performance Benchmark (Optimized)')\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33d9cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (0.29.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from pandas->evaluate) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3b6b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score) (2.7.0+cu118)\n",
      "Requirement already satisfied: numpy in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from bert-score) (1.3.5)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score) (4.50.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.16.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.31.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2021.11.10)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score) (4.54.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score) (8.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->bert-score) (1.26.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->bert-score) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install bert-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ae930d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.27.1\n",
      "  Downloading levenshtein-0.27.1-cp39-cp39-win_amd64.whl (100 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0\n",
      "  Downloading rapidfuzz-3.13.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc2be481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: absl-py in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: click in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py): started\n",
      "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24991 sha256=44a503e1bd53c2a545462bdbc5cd6920f67c0fc983bfeb7e2422ac2276e701f6\n",
      "  Stored in directory: c:\\users\\danie\\appdata\\local\\pip\\cache\\wheels\\9b\\3d\\39\\09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge_score absl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "764285b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from python-docx) (4.12.2)\n",
      "Collecting lxml>=3.1.0\n",
      "  Downloading lxml-5.4.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "Installing collected packages: lxml, python-docx\n",
      "Successfully installed lxml-5.4.0 python-docx-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3384496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Perplexity: 51.06\n",
      "Average ROUGE Score: 0.2769\n",
      "Average BLEU Score: 0.1393\n",
      "Average Edit Distance: 322.00\n",
      "Average BERTScore: 0.3882\n",
      "Win Rate: 0.00%\n",
      "Average Token Throughput: 4.35 tokens/sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "import Levenshtein\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# Load evaluation metrics using the evaluate package\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Test prompt\n",
    "prompt = \"What are the key financial risks in SEC filings?\"\n",
    "\n",
    "# Initialize lists for performance metrics\n",
    "time_taken_list = []\n",
    "tokens_per_second_list = []\n",
    "perplexity_list = []\n",
    "rouge_scores = []\n",
    "bleu_scores = []\n",
    "edit_distance_list = []\n",
    "bert_score_list = []\n",
    "win_rate_list = []\n",
    "\n",
    "# Number of test runs\n",
    "num_tests = 5  \n",
    "win_threshold = 0.8  # BERTScore threshold for Win% calculation\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Run multiple tests to gather performance data\n",
    "for _ in range(num_tests):\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate output (Disable gradients for speed-up)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=64, temperature)\n",
    "\n",
    "    # Decode output\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Measure inference time\n",
    "    time_taken = time.time() - start_time\n",
    "    time_taken_list.append(time_taken)\n",
    "\n",
    "    # Compute tokens per second\n",
    "    num_tokens = len(inputs[\"input_ids\"][0]) + 64  # Adjusted for new token limit\n",
    "    tokens_per_second = num_tokens / time_taken\n",
    "    tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "    # Compute Perplexity (Corrected)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])  # Pass input_ids as labels for loss calculation\n",
    "        loss = outputs.loss  # Cross-entropy loss\n",
    "        perplexity = torch.exp(loss).item()  # Perplexity is the exponential of the loss\n",
    "        perplexity_list.append(perplexity)\n",
    "\n",
    "    # Compute ROUGE score using evaluate package\n",
    "    rouge_result = rouge.compute(predictions=[decoded_output], references=[prompt])\n",
    "    rouge_scores.append(rouge_result[\"rougeL\"])\n",
    "\n",
    "    # Compute BLEU score using evaluate package\n",
    "    bleu_result = bleu.compute(predictions=[decoded_output], references=[prompt])\n",
    "    bleu_scores.append(bleu_result[\"bleu\"])\n",
    "\n",
    "    # Compute Edit Distance\n",
    "    edit_distance = levenshtein_distance(decoded_output, prompt)\n",
    "    edit_distance_list.append(edit_distance)\n",
    "\n",
    "    # Compute BERTScore\n",
    "    P, R, F1 = bert_score([decoded_output], [prompt], lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_score_list.append(F1.mean().item())\n",
    "\n",
    "    # Compute Win Rate (if BERTScore > threshold, consider it a \"win\")\n",
    "    win_rate_list.append(1 if F1.mean().item() >= win_threshold else 0)\n",
    "\n",
    "# Plot Performance Data\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot time taken\n",
    "ax1.set_xlabel('Test Number')\n",
    "ax1.set_ylabel('Time Taken (sec)', color='tab:blue')\n",
    "ax1.plot(range(1, num_tests + 1), time_taken_list, color='tab:blue', marker='o', label='Time Taken')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for tokens per second\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Tokens per Second', color='tab:green')\n",
    "ax2.plot(range(1, num_tests + 1), tokens_per_second_list, color='tab:green', marker='s', label='Tokens per Second')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "\n",
    "plt.title('Inference Performance Benchmark')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display Performance Metrics\n",
    "print(f\"Average Perplexity: {sum(perplexity_list) / num_tests:.2f}\")\n",
    "print(f\"Average ROUGE Score: {sum(rouge_scores) / num_tests:.4f}\")\n",
    "print(f\"Average BLEU Score: {sum(bleu_scores) / num_tests:.4f}\")\n",
    "print(f\"Average Edit Distance: {sum(edit_distance_list) / num_tests:.2f}\")\n",
    "print(f\"Average BERTScore: {sum(bert_score_list) / num_tests:.4f}\")\n",
    "print(f\"Win Rate: {sum(win_rate_list) / num_tests * 100:.2f}%\")\n",
    "print(f\"Average Token Throughput: {sum(tokens_per_second_list) / num_tests:.2f} tokens/sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e350cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25af51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (2.6.0+cu118)\n",
      "Requirement already satisfied: transformers in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (1.5.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from peft) (0.29.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2024.8.30)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f05f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 4.5/12.9 MB 24.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.9 MB 26.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 24.4 MB/s eta 0:00:00\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: numpy, tensorboard, keras\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "Successfully installed keras-3.9.2 numpy-2.1.3 tensorboard-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\danie\\Downloads\\RFNet-4D-main\\.conda\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3118f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.10.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow==2.10.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63232450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (4.50.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (2.6.0+cu118)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers[torch]) (1.5.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435f7585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1a45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting panda\n",
      "  Downloading panda-0.3.1.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from panda) (78.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from panda) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->panda) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->panda) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->panda) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\downloads\\rfnet-4d-main\\.conda\\lib\\site-packages (from requests->panda) (2024.8.30)\n",
      "Building wheels for collected packages: panda\n",
      "  Building wheel for panda (setup.py): started\n",
      "  Building wheel for panda (setup.py): finished with status 'done'\n",
      "  Created wheel for panda: filename=panda-0.3.1-py3-none-any.whl size=7296 sha256=8eff690c224a7fcc427680d471f918c77c2644308ddbc4b69976f5bb3a46a2b9\n",
      "  Stored in directory: c:\\users\\danie\\appdata\\local\\pip\\cache\\wheels\\df\\5c\\39\\36f8dae25a1e88d6ec4411dec4a143781e64fdff6897758eec\n",
      "Successfully built panda\n",
      "Installing collected packages: panda\n",
      "Successfully installed panda-0.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install panda \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8416bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: dill in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from evaluate) (1.3.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2024.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.31.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\danie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "575507ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-win_amd64.whl (75.4 MB)\n",
      "   ---------------------------------------- 0.0/75.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/75.4 MB 1.3 MB/s eta 0:00:59\n",
      "   ---------------------------------------- 0.2/75.4 MB 2.3 MB/s eta 0:00:34\n",
      "    --------------------------------------- 1.2/75.4 MB 10.7 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 2.5/75.4 MB 15.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 4.7/75.4 MB 22.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 7.1/75.4 MB 28.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 9.9/75.4 MB 33.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 12.3/75.4 MB 50.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 14.7/75.4 MB 54.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 17.2/75.4 MB 54.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 20.0/75.4 MB 54.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 22.6/75.4 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 24.2/75.4 MB 50.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 27.0/75.4 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 28.9/75.4 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 31.9/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 33.4/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 36.0/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 38.5/75.4 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 40.9/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 43.5/75.4 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 45.6/75.4 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 48.3/75.4 MB 54.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 50.6/75.4 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 53.0/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 55.1/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 57.3/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 59.7/75.4 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 62.0/75.4 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 64.1/75.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 66.3/75.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 68.7/75.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 70.8/75.4 MB 46.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 73.0/75.4 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  75.4/75.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  75.4/75.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 75.4/75.4 MB 34.4 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c4be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': ['\"Item 8.01. Other Events.\\n\\nOn March 21, 2023, the Company entered into an agreement with its wholly-owned subsidiary, F5, Inc. (F5) to merge F5 with a subsidiary of the Company. The merger is expected to be completed in the second quarter of 2023, subject to the satisfaction of customary closing conditions, including the receipt of regulatory approvals from relevant authorities.\\n\\nThe merger consideration will be paid in cash, with the Company paying F5 stockholders approximately $4.4 billion, or $23.00 per share, in the aggregate. This price represents a premium of approximately 25% to the closing price of F5\\'s common stock on the trading day preceding the announcement of the merger. The merger consideration will be funded with the Company\\'s existing cash reserves, which totaled approximately $8.2 billion as of December 31, 2022. The Company has sufficient liquidity to fund the merger consideration and does not anticipate the need to raise additional debt or equity financing in connection with the transaction.\\n\\nIn addition to the merger consideration, the Company will also assume F5\\'s outstanding debt of approximately $1.4 billion, which consists of senior notes with a weighted average interest rate of 4.2% and a weighted average maturity of 7.3 years. The assumption of F5\\'s debt is expected to increase the Company\\'s total debt to approximately $6.5 billion, pro forma for the merger. However, the Company believes that the merger will generate significant cash flow synergies and improve its overall financial profile, enabling it to manage its increased debt burden effectively.\\n\\nThe merger is subject to customary closing conditions, including the receipt of regulatory approvals from the Federal Trade Commission (FTC) and the Department of Justice (DOJ) under the Hart-Scott-Rodino Antitrust Improvements Act (HSR Act). The Company has filed the required notifications with the FTC and DOJ and is cooperating with their review of the transaction. While there can be no assurance that the regulatory approvals will be obtained on a timely basis, or at all, the Company believes that the merger will not raise significant competitive concerns and expects to receive the necessary approvals within the anticipated timeframe.\\n\\nIn connection with the merger, the Company will file a Current Report on Form 8-K, which will include the merger agreement and related exhibits, with the Securities and Exchange Commission (the SEC). The merger agreement will provide additional details about the terms and conditions of the transaction, including the merger consideration, the assumption of F5\\'s debt, and the post-merger organizational structure. The Company will also file with the SEC a Current Report on Form 8-K announcing the closing of the merger, which will include updated financial information and other relevant details about the transaction.\\n\\nThe Company expects the merger to generate significant strategic and financial benefits, including enhanced scale and competitiveness, improved operational efficiency, and increased cash flow. The merger is also expected to create opportunities for growth and expansion in new markets and geographies, as well as increased investment in research and development, sales and marketing, and customer support. The Company is committed to ensuring a smooth transition and integration of F5\\'s business and operations, with minimal disruption to customers, employees, and other stakeholders.\"', '\", and to the extent that the financial markets and the capital structure of the Company and its subsidiaries are affected by the impact of the COVID-19 pandemic, the financial markets and the capital structure of the Company and its subsidiaries could be negatively impacted. This potential negative impact may be exacerbated by various factors, including, but not limited to, reduced investor confidence, increased volatility in the financial markets, and reduced access to capital.\\n\\nIn addition, the COVID-19 pandemic has had a significant impact on the global economy, including the Company’s customers, and the Company has experienced and may continue to experience significant disruptions to its global operations. These disruptions include, but are not limited to, supply chain disruptions, the inability to access certain of its facilities, including the inability to access the Company’s global headquarters, as well as to its customers and suppliers, including the inability to access the Company’s customers’ facilities. This has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers, potentially leading to delays, cancellations, or reductions in orders.\\n\\nThe COVID-19 pandemic has also resulted in and may continue to result in significant disruptions to the Company’s supply chain. These disruptions include, but are not limited to, the Company’s inability to obtain adequate supplies of certain raw materials and components, including, but not limited to, semiconductors. The pandemic has caused significant shortages of these critical components, leading to increased costs and reduced availability. Furthermore, the Company’s inability to obtain adequate supplies of certain manufacturing and production materials and supplies, including, but not limited to, manufacturing equipment and tooling, has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers.\\n\\nIn addition, the COVID-19 pandemic has resulted in and may continue to result in significant disruptions to the Company’s global operations. These disruptions include, but are not limited to, the inability of the Company’s employees to work at the Company’s facilities, including the inability of the Company’s employees to work at the Company’s global headquarters. This has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers. The pandemic has also forced the Company to adopt remote work arrangements, which may not be as effective as traditional in-person work arrangements, potentially leading to reduced productivity and efficiency.\\n\\nThe COVID-19 pandemic has also resulted in and may continue to result in significant disruptions to the Company’s ability to deliver products to its customers. These disruptions include, but are not limited to, the Company’s inability to deliver products to its customers in a timely manner. This has resulted in and may continue to result in significant delays, increased costs, and reduced customer satisfaction. Furthermore, the pandemic has caused significant disruptions to global logistics and transportation systems, leading to increased costs and reduced availability of shipping and delivery options.\\n\\nThe Company is actively working to mitigate the impacts of the COVID-19 pandemic on its global operations and supply chain. These efforts include, but are not limited to, implementing remote work arrangements, increasing inventory levels of critical components, and identifying alternative suppliers and logistics providers. However, the Company cannot guarantee that these efforts will be successful, and the COVID-19 pandemic may continue to have a significant impact on the Company’s ability to supply products to its customers.\\n\\nThe Company’s management is closely monitoring the situation and is taking all necessary steps to minimize the impact of the COVID-19 pandemic on the Company’s operations and financial performance. However, the extent to which the COVID-19 pandemic will impact the Company’s financial performance and operations will depend on various factors, including, but not limited to, the duration and severity of the pandemic, the impact of the pandemic on the global economy, and the effectiveness of the Company’s mitigation efforts. As a result, the Company cannot provide any assurance that the COVID-19 pandemic will not have a material adverse impact on its financial performance and operations.\\n\\nIn light of the significant uncertainties and risks associated with the COVID-19 pandemic, the Company is taking a cautious approach to its financial planning and budgeting. The Company is regularly reviewing and updating its financial projections and is prepared to take additional steps as necessary to mitigate the impacts of the pandemic on its financial performance and operations. However, the Company cannot guarantee that these efforts will be successful, and the COVID-19 pandemic may continue to have a significant impact on the Company’s financial performance and operations.\\n\\nThe Company will continue to closely monitor the situation and will provide updates as necessary. However, the Company cannot predict with certainty the extent to which the COVID-19 pandemic will impact its financial performance and operations, and the Company’s actual results may differ significantly from its current expectations.\"', '\"Item 8.01\\nDate: September 23, 2022\\n\\nExhibit 99.1\\n\\nContact:\\nMelissa Stephenson\\nPhone: (202) 508-8000\\nEmail: [mstephenson@usw.org](mailto:mstephenson@usw.org)\\n\\nOn September 23, 2022, United Steelworkers (the \"USW\") announced that it has entered into a tentative agreement with XYZ Steel Corporation (the \"Company\") regarding a new collective bargaining agreement covering approximately 4,500 hourly employees at the Company\\'s U.S. facilities.\\n\\nThe tentative agreement is subject to ratification by the USW membership and is scheduled to be voted on during the week of October 3, 2022. The agreement provides for significant wage and benefit improvements for USW-represented employees, including:\\n\\n*   Average annual wage increases of 4.5% over the term of the agreement\\n*   Enhanced retirement benefits, including a $1,000 increase in the monthly pension multiplier\\n*   Improved healthcare benefits, including reduced employee premiums and out-of-pocket costs\\n*   Enhanced safety and health provisions, including the creation of a joint union-management safety committee\\n\\nThe tentative agreement also includes provisions to support the long-term competitiveness of the Company\\'s U.S. operations, including:\\n\\n*   A commitment to invest $500 million in capital improvements at the Company\\'s U.S. facilities over the term of the agreement\\n*   The creation of a joint union-management productivity committee to identify and implement efficiency improvements\\n*   A provision to allow the Company to adjust its workforce in response to changes in market conditions, subject to certain restrictions and limitations\\n\\nThe USW and the Company have also agreed to establish a joint committee to explore opportunities for growth and development in the U.S. steel industry, including the potential for new investments and job creation.\\n\\nThe tentative agreement is the result of several months of negotiations between the USW and the Company, and we believe that it provides a fair and equitable resolution to the parties\\' differences. We are confident that the agreement will be ratified by the USW membership and look forward to working with the Company to implement its terms.\\n\\nExhibit 99.1 is a copy of the press release announcing the tentative agreement.\\n\\n Safe Harbor Statement\\n\\nThis report contains forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. Such statements are subject to risks and uncertainties that could cause actual results to differ materially from those expressed or implied. These risks and uncertainties include, but are not limited to, general economic and business conditions, changes in the competitive environment, and the Company\\'s ability to implement the terms of the tentative agreement.\\n\\nThe Company undertakes no obligation to update or revise any forward-looking statements to reflect new information or events.\\n\\nAbout the USW\\n\\nThe United Steelworkers (USW) is a North American union representing workers in a wide range of industries, including steel, aluminum, mining, and energy. The USW is committed to negotiating fair and equitable collective bargaining agreements that provide good wages, benefits, and working conditions for its members.\\n\\nAbout XYZ Steel Corporation\\n\\nXYZ Steel Corporation is a leading producer of steel and steel products in North America, with operations in the United States and Canada. The Company is committed to providing high-quality products and services to its customers while maintaining a safe and healthy work environment for its employees.\\n\\nInvestor Contact:\\nMelissa Stephenson\\nPhone: (202) 508-8000\\nEmail: [mstephenson@usw.org](mailto:mstephenson@usw.org)\\n\\nMedia Contact:\\nSarah Johnson\\nPhone: (202) 508-8000\\nEmail: [sjohnson@usw.org](mailto:sjohnson@usw.org)\"', '\"the Company’s financial condition, results of operations, and cash flows.\\n\\nThe Company has a significant amount of indebtedness, including the senior notes and the term loan. As of December 31, 2022, the Company\\'s total debt outstanding was $1.2 billion, consisting of $800 million in senior notes and $400 million in term loans. The Company’s level of indebtedness may have significant consequences, including:\\n\\n• making it more difficult for the Company to raise capital to fund its business, pay its debts, or meet working capital needs. The Company may be required to dedicate a substantial portion of its cash flows from operations to service its debt, which could limit its ability to invest in its business, respond to changes in the market, or take advantage of new opportunities;\\n\\n• increasing sensitivity to changes in interest rates and other market conditions, including the Company’s exposure to variable rate debt. As of December 31, 2022, approximately $600 million of the Company\\'s debt was subject to variable interest rates, which could result in increased interest expenses if interest rates rise;\\n\\n• making it more difficult for the Company to comply with financial covenants, including those related to leverage, interest coverage, and other financial ratios, contained in the Company’s debt agreements. The Company is required to maintain certain financial ratios, such as a debt-to-equity ratio of no more than 3.5:1 and an interest coverage ratio of at least 2.5:1, and failure to comply with these covenants could result in a default under its debt agreements;\\n\\n• subjecting the Company to the risk of default under its debt agreements, which could result in the acceleration of its debt. If the Company defaults under any of its debt agreements, the lenders may declare all outstanding debt to be immediately due and payable, which could have a material adverse effect on the Company\\'s financial condition and results of operations;\\n\\n• subjecting the Company to the risk of cross-default, which could result in the acceleration of the Company’s debt, including the senior notes and the term loan, if the Company defaults under any other agreement. The Company has various other agreements, such as lease agreements and supply contracts, that contain cross-default provisions, which could result in a default under its debt agreements if the Company defaults under any of these other agreements;\\n\\n• subjecting the Company to the risk of restrictions on its ability to make payments on its debt, including the senior notes and the term loan, or make certain investments or enter into certain transactions. The Company\\'s debt agreements contain various restrictions, such as limitations on the Company\\'s ability to make dividend payments, incur additional debt, or enter into certain mergers or acquisitions, which could limit the Company\\'s ability to take actions that it believes are in its best interests;\\n\\n• increasing the Company’s vulnerability to adverse economic or other changes in the Company’s business. The Company operates in a highly competitive industry and is subject to various economic and market risks, such as changes in consumer demand, fluctuations in raw material prices, and increased competition from new entrants in the market;\\n\\n• limiting the Company’s flexibility in planning for, or responding to, changes in the Company’s business or in the market. The Company\\'s debt agreements contain various restrictions that may limit its ability to respond to changes in the market or take advantage of new opportunities, such as limitations on its ability to incur additional debt or make certain investments;\\n\\n• placing the Company and its subsidiaries at risk of having the Company’s assets sold to satisfy the Company’s obligations under its debt agreements. If the Company defaults under its debt agreements, the lenders may have the right to foreclose on the Company\\'s assets, which could result in a material loss of value for the Company\\'s shareholders.\\n\\nThe Company’s ability to meet its debt service obligations depends on its future operating performance and financial position, which are subject to a number of risks, including those discussed in this Item 1A, and to general economic, competitive and other factors beyond the Company’s control. If the Company is unable to generate sufficient cash flow from its operations or if it is unable to access capital markets or other financing sources on acceptable terms, it may not be able to meet its debt service obligations.\\n\\nIn addition, the Company’s debt agreements contain certain restrictions on its ability to incur additional debt, pay dividends, make certain investments, enter into certain transactions, and transfer certain assets, among other restrictions. These restrictions could limit the Company’s ability to take actions that it believes are in its best interests. For example, the Company\\'s debt agreements contain provisions that limit its ability to incur additional debt, including a provision that requires the Company to maintain a debt-to-equity ratio of no more than 3.5:1.\\n\\nThe Company’s debt agreements also contain certain covenants that may limit the Company’s ability to engage in certain activities that may be in its best interests. For example, the Company\\'s debt agreements contain provisions that limit its ability to make certain investments, such as investments in joint ventures or strategic partnerships, which could limit the Company\\'s ability to grow its business or take advantage of new opportunities.\\n\\nFurthermore, the Company\\'s debt agreements contain provisions that require it to maintain certain financial ratios, such as an interest coverage ratio of at least 2.5:1, and to comply with certain other financial covenants. Failure to comply with these covenants could result in a default under the Company\\'s debt agreements, which could have a material adverse effect on the Company\\'s financial condition and results of operations.\\n\\nIn order to mitigate these risks, the Company regularly reviews its debt agreements and assesses its compliance with the various covenants and restrictions contained in these agreements. The Company also regularly reviews its financial position and cash flows to ensure that it has sufficient liquidity to meet its debt service obligations. In addition, the Company has implemented various financial management strategies, such as maintaining a cash reserve and diversifying its revenue streams, to reduce its vulnerability to adverse economic or other changes in its business.\\n\\nDespite these efforts, the Company\\'s level of indebtedness and the restrictions contained in its debt agreements may still have a material adverse effect on its financial condition and results of operations. The Company\\'s ability to meet its debt service obligations and comply with the covenants and restrictions contained in its debt agreements will depend on its future operating performance and financial position, which are subject to a number of risks and uncertainties.\"', 'Item 8.01 Other Events\\n\\nOn April 15, 2022, the Company entered into a settlement agreement (the \"Agreement\") with a former employee (the \"Former Employee\") to resolve a claim for damages and costs arising from the Former Employee\\'s alleged breach of the Company\\'s Confidential Information and Invention Assignment Agreement (the \"CIIA Agreement\"). The CIIA Agreement, which was executed by the Former Employee upon commencement of employment with the Company, obligates employees to maintain the confidentiality of Company proprietary information and to assign to the Company all inventions, discoveries, and ideas conceived or developed during the term of employment.\\n\\nThe settlement agreement provides for a payment of $400,000 to the Former Employee, which amount is included in the Company\\'s accrued liabilities on the balance sheet as of March 31, 2022. The Company has recorded this liability in accordance with Accounting Standards Codification (\"ASC\") 450, Contingencies, and has accrued the full amount of the settlement payment. The payment is expected to be made on or before May 15, 2022, and will be funded from the Company\\'s existing cash and cash equivalents.\\n\\nThe Agreement also contains a release of all claims by the Former Employee against the Company and its subsidiaries, including any claims arising from the Former Employee\\'s employment with the Company or the termination of such employment. The release includes, but is not limited to, claims for wrongful termination, breach of contract, and any claims arising under federal, state, or local employment laws. In addition, the Agreement includes a covenant not to sue, pursuant to which the Former Employee agrees not to bring any lawsuit or other proceeding against the Company or its subsidiaries arising from the claims released under the Agreement.\\n\\nIn connection with the Agreement, the Company has also agreed to provide the Former Employee with a neutral reference, which will confirm the Former Employee\\'s dates of employment and job title, but will not include any information regarding the Former Employee\\'s performance or the circumstances surrounding the termination of employment.\\n\\nThe settlement payment and the related release of claims are expected to resolve all disputes between the Company and the Former Employee. The Company believes that the settlement is in the best interests of the Company and its stockholders, as it avoids the costs and uncertainties associated with litigation and allows the Company to focus on its business operations.\\n\\nThe foregoing is a summary and is qualified in its entirety by reference to the full text of the settlement agreement, which is filed as Exhibit 10.1 to this report.\\n\\n10.1 Settlement Agreement, dated April 15, 2022, between the Company and [Name of Former Employee]\\n\\n/s/ John E. Hennessy\\nJohn E. Hennessy\\nExecutive Vice President, General Counsel and Secretary\\nDate: April 19, 2022\\n\\nNote: The filing of the settlement agreement as an exhibit to this report is intended to provide investors and other interested parties with access to the terms and conditions of the settlement, as required by the Securities and Exchange Commission\\'s rules and regulations. The Company\\'s decision to file the settlement agreement as an exhibit should not be construed as an admission of any wrongdoing or liability by the Company or its subsidiaries.'], 'output': [{'analysis': 'Assuming $1.4B debt with 4.2% interest rate; merger subject to regulatory approvals', 'critical_dates': ['2023-06-30'], 'financial_impact': {'amount': 1400.0, 'recurring': False, 'timeframe': None}, 'key_metrics': {'debt_outstanding': 6500.0, 'hedge_ratio': None, 'interest_rate': 4.2, 'tax_exposure': None}, 'risk_categories': ['DEBT', 'LIQUIDITY', 'REGULATORY'], 'risk_severity': 'HIGH'}, {'analysis': 'Significant disruptions to global operations, supply chain, and customer deliveries due to COVID-19 pandemic, with potential for material adverse impact on financial performance and operations.', 'critical_dates': None, 'financial_impact': None, 'key_metrics': None, 'risk_categories': ['OPERATIONAL', 'MARKET', 'LABOR'], 'risk_severity': 'HIGH'}, {'analysis': 'Tentative labor agreement with USW includes $500M capital investment commitment and 4.5% average annual wage increases for 4,500 hourly employees.', 'critical_dates': ['2022-10-03'], 'financial_impact': {'amount': 500.0, 'recurring': False, 'timeframe': None}, 'key_metrics': None, 'risk_categories': ['LABOR'], 'risk_severity': 'MEDIUM'}, {'analysis': 'High debt exposure ($1.2B) with significant variable rate debt ($600M) may limit business flexibility and increase vulnerability to adverse economic changes.', 'critical_dates': None, 'financial_impact': {'amount': 1200.0, 'recurring': True, 'timeframe': None}, 'key_metrics': {'debt_outstanding': 1200.0, 'hedge_ratio': None, 'interest_rate': None, 'tax_exposure': None}, 'risk_categories': ['DEBT', 'INTEREST_RATE'], 'risk_severity': 'HIGH'}, {'analysis': 'Settlement payment of $400,000 to a former employee to resolve a claim for damages and costs', 'critical_dates': None, 'financial_impact': {'amount': 0.4, 'recurring': False, 'timeframe': '2022'}, 'key_metrics': None, 'risk_categories': ['LEGAL'], 'risk_severity': 'LOW'}], 'risk_severity': ['HIGH', 'HIGH', 'MEDIUM', 'HIGH', 'LOW'], 'risk_categories': [['DEBT', 'LIQUIDITY', 'REGULATORY'], ['OPERATIONAL', 'MARKET', 'LABOR'], ['LABOR'], ['DEBT', 'INTEREST_RATE'], ['LEGAL']], 'text_length': [3457, 5494, 3771, 7039, 3374], '__index_level_0__': [94, 728, 1, 864, 837]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "import time\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/gretelai/gretel-financial-risk-analysis-v1/\" + splits[\"train\"])\n",
    "\n",
    "# Convert dataframe to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Check the first few rows of the dataset to see what columns it has\n",
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd6daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\danie\\anaconda5\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\anaconda5\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': ['\"Item 8.01. Other Events.\\n\\nOn March 21, 2023, the Company entered into an agreement with its wholly-owned subsidiary, F5, Inc. (F5) to merge F5 with a subsidiary of the Company. The merger is expected to be completed in the second quarter of 2023, subject to the satisfaction of customary closing conditions, including the receipt of regulatory approvals from relevant authorities.\\n\\nThe merger consideration will be paid in cash, with the Company paying F5 stockholders approximately $4.4 billion, or $23.00 per share, in the aggregate. This price represents a premium of approximately 25% to the closing price of F5\\'s common stock on the trading day preceding the announcement of the merger. The merger consideration will be funded with the Company\\'s existing cash reserves, which totaled approximately $8.2 billion as of December 31, 2022. The Company has sufficient liquidity to fund the merger consideration and does not anticipate the need to raise additional debt or equity financing in connection with the transaction.\\n\\nIn addition to the merger consideration, the Company will also assume F5\\'s outstanding debt of approximately $1.4 billion, which consists of senior notes with a weighted average interest rate of 4.2% and a weighted average maturity of 7.3 years. The assumption of F5\\'s debt is expected to increase the Company\\'s total debt to approximately $6.5 billion, pro forma for the merger. However, the Company believes that the merger will generate significant cash flow synergies and improve its overall financial profile, enabling it to manage its increased debt burden effectively.\\n\\nThe merger is subject to customary closing conditions, including the receipt of regulatory approvals from the Federal Trade Commission (FTC) and the Department of Justice (DOJ) under the Hart-Scott-Rodino Antitrust Improvements Act (HSR Act). The Company has filed the required notifications with the FTC and DOJ and is cooperating with their review of the transaction. While there can be no assurance that the regulatory approvals will be obtained on a timely basis, or at all, the Company believes that the merger will not raise significant competitive concerns and expects to receive the necessary approvals within the anticipated timeframe.\\n\\nIn connection with the merger, the Company will file a Current Report on Form 8-K, which will include the merger agreement and related exhibits, with the Securities and Exchange Commission (the SEC). The merger agreement will provide additional details about the terms and conditions of the transaction, including the merger consideration, the assumption of F5\\'s debt, and the post-merger organizational structure. The Company will also file with the SEC a Current Report on Form 8-K announcing the closing of the merger, which will include updated financial information and other relevant details about the transaction.\\n\\nThe Company expects the merger to generate significant strategic and financial benefits, including enhanced scale and competitiveness, improved operational efficiency, and increased cash flow. The merger is also expected to create opportunities for growth and expansion in new markets and geographies, as well as increased investment in research and development, sales and marketing, and customer support. The Company is committed to ensuring a smooth transition and integration of F5\\'s business and operations, with minimal disruption to customers, employees, and other stakeholders.\"', '\", and to the extent that the financial markets and the capital structure of the Company and its subsidiaries are affected by the impact of the COVID-19 pandemic, the financial markets and the capital structure of the Company and its subsidiaries could be negatively impacted. This potential negative impact may be exacerbated by various factors, including, but not limited to, reduced investor confidence, increased volatility in the financial markets, and reduced access to capital.\\n\\nIn addition, the COVID-19 pandemic has had a significant impact on the global economy, including the Company’s customers, and the Company has experienced and may continue to experience significant disruptions to its global operations. These disruptions include, but are not limited to, supply chain disruptions, the inability to access certain of its facilities, including the inability to access the Company’s global headquarters, as well as to its customers and suppliers, including the inability to access the Company’s customers’ facilities. This has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers, potentially leading to delays, cancellations, or reductions in orders.\\n\\nThe COVID-19 pandemic has also resulted in and may continue to result in significant disruptions to the Company’s supply chain. These disruptions include, but are not limited to, the Company’s inability to obtain adequate supplies of certain raw materials and components, including, but not limited to, semiconductors. The pandemic has caused significant shortages of these critical components, leading to increased costs and reduced availability. Furthermore, the Company’s inability to obtain adequate supplies of certain manufacturing and production materials and supplies, including, but not limited to, manufacturing equipment and tooling, has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers.\\n\\nIn addition, the COVID-19 pandemic has resulted in and may continue to result in significant disruptions to the Company’s global operations. These disruptions include, but are not limited to, the inability of the Company’s employees to work at the Company’s facilities, including the inability of the Company’s employees to work at the Company’s global headquarters. This has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers. The pandemic has also forced the Company to adopt remote work arrangements, which may not be as effective as traditional in-person work arrangements, potentially leading to reduced productivity and efficiency.\\n\\nThe COVID-19 pandemic has also resulted in and may continue to result in significant disruptions to the Company’s ability to deliver products to its customers. These disruptions include, but are not limited to, the Company’s inability to deliver products to its customers in a timely manner. This has resulted in and may continue to result in significant delays, increased costs, and reduced customer satisfaction. Furthermore, the pandemic has caused significant disruptions to global logistics and transportation systems, leading to increased costs and reduced availability of shipping and delivery options.\\n\\nThe Company is actively working to mitigate the impacts of the COVID-19 pandemic on its global operations and supply chain. These efforts include, but are not limited to, implementing remote work arrangements, increasing inventory levels of critical components, and identifying alternative suppliers and logistics providers. However, the Company cannot guarantee that these efforts will be successful, and the COVID-19 pandemic may continue to have a significant impact on the Company’s ability to supply products to its customers.\\n\\nThe Company’s management is closely monitoring the situation and is taking all necessary steps to minimize the impact of the COVID-19 pandemic on the Company’s operations and financial performance. However, the extent to which the COVID-19 pandemic will impact the Company’s financial performance and operations will depend on various factors, including, but not limited to, the duration and severity of the pandemic, the impact of the pandemic on the global economy, and the effectiveness of the Company’s mitigation efforts. As a result, the Company cannot provide any assurance that the COVID-19 pandemic will not have a material adverse impact on its financial performance and operations.\\n\\nIn light of the significant uncertainties and risks associated with the COVID-19 pandemic, the Company is taking a cautious approach to its financial planning and budgeting. The Company is regularly reviewing and updating its financial projections and is prepared to take additional steps as necessary to mitigate the impacts of the pandemic on its financial performance and operations. However, the Company cannot guarantee that these efforts will be successful, and the COVID-19 pandemic may continue to have a significant impact on the Company’s financial performance and operations.\\n\\nThe Company will continue to closely monitor the situation and will provide updates as necessary. However, the Company cannot predict with certainty the extent to which the COVID-19 pandemic will impact its financial performance and operations, and the Company’s actual results may differ significantly from its current expectations.\"', '\"Item 8.01\\nDate: September 23, 2022\\n\\nExhibit 99.1\\n\\nContact:\\nMelissa Stephenson\\nPhone: (202) 508-8000\\nEmail: [mstephenson@usw.org](mailto:mstephenson@usw.org)\\n\\nOn September 23, 2022, United Steelworkers (the \"USW\") announced that it has entered into a tentative agreement with XYZ Steel Corporation (the \"Company\") regarding a new collective bargaining agreement covering approximately 4,500 hourly employees at the Company\\'s U.S. facilities.\\n\\nThe tentative agreement is subject to ratification by the USW membership and is scheduled to be voted on during the week of October 3, 2022. The agreement provides for significant wage and benefit improvements for USW-represented employees, including:\\n\\n*   Average annual wage increases of 4.5% over the term of the agreement\\n*   Enhanced retirement benefits, including a $1,000 increase in the monthly pension multiplier\\n*   Improved healthcare benefits, including reduced employee premiums and out-of-pocket costs\\n*   Enhanced safety and health provisions, including the creation of a joint union-management safety committee\\n\\nThe tentative agreement also includes provisions to support the long-term competitiveness of the Company\\'s U.S. operations, including:\\n\\n*   A commitment to invest $500 million in capital improvements at the Company\\'s U.S. facilities over the term of the agreement\\n*   The creation of a joint union-management productivity committee to identify and implement efficiency improvements\\n*   A provision to allow the Company to adjust its workforce in response to changes in market conditions, subject to certain restrictions and limitations\\n\\nThe USW and the Company have also agreed to establish a joint committee to explore opportunities for growth and development in the U.S. steel industry, including the potential for new investments and job creation.\\n\\nThe tentative agreement is the result of several months of negotiations between the USW and the Company, and we believe that it provides a fair and equitable resolution to the parties\\' differences. We are confident that the agreement will be ratified by the USW membership and look forward to working with the Company to implement its terms.\\n\\nExhibit 99.1 is a copy of the press release announcing the tentative agreement.\\n\\n Safe Harbor Statement\\n\\nThis report contains forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. Such statements are subject to risks and uncertainties that could cause actual results to differ materially from those expressed or implied. These risks and uncertainties include, but are not limited to, general economic and business conditions, changes in the competitive environment, and the Company\\'s ability to implement the terms of the tentative agreement.\\n\\nThe Company undertakes no obligation to update or revise any forward-looking statements to reflect new information or events.\\n\\nAbout the USW\\n\\nThe United Steelworkers (USW) is a North American union representing workers in a wide range of industries, including steel, aluminum, mining, and energy. The USW is committed to negotiating fair and equitable collective bargaining agreements that provide good wages, benefits, and working conditions for its members.\\n\\nAbout XYZ Steel Corporation\\n\\nXYZ Steel Corporation is a leading producer of steel and steel products in North America, with operations in the United States and Canada. The Company is committed to providing high-quality products and services to its customers while maintaining a safe and healthy work environment for its employees.\\n\\nInvestor Contact:\\nMelissa Stephenson\\nPhone: (202) 508-8000\\nEmail: [mstephenson@usw.org](mailto:mstephenson@usw.org)\\n\\nMedia Contact:\\nSarah Johnson\\nPhone: (202) 508-8000\\nEmail: [sjohnson@usw.org](mailto:sjohnson@usw.org)\"', '\"the Company’s financial condition, results of operations, and cash flows.\\n\\nThe Company has a significant amount of indebtedness, including the senior notes and the term loan. As of December 31, 2022, the Company\\'s total debt outstanding was $1.2 billion, consisting of $800 million in senior notes and $400 million in term loans. The Company’s level of indebtedness may have significant consequences, including:\\n\\n• making it more difficult for the Company to raise capital to fund its business, pay its debts, or meet working capital needs. The Company may be required to dedicate a substantial portion of its cash flows from operations to service its debt, which could limit its ability to invest in its business, respond to changes in the market, or take advantage of new opportunities;\\n\\n• increasing sensitivity to changes in interest rates and other market conditions, including the Company’s exposure to variable rate debt. As of December 31, 2022, approximately $600 million of the Company\\'s debt was subject to variable interest rates, which could result in increased interest expenses if interest rates rise;\\n\\n• making it more difficult for the Company to comply with financial covenants, including those related to leverage, interest coverage, and other financial ratios, contained in the Company’s debt agreements. The Company is required to maintain certain financial ratios, such as a debt-to-equity ratio of no more than 3.5:1 and an interest coverage ratio of at least 2.5:1, and failure to comply with these covenants could result in a default under its debt agreements;\\n\\n• subjecting the Company to the risk of default under its debt agreements, which could result in the acceleration of its debt. If the Company defaults under any of its debt agreements, the lenders may declare all outstanding debt to be immediately due and payable, which could have a material adverse effect on the Company\\'s financial condition and results of operations;\\n\\n• subjecting the Company to the risk of cross-default, which could result in the acceleration of the Company’s debt, including the senior notes and the term loan, if the Company defaults under any other agreement. The Company has various other agreements, such as lease agreements and supply contracts, that contain cross-default provisions, which could result in a default under its debt agreements if the Company defaults under any of these other agreements;\\n\\n• subjecting the Company to the risk of restrictions on its ability to make payments on its debt, including the senior notes and the term loan, or make certain investments or enter into certain transactions. The Company\\'s debt agreements contain various restrictions, such as limitations on the Company\\'s ability to make dividend payments, incur additional debt, or enter into certain mergers or acquisitions, which could limit the Company\\'s ability to take actions that it believes are in its best interests;\\n\\n• increasing the Company’s vulnerability to adverse economic or other changes in the Company’s business. The Company operates in a highly competitive industry and is subject to various economic and market risks, such as changes in consumer demand, fluctuations in raw material prices, and increased competition from new entrants in the market;\\n\\n• limiting the Company’s flexibility in planning for, or responding to, changes in the Company’s business or in the market. The Company\\'s debt agreements contain various restrictions that may limit its ability to respond to changes in the market or take advantage of new opportunities, such as limitations on its ability to incur additional debt or make certain investments;\\n\\n• placing the Company and its subsidiaries at risk of having the Company’s assets sold to satisfy the Company’s obligations under its debt agreements. If the Company defaults under its debt agreements, the lenders may have the right to foreclose on the Company\\'s assets, which could result in a material loss of value for the Company\\'s shareholders.\\n\\nThe Company’s ability to meet its debt service obligations depends on its future operating performance and financial position, which are subject to a number of risks, including those discussed in this Item 1A, and to general economic, competitive and other factors beyond the Company’s control. If the Company is unable to generate sufficient cash flow from its operations or if it is unable to access capital markets or other financing sources on acceptable terms, it may not be able to meet its debt service obligations.\\n\\nIn addition, the Company’s debt agreements contain certain restrictions on its ability to incur additional debt, pay dividends, make certain investments, enter into certain transactions, and transfer certain assets, among other restrictions. These restrictions could limit the Company’s ability to take actions that it believes are in its best interests. For example, the Company\\'s debt agreements contain provisions that limit its ability to incur additional debt, including a provision that requires the Company to maintain a debt-to-equity ratio of no more than 3.5:1.\\n\\nThe Company’s debt agreements also contain certain covenants that may limit the Company’s ability to engage in certain activities that may be in its best interests. For example, the Company\\'s debt agreements contain provisions that limit its ability to make certain investments, such as investments in joint ventures or strategic partnerships, which could limit the Company\\'s ability to grow its business or take advantage of new opportunities.\\n\\nFurthermore, the Company\\'s debt agreements contain provisions that require it to maintain certain financial ratios, such as an interest coverage ratio of at least 2.5:1, and to comply with certain other financial covenants. Failure to comply with these covenants could result in a default under the Company\\'s debt agreements, which could have a material adverse effect on the Company\\'s financial condition and results of operations.\\n\\nIn order to mitigate these risks, the Company regularly reviews its debt agreements and assesses its compliance with the various covenants and restrictions contained in these agreements. The Company also regularly reviews its financial position and cash flows to ensure that it has sufficient liquidity to meet its debt service obligations. In addition, the Company has implemented various financial management strategies, such as maintaining a cash reserve and diversifying its revenue streams, to reduce its vulnerability to adverse economic or other changes in its business.\\n\\nDespite these efforts, the Company\\'s level of indebtedness and the restrictions contained in its debt agreements may still have a material adverse effect on its financial condition and results of operations. The Company\\'s ability to meet its debt service obligations and comply with the covenants and restrictions contained in its debt agreements will depend on its future operating performance and financial position, which are subject to a number of risks and uncertainties.\"', 'Item 8.01 Other Events\\n\\nOn April 15, 2022, the Company entered into a settlement agreement (the \"Agreement\") with a former employee (the \"Former Employee\") to resolve a claim for damages and costs arising from the Former Employee\\'s alleged breach of the Company\\'s Confidential Information and Invention Assignment Agreement (the \"CIIA Agreement\"). The CIIA Agreement, which was executed by the Former Employee upon commencement of employment with the Company, obligates employees to maintain the confidentiality of Company proprietary information and to assign to the Company all inventions, discoveries, and ideas conceived or developed during the term of employment.\\n\\nThe settlement agreement provides for a payment of $400,000 to the Former Employee, which amount is included in the Company\\'s accrued liabilities on the balance sheet as of March 31, 2022. The Company has recorded this liability in accordance with Accounting Standards Codification (\"ASC\") 450, Contingencies, and has accrued the full amount of the settlement payment. The payment is expected to be made on or before May 15, 2022, and will be funded from the Company\\'s existing cash and cash equivalents.\\n\\nThe Agreement also contains a release of all claims by the Former Employee against the Company and its subsidiaries, including any claims arising from the Former Employee\\'s employment with the Company or the termination of such employment. The release includes, but is not limited to, claims for wrongful termination, breach of contract, and any claims arising under federal, state, or local employment laws. In addition, the Agreement includes a covenant not to sue, pursuant to which the Former Employee agrees not to bring any lawsuit or other proceeding against the Company or its subsidiaries arising from the claims released under the Agreement.\\n\\nIn connection with the Agreement, the Company has also agreed to provide the Former Employee with a neutral reference, which will confirm the Former Employee\\'s dates of employment and job title, but will not include any information regarding the Former Employee\\'s performance or the circumstances surrounding the termination of employment.\\n\\nThe settlement payment and the related release of claims are expected to resolve all disputes between the Company and the Former Employee. The Company believes that the settlement is in the best interests of the Company and its stockholders, as it avoids the costs and uncertainties associated with litigation and allows the Company to focus on its business operations.\\n\\nThe foregoing is a summary and is qualified in its entirety by reference to the full text of the settlement agreement, which is filed as Exhibit 10.1 to this report.\\n\\n10.1 Settlement Agreement, dated April 15, 2022, between the Company and [Name of Former Employee]\\n\\n/s/ John E. Hennessy\\nJohn E. Hennessy\\nExecutive Vice President, General Counsel and Secretary\\nDate: April 19, 2022\\n\\nNote: The filing of the settlement agreement as an exhibit to this report is intended to provide investors and other interested parties with access to the terms and conditions of the settlement, as required by the Securities and Exchange Commission\\'s rules and regulations. The Company\\'s decision to file the settlement agreement as an exhibit should not be construed as an admission of any wrongdoing or liability by the Company or its subsidiaries.'], 'output': [{'analysis': 'Assuming $1.4B debt with 4.2% interest rate; merger subject to regulatory approvals', 'critical_dates': ['2023-06-30'], 'financial_impact': {'amount': 1400.0, 'recurring': False, 'timeframe': None}, 'key_metrics': {'debt_outstanding': 6500.0, 'hedge_ratio': None, 'interest_rate': 4.2, 'tax_exposure': None}, 'risk_categories': ['DEBT', 'LIQUIDITY', 'REGULATORY'], 'risk_severity': 'HIGH'}, {'analysis': 'Significant disruptions to global operations, supply chain, and customer deliveries due to COVID-19 pandemic, with potential for material adverse impact on financial performance and operations.', 'critical_dates': None, 'financial_impact': None, 'key_metrics': None, 'risk_categories': ['OPERATIONAL', 'MARKET', 'LABOR'], 'risk_severity': 'HIGH'}, {'analysis': 'Tentative labor agreement with USW includes $500M capital investment commitment and 4.5% average annual wage increases for 4,500 hourly employees.', 'critical_dates': ['2022-10-03'], 'financial_impact': {'amount': 500.0, 'recurring': False, 'timeframe': None}, 'key_metrics': None, 'risk_categories': ['LABOR'], 'risk_severity': 'MEDIUM'}, {'analysis': 'High debt exposure ($1.2B) with significant variable rate debt ($600M) may limit business flexibility and increase vulnerability to adverse economic changes.', 'critical_dates': None, 'financial_impact': {'amount': 1200.0, 'recurring': True, 'timeframe': None}, 'key_metrics': {'debt_outstanding': 1200.0, 'hedge_ratio': None, 'interest_rate': None, 'tax_exposure': None}, 'risk_categories': ['DEBT', 'INTEREST_RATE'], 'risk_severity': 'HIGH'}, {'analysis': 'Settlement payment of $400,000 to a former employee to resolve a claim for damages and costs', 'critical_dates': None, 'financial_impact': {'amount': 0.4, 'recurring': False, 'timeframe': '2022'}, 'key_metrics': None, 'risk_categories': ['LEGAL'], 'risk_severity': 'LOW'}], 'risk_severity': ['HIGH', 'HIGH', 'MEDIUM', 'HIGH', 'LOW'], 'risk_categories': [['DEBT', 'LIQUIDITY', 'REGULATORY'], ['OPERATIONAL', 'MARKET', 'LABOR'], ['LABOR'], ['DEBT', 'INTEREST_RATE'], ['LEGAL']], 'text_length': [3457, 5494, 3771, 7039, 3374], '__index_level_0__': [94, 728, 1, 864, 837]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc973f878ab840dcb76f3af0e0264814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'BitsAndBytesConfig' has no attribute 'from_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m tokenized_datasets \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Load model with QLoRA quantization using BitsAndBytesConfig\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     79\u001b[0m     model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[0;32m     80\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Enable 4-bit quantization\u001b[39;00m\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path, config\u001b[38;5;241m=\u001b[39mquantization_config)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Set up PEFA (Prompted Embeddings for Fine-Tuning)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'BitsAndBytesConfig' has no attribute 'from_pretrained'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/gretelai/gretel-financial-risk-analysis-v1/\" + splits[\"train\"])\n",
    "\n",
    "# Convert dataframe to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Inspect the first few rows of the dataset to confirm structure\n",
    "print(dataset[:5])  # Check the structure of 'input' and 'output'\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "# # Tokenize function (process both input and output)\n",
    "# def tokenize_function(examples):\n",
    "#     # We assume 'input' is the text and 'output' is the risk analysis structure\n",
    "#     inputs = tokenizer(examples['input'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    \n",
    "#     # Format the output and tokenize it\n",
    "#     formatted_outputs = [format_output(output) for output in examples['output']]\n",
    "#     outputs = tokenizer(formatted_outputs, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    \n",
    "#     inputs['labels'] = outputs['input_ids']  # Use the tokenized output as labels\n",
    "#     return inputs\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Iterate through the 'output' list for each instance and extract the 'analysis'\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output'] if 'analysis' in output_item]\n",
    "\n",
    "    # Tokenize the 'analysis' text\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load model with QLoRA quantization using BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig.from_pretrained(\n",
    "    model_path=model_path,\n",
    "    load_in_8bit=True  # Enable 4-bit quantization\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, config=quantization_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Financial risk analysis for: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n",
    "\n",
    "# Plotting performance metrics (optional, using your previous code)\n",
    "# Collect metrics during training\n",
    "time_taken_list = []\n",
    "tokens_per_second_list = []\n",
    "perplexity_list = []\n",
    "rouge_scores = []\n",
    "bleu_scores = []\n",
    "edit_distance_list = []\n",
    "bert_score_list = []\n",
    "win_rate_list = []\n",
    "\n",
    "num_tests = 5  # Number of tests for evaluation\n",
    "win_threshold = 0.8  # BERTScore threshold for Win% calculation\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for _ in range(num_tests):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\"What are the key financial risks in SEC filings?\", return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=64)\n",
    "\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Measure inference time\n",
    "    time_taken = time.time() - start_time\n",
    "    time_taken_list.append(time_taken)\n",
    "\n",
    "    # Compute tokens per second\n",
    "    num_tokens = len(inputs[\"input_ids\"][0]) + 64\n",
    "    tokens_per_second = num_tokens / time_taken\n",
    "    tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "    # Compute Perplexity\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss).item()\n",
    "        perplexity_list.append(perplexity)\n",
    "\n",
    "    # Evaluate ROUGE and BLEU\n",
    "    rouge_result = rouge.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "    rouge_scores.append(rouge_result[\"rougeL\"])\n",
    "\n",
    "    bleu_result = bleu.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "    bleu_scores.append(bleu_result[\"bleu\"])\n",
    "\n",
    "    # Levenshtein Edit Distance\n",
    "    edit_distance = levenshtein_distance(decoded_output, \"What are the key financial risks in SEC filings?\")\n",
    "    edit_distance_list.append(edit_distance)\n",
    "\n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score([decoded_output], [\"What are the key financial risks in SEC filings?\"], lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_score_list.append(F1.mean().item())\n",
    "\n",
    "    # Compute Win Rate\n",
    "    win_rate_list.append(1 if F1.mean().item() >= win_threshold else 0)\n",
    "\n",
    "# Output average performance metrics\n",
    "print(f\"Average Perplexity: {sum(perplexity_list) / num_tests:.2f}\")\n",
    "print(f\"Average ROUGE Score: {sum(rouge_scores) / num_tests:.4f}\")\n",
    "print(f\"Average BLEU Score: {sum(bleu_scores) / num_tests:.4f}\")\n",
    "print(f\"Average Edit Distance: {sum(edit_distance_list) / num_tests:.2f}\")\n",
    "print(f\"Average BERTScore: {sum(bert_score_list) / num_tests:.4f}\")\n",
    "print(f\"Win Rate: {sum(win_rate_list) / num_tests * 100:.2f}%\")\n",
    "print(f\"Average Token Throughput: {sum(tokens_per_second_list) / num_tests:.2f} tokens/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "408364e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\danie\\anaconda5\\lib\\site-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U bitsandbytes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62c50d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement bitsandbytes-cudaXXX (from versions: none)\n",
      "ERROR: No matching distribution found for bitsandbytes-cudaXXX\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade bitsandbytes-cudaXXX  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2dff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\danie\\anaconda5\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\anaconda5\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1a4970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd6fd0a7ed640e0b1c81b0ecfced72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\danie\\.cache\\huggingface\\hub\\datasets--gretelai--gretel-financial-risk-analysis-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697359ded3a54a518cc12ae3d2380ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fecd51a8bf94bc181cc766b0ef7b8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/458k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73e7b0309974e11ab730296241dce84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aefa650e7164956b8123d3f4af7815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f919b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'output', 'risk_severity', 'risk_categories', 'text_length', '__index_level_0__'],\n",
      "        num_rows: 827\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'output', 'risk_severity', 'risk_categories', 'text_length', '__index_level_0__'],\n",
      "        num_rows: 207\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Show the dataset's info\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f7490bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bdc7cf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Invalid key: slice(None, 5, None). Please first select a split. For example: `my_dataset_dictionary['train'][slice(None, 5, None)]`. Available splits: ['test', 'train']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgretelai/gretel-financial-risk-analysis-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Inspect the first few rows of the dataset to confirm structure\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset[:\u001b[38;5;241m5\u001b[39m])  \u001b[38;5;66;03m# Check the structure of 'input' and 'output'\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize tokenizer\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Mistral-7B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adjust to your model path\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\datasets\\dataset_dict.py:88\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     84\u001b[0m available_suggested_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     85\u001b[0m     split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split\u001b[38;5;241m.\u001b[39mTRAIN, Split\u001b[38;5;241m.\u001b[39mTEST, Split\u001b[38;5;241m.\u001b[39mVALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m     86\u001b[0m ]\n\u001b[0;32m     87\u001b[0m suggested_split \u001b[38;5;241m=\u001b[39m available_suggested_splits[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m available_suggested_splits \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please first select a split. For example: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`my_dataset_dictionary[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggested_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable splits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Invalid key: slice(None, 5, None). Please first select a split. For example: `my_dataset_dictionary['train'][slice(None, 5, None)]`. Available splits: ['test', 'train']\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "\n",
    "# Inspect the first few rows of the dataset to confirm structure\n",
    "print(dataset[:5])  # Check the structure of 'input' and 'output'\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "# Tokenize function (process both input and output)\n",
    "def tokenize_function(examples):\n",
    "    # Iterate through the 'output' list for each instance and extract the 'analysis'\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output'] if 'analysis' in output_item]\n",
    "\n",
    "    # Tokenize the 'analysis' text\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=quantization_config,\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    eval_strategy =\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,  # If this raises an error, check for eval_strategy\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],  # Correct training dataset\n",
    "    eval_dataset=tokenized_datasets[\"test\"],   # Correct testing dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n",
    "\n",
    "# Plotting performance metrics (optional, using your previous code)\n",
    "# Collect metrics during training\n",
    "time_taken_list = []\n",
    "tokens_per_second_list = []\n",
    "perplexity_list = []\n",
    "rouge_scores = []\n",
    "bleu_scores = []\n",
    "edit_distance_list = []\n",
    "bert_score_list = []\n",
    "win_rate_list = []\n",
    "\n",
    "num_tests = 5  # Number of tests for evaluation\n",
    "win_threshold = 0.8  # BERTScore threshold for Win% calculation\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for _ in range(num_tests):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\"What are the key financial risks in SEC filings?\", return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=64)\n",
    "\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Measure inference time\n",
    "    time_taken = time.time() - start_time\n",
    "    time_taken_list.append(time_taken)\n",
    "\n",
    "    # Compute tokens per second\n",
    "    num_tokens = len(inputs[\"input_ids\"][0]) + 64\n",
    "    tokens_per_second = num_tokens / time_taken\n",
    "    tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "    # Compute Perplexity\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss).item()\n",
    "        perplexity_list.append(perplexity)\n",
    "\n",
    "    # Evaluate ROUGE and BLEU\n",
    "    rouge_result = rouge.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "    rouge_scores.append(rouge_result[\"rougeL\"])\n",
    "\n",
    "    bleu_result = bleu.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "    bleu_scores.append(bleu_result[\"bleu\"])\n",
    "\n",
    "    # Levenshtein Edit Distance\n",
    "    edit_distance = levenshtein_distance(decoded_output, \"What are the key financial risks in SEC filings?\")\n",
    "    edit_distance_list.append(edit_distance)\n",
    "\n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score([decoded_output], [\"What are the key financial risks in SEC filings?\"], lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_score_list.append(F1.mean().item())\n",
    "\n",
    "    # Compute Win Rate\n",
    "    win_rate_list.append(1 if F1.mean().item() >= win_threshold else 0)\n",
    "\n",
    "# Output average performance metrics\n",
    "print(f\"Average Perplexity: {sum(perplexity_list) / num_tests:.2f}\")\n",
    "print(f\"Average ROUGE Score: {sum(rouge_scores) / num_tests:.4f}\")\n",
    "print(f\"Average BLEU Score: {sum(bleu_scores) / num_tests:.4f}\")\n",
    "print(f\"Average Edit Distance: {sum(edit_distance_list) / num_tests:.2f}\")\n",
    "print(f\"Average BERTScore: {sum(bert_score_list) / num_tests:.4f}\")\n",
    "print(f\"Win Rate: {sum(win_rate_list) / num_tests * 100:.2f}%\")\n",
    "print(f\"Average Token Throughput: {sum(tokens_per_second_list) / num_tests:.2f} tokens/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b801178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': ['\"Item 8.01. Other Events.\\n\\nOn March 21, 2023, the Company entered into an agreement with its wholly-owned subsidiary, F5, Inc. (F5) to merge F5 with a subsidiary of the Company. The merger is expected to be completed in the second quarter of 2023, subject to the satisfaction of customary closing conditions, including the receipt of regulatory approvals from relevant authorities.\\n\\nThe merger consideration will be paid in cash, with the Company paying F5 stockholders approximately $4.4 billion, or $23.00 per share, in the aggregate. This price represents a premium of approximately 25% to the closing price of F5\\'s common stock on the trading day preceding the announcement of the merger. The merger consideration will be funded with the Company\\'s existing cash reserves, which totaled approximately $8.2 billion as of December 31, 2022. The Company has sufficient liquidity to fund the merger consideration and does not anticipate the need to raise additional debt or equity financing in connection with the transaction.\\n\\nIn addition to the merger consideration, the Company will also assume F5\\'s outstanding debt of approximately $1.4 billion, which consists of senior notes with a weighted average interest rate of 4.2% and a weighted average maturity of 7.3 years. The assumption of F5\\'s debt is expected to increase the Company\\'s total debt to approximately $6.5 billion, pro forma for the merger. However, the Company believes that the merger will generate significant cash flow synergies and improve its overall financial profile, enabling it to manage its increased debt burden effectively.\\n\\nThe merger is subject to customary closing conditions, including the receipt of regulatory approvals from the Federal Trade Commission (FTC) and the Department of Justice (DOJ) under the Hart-Scott-Rodino Antitrust Improvements Act (HSR Act). The Company has filed the required notifications with the FTC and DOJ and is cooperating with their review of the transaction. While there can be no assurance that the regulatory approvals will be obtained on a timely basis, or at all, the Company believes that the merger will not raise significant competitive concerns and expects to receive the necessary approvals within the anticipated timeframe.\\n\\nIn connection with the merger, the Company will file a Current Report on Form 8-K, which will include the merger agreement and related exhibits, with the Securities and Exchange Commission (the SEC). The merger agreement will provide additional details about the terms and conditions of the transaction, including the merger consideration, the assumption of F5\\'s debt, and the post-merger organizational structure. The Company will also file with the SEC a Current Report on Form 8-K announcing the closing of the merger, which will include updated financial information and other relevant details about the transaction.\\n\\nThe Company expects the merger to generate significant strategic and financial benefits, including enhanced scale and competitiveness, improved operational efficiency, and increased cash flow. The merger is also expected to create opportunities for growth and expansion in new markets and geographies, as well as increased investment in research and development, sales and marketing, and customer support. The Company is committed to ensuring a smooth transition and integration of F5\\'s business and operations, with minimal disruption to customers, employees, and other stakeholders.\"', '\", and to the extent that the financial markets and the capital structure of the Company and its subsidiaries are affected by the impact of the COVID-19 pandemic, the financial markets and the capital structure of the Company and its subsidiaries could be negatively impacted. This potential negative impact may be exacerbated by various factors, including, but not limited to, reduced investor confidence, increased volatility in the financial markets, and reduced access to capital.\\n\\nIn addition, the COVID-19 pandemic has had a significant impact on the global economy, including the Company’s customers, and the Company has experienced and may continue to experience significant disruptions to its global operations. These disruptions include, but are not limited to, supply chain disruptions, the inability to access certain of its facilities, including the inability to access the Company’s global headquarters, as well as to its customers and suppliers, including the inability to access the Company’s customers’ facilities. This has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers, potentially leading to delays, cancellations, or reductions in orders.\\n\\nThe COVID-19 pandemic has also resulted in and may continue to result in significant disruptions to the Company’s supply chain. These disruptions include, but are not limited to, the Company’s inability to obtain adequate supplies of certain raw materials and components, including, but not limited to, semiconductors. The pandemic has caused significant shortages of these critical components, leading to increased costs and reduced availability. Furthermore, the Company’s inability to obtain adequate supplies of certain manufacturing and production materials and supplies, including, but not limited to, manufacturing equipment and tooling, has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers.\\n\\nIn addition, the COVID-19 pandemic has resulted in and may continue to result in significant disruptions to the Company’s global operations. These disruptions include, but are not limited to, the inability of the Company’s employees to work at the Company’s facilities, including the inability of the Company’s employees to work at the Company’s global headquarters. This has resulted in and may continue to result in significant disruptions to the Company’s ability to supply products to its customers. The pandemic has also forced the Company to adopt remote work arrangements, which may not be as effective as traditional in-person work arrangements, potentially leading to reduced productivity and efficiency.\\n\\nThe COVID-19 pandemic has also resulted in and may continue to result in significant disruptions to the Company’s ability to deliver products to its customers. These disruptions include, but are not limited to, the Company’s inability to deliver products to its customers in a timely manner. This has resulted in and may continue to result in significant delays, increased costs, and reduced customer satisfaction. Furthermore, the pandemic has caused significant disruptions to global logistics and transportation systems, leading to increased costs and reduced availability of shipping and delivery options.\\n\\nThe Company is actively working to mitigate the impacts of the COVID-19 pandemic on its global operations and supply chain. These efforts include, but are not limited to, implementing remote work arrangements, increasing inventory levels of critical components, and identifying alternative suppliers and logistics providers. However, the Company cannot guarantee that these efforts will be successful, and the COVID-19 pandemic may continue to have a significant impact on the Company’s ability to supply products to its customers.\\n\\nThe Company’s management is closely monitoring the situation and is taking all necessary steps to minimize the impact of the COVID-19 pandemic on the Company’s operations and financial performance. However, the extent to which the COVID-19 pandemic will impact the Company’s financial performance and operations will depend on various factors, including, but not limited to, the duration and severity of the pandemic, the impact of the pandemic on the global economy, and the effectiveness of the Company’s mitigation efforts. As a result, the Company cannot provide any assurance that the COVID-19 pandemic will not have a material adverse impact on its financial performance and operations.\\n\\nIn light of the significant uncertainties and risks associated with the COVID-19 pandemic, the Company is taking a cautious approach to its financial planning and budgeting. The Company is regularly reviewing and updating its financial projections and is prepared to take additional steps as necessary to mitigate the impacts of the pandemic on its financial performance and operations. However, the Company cannot guarantee that these efforts will be successful, and the COVID-19 pandemic may continue to have a significant impact on the Company’s financial performance and operations.\\n\\nThe Company will continue to closely monitor the situation and will provide updates as necessary. However, the Company cannot predict with certainty the extent to which the COVID-19 pandemic will impact its financial performance and operations, and the Company’s actual results may differ significantly from its current expectations.\"', '\"Item 8.01\\nDate: September 23, 2022\\n\\nExhibit 99.1\\n\\nContact:\\nMelissa Stephenson\\nPhone: (202) 508-8000\\nEmail: [mstephenson@usw.org](mailto:mstephenson@usw.org)\\n\\nOn September 23, 2022, United Steelworkers (the \"USW\") announced that it has entered into a tentative agreement with XYZ Steel Corporation (the \"Company\") regarding a new collective bargaining agreement covering approximately 4,500 hourly employees at the Company\\'s U.S. facilities.\\n\\nThe tentative agreement is subject to ratification by the USW membership and is scheduled to be voted on during the week of October 3, 2022. The agreement provides for significant wage and benefit improvements for USW-represented employees, including:\\n\\n*   Average annual wage increases of 4.5% over the term of the agreement\\n*   Enhanced retirement benefits, including a $1,000 increase in the monthly pension multiplier\\n*   Improved healthcare benefits, including reduced employee premiums and out-of-pocket costs\\n*   Enhanced safety and health provisions, including the creation of a joint union-management safety committee\\n\\nThe tentative agreement also includes provisions to support the long-term competitiveness of the Company\\'s U.S. operations, including:\\n\\n*   A commitment to invest $500 million in capital improvements at the Company\\'s U.S. facilities over the term of the agreement\\n*   The creation of a joint union-management productivity committee to identify and implement efficiency improvements\\n*   A provision to allow the Company to adjust its workforce in response to changes in market conditions, subject to certain restrictions and limitations\\n\\nThe USW and the Company have also agreed to establish a joint committee to explore opportunities for growth and development in the U.S. steel industry, including the potential for new investments and job creation.\\n\\nThe tentative agreement is the result of several months of negotiations between the USW and the Company, and we believe that it provides a fair and equitable resolution to the parties\\' differences. We are confident that the agreement will be ratified by the USW membership and look forward to working with the Company to implement its terms.\\n\\nExhibit 99.1 is a copy of the press release announcing the tentative agreement.\\n\\n Safe Harbor Statement\\n\\nThis report contains forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. Such statements are subject to risks and uncertainties that could cause actual results to differ materially from those expressed or implied. These risks and uncertainties include, but are not limited to, general economic and business conditions, changes in the competitive environment, and the Company\\'s ability to implement the terms of the tentative agreement.\\n\\nThe Company undertakes no obligation to update or revise any forward-looking statements to reflect new information or events.\\n\\nAbout the USW\\n\\nThe United Steelworkers (USW) is a North American union representing workers in a wide range of industries, including steel, aluminum, mining, and energy. The USW is committed to negotiating fair and equitable collective bargaining agreements that provide good wages, benefits, and working conditions for its members.\\n\\nAbout XYZ Steel Corporation\\n\\nXYZ Steel Corporation is a leading producer of steel and steel products in North America, with operations in the United States and Canada. The Company is committed to providing high-quality products and services to its customers while maintaining a safe and healthy work environment for its employees.\\n\\nInvestor Contact:\\nMelissa Stephenson\\nPhone: (202) 508-8000\\nEmail: [mstephenson@usw.org](mailto:mstephenson@usw.org)\\n\\nMedia Contact:\\nSarah Johnson\\nPhone: (202) 508-8000\\nEmail: [sjohnson@usw.org](mailto:sjohnson@usw.org)\"', '\"the Company’s financial condition, results of operations, and cash flows.\\n\\nThe Company has a significant amount of indebtedness, including the senior notes and the term loan. As of December 31, 2022, the Company\\'s total debt outstanding was $1.2 billion, consisting of $800 million in senior notes and $400 million in term loans. The Company’s level of indebtedness may have significant consequences, including:\\n\\n• making it more difficult for the Company to raise capital to fund its business, pay its debts, or meet working capital needs. The Company may be required to dedicate a substantial portion of its cash flows from operations to service its debt, which could limit its ability to invest in its business, respond to changes in the market, or take advantage of new opportunities;\\n\\n• increasing sensitivity to changes in interest rates and other market conditions, including the Company’s exposure to variable rate debt. As of December 31, 2022, approximately $600 million of the Company\\'s debt was subject to variable interest rates, which could result in increased interest expenses if interest rates rise;\\n\\n• making it more difficult for the Company to comply with financial covenants, including those related to leverage, interest coverage, and other financial ratios, contained in the Company’s debt agreements. The Company is required to maintain certain financial ratios, such as a debt-to-equity ratio of no more than 3.5:1 and an interest coverage ratio of at least 2.5:1, and failure to comply with these covenants could result in a default under its debt agreements;\\n\\n• subjecting the Company to the risk of default under its debt agreements, which could result in the acceleration of its debt. If the Company defaults under any of its debt agreements, the lenders may declare all outstanding debt to be immediately due and payable, which could have a material adverse effect on the Company\\'s financial condition and results of operations;\\n\\n• subjecting the Company to the risk of cross-default, which could result in the acceleration of the Company’s debt, including the senior notes and the term loan, if the Company defaults under any other agreement. The Company has various other agreements, such as lease agreements and supply contracts, that contain cross-default provisions, which could result in a default under its debt agreements if the Company defaults under any of these other agreements;\\n\\n• subjecting the Company to the risk of restrictions on its ability to make payments on its debt, including the senior notes and the term loan, or make certain investments or enter into certain transactions. The Company\\'s debt agreements contain various restrictions, such as limitations on the Company\\'s ability to make dividend payments, incur additional debt, or enter into certain mergers or acquisitions, which could limit the Company\\'s ability to take actions that it believes are in its best interests;\\n\\n• increasing the Company’s vulnerability to adverse economic or other changes in the Company’s business. The Company operates in a highly competitive industry and is subject to various economic and market risks, such as changes in consumer demand, fluctuations in raw material prices, and increased competition from new entrants in the market;\\n\\n• limiting the Company’s flexibility in planning for, or responding to, changes in the Company’s business or in the market. The Company\\'s debt agreements contain various restrictions that may limit its ability to respond to changes in the market or take advantage of new opportunities, such as limitations on its ability to incur additional debt or make certain investments;\\n\\n• placing the Company and its subsidiaries at risk of having the Company’s assets sold to satisfy the Company’s obligations under its debt agreements. If the Company defaults under its debt agreements, the lenders may have the right to foreclose on the Company\\'s assets, which could result in a material loss of value for the Company\\'s shareholders.\\n\\nThe Company’s ability to meet its debt service obligations depends on its future operating performance and financial position, which are subject to a number of risks, including those discussed in this Item 1A, and to general economic, competitive and other factors beyond the Company’s control. If the Company is unable to generate sufficient cash flow from its operations or if it is unable to access capital markets or other financing sources on acceptable terms, it may not be able to meet its debt service obligations.\\n\\nIn addition, the Company’s debt agreements contain certain restrictions on its ability to incur additional debt, pay dividends, make certain investments, enter into certain transactions, and transfer certain assets, among other restrictions. These restrictions could limit the Company’s ability to take actions that it believes are in its best interests. For example, the Company\\'s debt agreements contain provisions that limit its ability to incur additional debt, including a provision that requires the Company to maintain a debt-to-equity ratio of no more than 3.5:1.\\n\\nThe Company’s debt agreements also contain certain covenants that may limit the Company’s ability to engage in certain activities that may be in its best interests. For example, the Company\\'s debt agreements contain provisions that limit its ability to make certain investments, such as investments in joint ventures or strategic partnerships, which could limit the Company\\'s ability to grow its business or take advantage of new opportunities.\\n\\nFurthermore, the Company\\'s debt agreements contain provisions that require it to maintain certain financial ratios, such as an interest coverage ratio of at least 2.5:1, and to comply with certain other financial covenants. Failure to comply with these covenants could result in a default under the Company\\'s debt agreements, which could have a material adverse effect on the Company\\'s financial condition and results of operations.\\n\\nIn order to mitigate these risks, the Company regularly reviews its debt agreements and assesses its compliance with the various covenants and restrictions contained in these agreements. The Company also regularly reviews its financial position and cash flows to ensure that it has sufficient liquidity to meet its debt service obligations. In addition, the Company has implemented various financial management strategies, such as maintaining a cash reserve and diversifying its revenue streams, to reduce its vulnerability to adverse economic or other changes in its business.\\n\\nDespite these efforts, the Company\\'s level of indebtedness and the restrictions contained in its debt agreements may still have a material adverse effect on its financial condition and results of operations. The Company\\'s ability to meet its debt service obligations and comply with the covenants and restrictions contained in its debt agreements will depend on its future operating performance and financial position, which are subject to a number of risks and uncertainties.\"', 'Item 8.01 Other Events\\n\\nOn April 15, 2022, the Company entered into a settlement agreement (the \"Agreement\") with a former employee (the \"Former Employee\") to resolve a claim for damages and costs arising from the Former Employee\\'s alleged breach of the Company\\'s Confidential Information and Invention Assignment Agreement (the \"CIIA Agreement\"). The CIIA Agreement, which was executed by the Former Employee upon commencement of employment with the Company, obligates employees to maintain the confidentiality of Company proprietary information and to assign to the Company all inventions, discoveries, and ideas conceived or developed during the term of employment.\\n\\nThe settlement agreement provides for a payment of $400,000 to the Former Employee, which amount is included in the Company\\'s accrued liabilities on the balance sheet as of March 31, 2022. The Company has recorded this liability in accordance with Accounting Standards Codification (\"ASC\") 450, Contingencies, and has accrued the full amount of the settlement payment. The payment is expected to be made on or before May 15, 2022, and will be funded from the Company\\'s existing cash and cash equivalents.\\n\\nThe Agreement also contains a release of all claims by the Former Employee against the Company and its subsidiaries, including any claims arising from the Former Employee\\'s employment with the Company or the termination of such employment. The release includes, but is not limited to, claims for wrongful termination, breach of contract, and any claims arising under federal, state, or local employment laws. In addition, the Agreement includes a covenant not to sue, pursuant to which the Former Employee agrees not to bring any lawsuit or other proceeding against the Company or its subsidiaries arising from the claims released under the Agreement.\\n\\nIn connection with the Agreement, the Company has also agreed to provide the Former Employee with a neutral reference, which will confirm the Former Employee\\'s dates of employment and job title, but will not include any information regarding the Former Employee\\'s performance or the circumstances surrounding the termination of employment.\\n\\nThe settlement payment and the related release of claims are expected to resolve all disputes between the Company and the Former Employee. The Company believes that the settlement is in the best interests of the Company and its stockholders, as it avoids the costs and uncertainties associated with litigation and allows the Company to focus on its business operations.\\n\\nThe foregoing is a summary and is qualified in its entirety by reference to the full text of the settlement agreement, which is filed as Exhibit 10.1 to this report.\\n\\n10.1 Settlement Agreement, dated April 15, 2022, between the Company and [Name of Former Employee]\\n\\n/s/ John E. Hennessy\\nJohn E. Hennessy\\nExecutive Vice President, General Counsel and Secretary\\nDate: April 19, 2022\\n\\nNote: The filing of the settlement agreement as an exhibit to this report is intended to provide investors and other interested parties with access to the terms and conditions of the settlement, as required by the Securities and Exchange Commission\\'s rules and regulations. The Company\\'s decision to file the settlement agreement as an exhibit should not be construed as an admission of any wrongdoing or liability by the Company or its subsidiaries.'], 'output': [{'analysis': 'Assuming $1.4B debt with 4.2% interest rate; merger subject to regulatory approvals', 'critical_dates': ['2023-06-30'], 'financial_impact': {'amount': 1400.0, 'recurring': False, 'timeframe': None}, 'key_metrics': {'debt_outstanding': 6500.0, 'hedge_ratio': None, 'interest_rate': 4.2, 'tax_exposure': None}, 'risk_categories': ['DEBT', 'LIQUIDITY', 'REGULATORY'], 'risk_severity': 'HIGH'}, {'analysis': 'Significant disruptions to global operations, supply chain, and customer deliveries due to COVID-19 pandemic, with potential for material adverse impact on financial performance and operations.', 'critical_dates': None, 'financial_impact': None, 'key_metrics': None, 'risk_categories': ['OPERATIONAL', 'MARKET', 'LABOR'], 'risk_severity': 'HIGH'}, {'analysis': 'Tentative labor agreement with USW includes $500M capital investment commitment and 4.5% average annual wage increases for 4,500 hourly employees.', 'critical_dates': ['2022-10-03'], 'financial_impact': {'amount': 500.0, 'recurring': False, 'timeframe': None}, 'key_metrics': None, 'risk_categories': ['LABOR'], 'risk_severity': 'MEDIUM'}, {'analysis': 'High debt exposure ($1.2B) with significant variable rate debt ($600M) may limit business flexibility and increase vulnerability to adverse economic changes.', 'critical_dates': None, 'financial_impact': {'amount': 1200.0, 'recurring': True, 'timeframe': None}, 'key_metrics': {'debt_outstanding': 1200.0, 'hedge_ratio': None, 'interest_rate': None, 'tax_exposure': None}, 'risk_categories': ['DEBT', 'INTEREST_RATE'], 'risk_severity': 'HIGH'}, {'analysis': 'Settlement payment of $400,000 to a former employee to resolve a claim for damages and costs', 'critical_dates': None, 'financial_impact': {'amount': 0.4, 'recurring': False, 'timeframe': '2022'}, 'key_metrics': None, 'risk_categories': ['LEGAL'], 'risk_severity': 'LOW'}], 'risk_severity': ['HIGH', 'HIGH', 'MEDIUM', 'HIGH', 'LOW'], 'risk_categories': [['DEBT', 'LIQUIDITY', 'REGULATORY'], ['OPERATIONAL', 'MARKET', 'LABOR'], ['LABOR'], ['DEBT', 'INTEREST_RATE'], ['LEGAL']], 'text_length': [3457, 5494, 3771, 7039, 3374], '__index_level_0__': [94, 728, 1, 864, 837]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2379ae97d1c41498521ee796de837f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3c2fd5cc014adfb04753ace06071d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed5788130854df1b03323982c9db8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column train not in the dataset. Current columns in the dataset: ['input', 'output', 'risk_severity', 'risk_categories', 'text_length', '__index_level_0__', 'input_ids', 'attention_mask', 'input_text']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 144\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrougeL\u001b[39m\u001b[38;5;124m\"\u001b[39m: rouge_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrougeL\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m: bleu_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: win_rate,\n\u001b[0;32m    138\u001b[0m     }\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Initialize Trainer with compute_metrics\u001b[39;00m\n\u001b[0;32m    141\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    142\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    143\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m--> 144\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    145\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    146\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m    147\u001b[0m )\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[0;32m    150\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\datasets\\arrow_dataset.py:2777\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2776\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\datasets\\arrow_dataset.py:2761\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2759\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   2760\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m-> 2761\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m   2762\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[0;32m   2763\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[0;32m   2764\u001b[0m )\n\u001b[0;32m   2765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\datasets\\formatting\\formatting.py:609\u001b[0m, in \u001b[0;36mquery_table\u001b[1;34m(table, key, indices)\u001b[0m\n\u001b[0;32m    607\u001b[0m         _raise_bad_key_type(key)\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 609\u001b[0m     _check_valid_column_key(key, table\u001b[38;5;241m.\u001b[39mcolumn_names)\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\datasets\\formatting\\formatting.py:546\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[1;34m(key, columns)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column train not in the dataset. Current columns in the dataset: ['input', 'output', 'risk_severity', 'risk_categories', 'text_length', '__index_level_0__', 'input_ids', 'attention_mask', 'input_text']\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "#Load dataset\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "# Tokenize function (process both input and output)\n",
    "def tokenize_function(examples):\n",
    "    # Iterate through the 'output' list for each instance and extract the 'analysis'\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output'] if 'analysis' in output_item]\n",
    "\n",
    "    # Tokenize the 'analysis' text\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=quantization_config,\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Financial risk analysis for: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    eval_strategy =\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,  # If this raises an error, check for eval_strategy\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n",
    "\n",
    "# Plotting performance metrics (optional, using your previous code)\n",
    "# Collect metrics during training\n",
    "time_taken_list = []\n",
    "tokens_per_second_list = []\n",
    "perplexity_list = []\n",
    "rouge_scores = []\n",
    "bleu_scores = []\n",
    "edit_distance_list = []\n",
    "bert_score_list = []\n",
    "win_rate_list = []\n",
    "\n",
    "num_tests = 5  # Number of tests for evaluation\n",
    "win_threshold = 0.8  # BERTScore threshold for Win% calculation\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for _ in range(num_tests):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\"What are the key financial risks in SEC filings?\", return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=64)\n",
    "\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Measure inference time\n",
    "    time_taken = time.time() - start_time\n",
    "    time_taken_list.append(time_taken)\n",
    "\n",
    "    # Compute tokens per second\n",
    "    num_tokens = len(inputs[\"input_ids\"][0]) + 64\n",
    "    tokens_per_second = num_tokens / time_taken\n",
    "    tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "    # Compute Perplexity\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss).item()\n",
    "        perplexity_list.append(perplexity)\n",
    "\n",
    "    # Evaluate ROUGE and BLEU\n",
    "    rouge_result = rouge.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "    rouge_scores.append(rouge_result[\"rougeL\"])\n",
    "\n",
    "    bleu_result = bleu.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "    bleu_scores.append(bleu_result[\"bleu\"])\n",
    "\n",
    "    # Levenshtein Edit Distance\n",
    "    edit_distance = levenshtein_distance(decoded_output, \"What are the key financial risks in SEC filings?\")\n",
    "    edit_distance_list.append(edit_distance)\n",
    "\n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score([decoded_output], [\"What are the key financial risks in SEC filings?\"], lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_score_list.append(F1.mean().item())\n",
    "\n",
    "    # Compute Win Rate\n",
    "    win_rate_list.append(1 if F1.mean().item() >= win_threshold else 0)\n",
    "\n",
    "# Output average performance metrics\n",
    "print(f\"Average Perplexity: {sum(perplexity_list) / num_tests:.2f}\")\n",
    "print(f\"Average ROUGE Score: {sum(rouge_scores) / num_tests:.4f}\")\n",
    "print(f\"Average BLEU Score: {sum(bleu_scores) / num_tests:.4f}\")\n",
    "print(f\"Average Edit Distance: {sum(edit_distance_list) / num_tests:.2f}\")\n",
    "print(f\"Average BERTScore: {sum(bert_score_list) / num_tests:.4f}\")\n",
    "print(f\"Win Rate: {sum(win_rate_list) / num_tests * 100:.2f}%\")\n",
    "print(f\"Average Token Throughput: {sum(tokens_per_second_list) / num_tests:.2f} tokens/sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536fbc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a773e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc06cbb56e35459e89c7e18594b2b1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6aad4dde9c4e5aa8dfc9dfb726ee26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600b0bf8e5ab4bad8e860e61adca0794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb25388046d45308a0854c9a80c1250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c2588790b74d8cb3fe0d087defd5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 15.99 GiB of which 0 bytes is free. Of the allocated memory 29.86 GiB is allocated by PyTorch, and 288.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 139\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrougeL\u001b[39m\u001b[38;5;124m\"\u001b[39m: rouge_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrougeL\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m: bleu_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: win_rate,\n\u001b[0;32m    136\u001b[0m     }\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Initialize Trainer with compute_metrics\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    140\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    141\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m    142\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    143\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    144\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m    145\u001b[0m )\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[0;32m    148\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:614\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[0;32m    613\u001b[0m ):\n\u001b[1;32m--> 614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_model_to_device(model, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    616\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:901\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[1;32m--> 901\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\modeling_utils.py:3698\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3697\u001b[0m         )\n\u001b[1;32m-> 3698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1161\u001b[0m         device,\n\u001b[0;32m   1162\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1163\u001b[0m         non_blocking,\n\u001b[0;32m   1164\u001b[0m     )\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 15.99 GiB of which 0 bytes is free. Of the allocated memory 29.86 GiB is allocated by PyTorch, and 288.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,torch_dtype=\"auto\", device_map=\"auto\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "\n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=256)\n",
    "\n",
    "    # Add 'labels' field for training (auto-regressive causal language models expect labels)\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
    "\n",
    "    return inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=quantization_config,\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Financial risk analysis for: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    eval_strategy =\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,  # If this raises an error, check for eval_strategy\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n",
    "\n",
    "# # Plotting performance metrics (optional, using your previous code)\n",
    "# # Collect metrics during training\n",
    "# time_taken_list = []\n",
    "# tokens_per_second_list = []\n",
    "# perplexity_list = []\n",
    "# rouge_scores = []\n",
    "# bleu_scores = []\n",
    "# edit_distance_list = []\n",
    "# bert_score_list = []\n",
    "# win_rate_list = []\n",
    "\n",
    "# num_tests = 5  # Number of tests for evaluation\n",
    "# win_threshold = 0.8  # BERTScore threshold for Win% calculation\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# for _ in range(num_tests):\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Tokenize input\n",
    "#     inputs = tokenizer(\"What are the key financial risks in SEC filings?\", return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "#     # Generate output\n",
    "#     with torch.no_grad():\n",
    "#         output = model.generate(**inputs, max_new_tokens=64)\n",
    "\n",
    "#     decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "#     # Measure inference time\n",
    "#     time_taken = time.time() - start_time\n",
    "#     time_taken_list.append(time_taken)\n",
    "\n",
    "#     # Compute tokens per second\n",
    "#     num_tokens = len(inputs[\"input_ids\"][0]) + 64\n",
    "#     tokens_per_second = num_tokens / time_taken\n",
    "#     tokens_per_second_list.append(tokens_per_second)\n",
    "\n",
    "#     # Compute Perplexity\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "#         loss = outputs.loss\n",
    "#         perplexity = torch.exp(loss).item()\n",
    "#         perplexity_list.append(perplexity)\n",
    "\n",
    "#     # Evaluate ROUGE and BLEU\n",
    "#     rouge_result = rouge.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "#     rouge_scores.append(rouge_result[\"rougeL\"])\n",
    "\n",
    "#     bleu_result = bleu.compute(predictions=[decoded_output], references=[\"What are the key financial risks in SEC filings?\"])\n",
    "#     bleu_scores.append(bleu_result[\"bleu\"])\n",
    "\n",
    "#     # Levenshtein Edit Distance\n",
    "#     edit_distance = levenshtein_distance(decoded_output, \"What are the key financial risks in SEC filings?\")\n",
    "#     edit_distance_list.append(edit_distance)\n",
    "\n",
    "#     # BERTScore\n",
    "#     P, R, F1 = bert_score([decoded_output], [\"What are the key financial risks in SEC filings?\"], lang=\"en\", rescale_with_baseline=True)\n",
    "#     bert_score_list.append(F1.mean().item())\n",
    "\n",
    "#     # Compute Win Rate\n",
    "#     win_rate_list.append(1 if F1.mean().item() >= win_threshold else 0)\n",
    "\n",
    "# # Output average performance metrics\n",
    "# print(f\"Average Perplexity: {sum(perplexity_list) / num_tests:.2f}\")\n",
    "# print(f\"Average ROUGE Score: {sum(rouge_scores) / num_tests:.4f}\")\n",
    "# print(f\"Average BLEU Score: {sum(bleu_scores) / num_tests:.4f}\")\n",
    "# print(f\"Average Edit Distance: {sum(edit_distance_list) / num_tests:.2f}\")\n",
    "# print(f\"Average BERTScore: {sum(bert_score_list) / num_tests:.4f}\")\n",
    "# print(f\"Win Rate: {sum(win_rate_list) / num_tests * 100:.2f}%\")\n",
    "# print(f\"Average Token Throughput: {sum(tokens_per_second_list) / num_tests:.2f} tokens/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43c96576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (2.4.1+cu118)\n",
      "Requirement already satisfied: transformers in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from peft) (0.30.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda5\\lib\\site-packages (from torch>=1.13.0->peft) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\anaconda5\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers->peft) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\danie\\anaconda5\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f480104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211a1bede8854e4da3d9cfdd3119d94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0854322d6b943f3a77c620b1b4de259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802376f6ffee4a3a8490164431de507d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2521ccb80cd94d8fb470db70e3bbe677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "c:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:54: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 53/153 01:32 < 03:01, 0.55 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 03:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 171\u001b[0m\n\u001b[0;32m    162\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    163\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    164\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m    174\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mistral\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2246\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2247\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2248\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2249\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2250\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:2661\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(\n\u001b[0;32m   2662\u001b[0m     tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate\n\u001b[0;32m   2663\u001b[0m )\n\u001b[0;32m   2665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2667\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:3096\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[0;32m   3094\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 3096\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[0;32m   3097\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m   3099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:3045\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3045\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys_for_eval)\n\u001b[0;32m   3046\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   3048\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:4154\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4151\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   4153\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 4154\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[0;32m   4155\u001b[0m     eval_dataloader,\n\u001b[0;32m   4156\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4157\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[0;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[0;32m   4159\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4160\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[0;32m   4161\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[0;32m   4162\u001b[0m )\n\u001b[0;32m   4164\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   4165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:4443\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4441\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4442\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 4443\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[0;32m   4444\u001b[0m         EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_set_kwargs)\n\u001b[0;32m   4445\u001b[0m     )\n\u001b[0;32m   4446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4447\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[1], line 134\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(pred)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred\u001b[38;5;241m.\u001b[39mlabel_ids, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    132\u001b[0m         pred\u001b[38;5;241m.\u001b[39mlabel_ids \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mlabel_ids\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 134\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(pred\u001b[38;5;241m.\u001b[39mpredictions, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m decoded_labels \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(pred\u001b[38;5;241m.\u001b[39mlabel_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# ROUGE\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3831\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[1;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3808\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3812\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3828\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[0;32m   3829\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m-> 3831\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m   3832\u001b[0m             seq,\n\u001b[0;32m   3833\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3834\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3835\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3836\u001b[0m         )\n\u001b[0;32m   3837\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[0;32m   3838\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3870\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3867\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[0;32m   3868\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[1;32m-> 3870\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   3871\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[0;32m   3872\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3873\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3874\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3875\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:668\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    667\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[1;32m--> 668\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens)\n\u001b[0;32m    670\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    671\u001b[0m     clean_up_tokenization_spaces\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[0;32m    674\u001b[0m )\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,torch_dtype=\"auto\", device_map=\"auto\", load_in_4bit=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "\n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=256)\n",
    "\n",
    "    # Add 'labels' field for training (auto-regressive causal language models expect labels)\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
    "\n",
    "    return inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=quantization_config,\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=2,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=16,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.1,  # Dropout rate for LoRA\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Financial risk analysis for: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    eval_strategy =\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,  # If this raises an error, check for eval_strategy\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# # Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "        \n",
    "    #Convert tensors to lists if they are tensors\n",
    "    if isinstance(pred.predictions, torch.Tensor):\n",
    "            pred.predictions = pred.predictions.tolist()\n",
    "    if isinstance(pred.label_ids, torch.Tensor):\n",
    "            pred.label_ids = pred.label_ids.tolist()\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0871f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8071f196c9a74886a1dd9b206cd16177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "c:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:54: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 53/153 01:31 < 02:58, 0.56 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 03:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 179\u001b[0m\n\u001b[0;32m    170\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    171\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    172\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m    176\u001b[0m )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m    182\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mistral\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2246\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2247\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2248\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2249\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2250\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:2661\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(\n\u001b[0;32m   2662\u001b[0m     tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate\n\u001b[0;32m   2663\u001b[0m )\n\u001b[0;32m   2665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2667\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:3096\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[0;32m   3094\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 3096\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[0;32m   3097\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m   3099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:3045\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3045\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys_for_eval)\n\u001b[0;32m   3046\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   3048\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:4154\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4151\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   4153\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 4154\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[0;32m   4155\u001b[0m     eval_dataloader,\n\u001b[0;32m   4156\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4157\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[0;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[0;32m   4159\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4160\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[0;32m   4161\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[0;32m   4162\u001b[0m )\n\u001b[0;32m   4164\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   4165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:4443\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4441\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4442\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 4443\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[0;32m   4444\u001b[0m         EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_set_kwargs)\n\u001b[0;32m   4445\u001b[0m     )\n\u001b[0;32m   4446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4447\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[1], line 144\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(pred)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred\u001b[38;5;241m.\u001b[39mlabel_ids, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    142\u001b[0m     pred\u001b[38;5;241m.\u001b[39mlabel_ids \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mlabel_ids\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 144\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(pred\u001b[38;5;241m.\u001b[39mpredictions, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    145\u001b[0m decoded_labels \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(pred\u001b[38;5;241m.\u001b[39mlabel_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# ROUGE\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3831\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[1;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3808\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3812\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3828\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[0;32m   3829\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m-> 3831\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m   3832\u001b[0m             seq,\n\u001b[0;32m   3833\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3834\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3835\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3836\u001b[0m         )\n\u001b[0;32m   3837\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[0;32m   3838\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3870\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3867\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[0;32m   3868\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[1;32m-> 3870\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   3871\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[0;32m   3872\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3873\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3874\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3875\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:668\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    667\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[1;32m--> 668\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens)\n\u001b[0;32m    670\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    671\u001b[0m     clean_up_tokenization_spaces\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[0;32m    674\u001b[0m )\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\", load_in_4bit=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "    \n",
    "    print(f\"Analysis List: {analysis_list}\")  # Check the content of analysis_list\n",
    "    \n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=256)\n",
    "    \n",
    "    print(f\"Inputs: {inputs}\")  # Check the structure of the tokenized inputs\n",
    "    \n",
    "    # Ensure that padding tokens are not included in the labels\n",
    "    # Remove padding tokens from input_ids for the labels (if it's a language modeling task)\n",
    "    inputs[\"input_ids\"] = torch.tensor(inputs[\"input_ids\"])\n",
    "    \n",
    "    # The labels should not include padding tokens (pad token is typically '2')\n",
    "    # Replace padding tokens with -100 so they are ignored by the loss function\n",
    "    inputs[\"labels\"] = torch.tensor(inputs[\"input_ids\"]).clone()\n",
    "    inputs[\"labels\"][inputs[\"labels\"] == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=quantization_config,\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=2,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=16,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.1,  # Dropout rate for LoRA\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Financial risk analysis for: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,  # If this raises an error, check for eval_strategy\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    \n",
    "    # Convert tensors to lists if they are tensors\n",
    "    if isinstance(pred.predictions, torch.Tensor):\n",
    "        pred.predictions = pred.predictions.tolist()\n",
    "    if isinstance(pred.label_ids, torch.Tensor):\n",
    "        pred.label_ids = pred.label_ids.tolist()\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cd7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2fd59daa3f4af58d407dedaa673ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "c:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:54: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2550' max='2550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2550/2550 2:21:32, Epoch 49/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Edit Distance</th>\n",
       "      <th>Bert Score</th>\n",
       "      <th>Win Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.982735</td>\n",
       "      <td>0.435085</td>\n",
       "      <td>0.134427</td>\n",
       "      <td>53.874396</td>\n",
       "      <td>0.349207</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.720618</td>\n",
       "      <td>0.484448</td>\n",
       "      <td>0.174453</td>\n",
       "      <td>49.256039</td>\n",
       "      <td>0.421224</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.676389</td>\n",
       "      <td>0.494940</td>\n",
       "      <td>0.187287</td>\n",
       "      <td>48.594203</td>\n",
       "      <td>0.432041</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.816700</td>\n",
       "      <td>1.669335</td>\n",
       "      <td>0.494658</td>\n",
       "      <td>0.192939</td>\n",
       "      <td>49.241546</td>\n",
       "      <td>0.430160</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.816700</td>\n",
       "      <td>1.670051</td>\n",
       "      <td>0.489776</td>\n",
       "      <td>0.195260</td>\n",
       "      <td>50.149758</td>\n",
       "      <td>0.430211</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.816700</td>\n",
       "      <td>1.680781</td>\n",
       "      <td>0.490478</td>\n",
       "      <td>0.194314</td>\n",
       "      <td>49.869565</td>\n",
       "      <td>0.429453</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.816700</td>\n",
       "      <td>1.702576</td>\n",
       "      <td>0.493149</td>\n",
       "      <td>0.192048</td>\n",
       "      <td>50.154589</td>\n",
       "      <td>0.432734</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>1.744738</td>\n",
       "      <td>0.487073</td>\n",
       "      <td>0.192317</td>\n",
       "      <td>50.748792</td>\n",
       "      <td>0.429132</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>1.821978</td>\n",
       "      <td>0.484805</td>\n",
       "      <td>0.192060</td>\n",
       "      <td>51.024155</td>\n",
       "      <td>0.422187</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>1.852146</td>\n",
       "      <td>0.482083</td>\n",
       "      <td>0.182873</td>\n",
       "      <td>51.975845</td>\n",
       "      <td>0.419383</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>1.932733</td>\n",
       "      <td>0.481332</td>\n",
       "      <td>0.185666</td>\n",
       "      <td>51.536232</td>\n",
       "      <td>0.417067</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.054200</td>\n",
       "      <td>1.994364</td>\n",
       "      <td>0.472032</td>\n",
       "      <td>0.171521</td>\n",
       "      <td>52.937198</td>\n",
       "      <td>0.407497</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.054200</td>\n",
       "      <td>2.121124</td>\n",
       "      <td>0.474832</td>\n",
       "      <td>0.174505</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>0.403994</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.054200</td>\n",
       "      <td>2.191565</td>\n",
       "      <td>0.471728</td>\n",
       "      <td>0.173725</td>\n",
       "      <td>52.787440</td>\n",
       "      <td>0.399621</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.054200</td>\n",
       "      <td>2.270125</td>\n",
       "      <td>0.467930</td>\n",
       "      <td>0.166807</td>\n",
       "      <td>53.845411</td>\n",
       "      <td>0.400115</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>2.355670</td>\n",
       "      <td>0.463490</td>\n",
       "      <td>0.164898</td>\n",
       "      <td>53.879227</td>\n",
       "      <td>0.396688</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>2.482552</td>\n",
       "      <td>0.458768</td>\n",
       "      <td>0.159336</td>\n",
       "      <td>53.850242</td>\n",
       "      <td>0.389018</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>2.515997</td>\n",
       "      <td>0.459322</td>\n",
       "      <td>0.168752</td>\n",
       "      <td>53.903382</td>\n",
       "      <td>0.390570</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>2.598764</td>\n",
       "      <td>0.463097</td>\n",
       "      <td>0.163270</td>\n",
       "      <td>54.106280</td>\n",
       "      <td>0.387645</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>2.581266</td>\n",
       "      <td>0.460042</td>\n",
       "      <td>0.164603</td>\n",
       "      <td>53.782609</td>\n",
       "      <td>0.390875</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>2.702158</td>\n",
       "      <td>0.452102</td>\n",
       "      <td>0.155469</td>\n",
       "      <td>54.743961</td>\n",
       "      <td>0.383201</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>2.698354</td>\n",
       "      <td>0.459214</td>\n",
       "      <td>0.161556</td>\n",
       "      <td>54.545894</td>\n",
       "      <td>0.390390</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>2.818443</td>\n",
       "      <td>0.459377</td>\n",
       "      <td>0.163324</td>\n",
       "      <td>53.874396</td>\n",
       "      <td>0.388574</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>2.811203</td>\n",
       "      <td>0.457519</td>\n",
       "      <td>0.152122</td>\n",
       "      <td>54.144928</td>\n",
       "      <td>0.391288</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>2.927118</td>\n",
       "      <td>0.456105</td>\n",
       "      <td>0.157225</td>\n",
       "      <td>54.599034</td>\n",
       "      <td>0.382580</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>2.889038</td>\n",
       "      <td>0.453448</td>\n",
       "      <td>0.154151</td>\n",
       "      <td>54.608696</td>\n",
       "      <td>0.386504</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>2.961476</td>\n",
       "      <td>0.452292</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>54.608696</td>\n",
       "      <td>0.383458</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>2.949210</td>\n",
       "      <td>0.450951</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>54.594203</td>\n",
       "      <td>0.381052</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>2.896925</td>\n",
       "      <td>0.457839</td>\n",
       "      <td>0.157831</td>\n",
       "      <td>54.178744</td>\n",
       "      <td>0.391649</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>2.932551</td>\n",
       "      <td>0.458509</td>\n",
       "      <td>0.155916</td>\n",
       "      <td>54.342995</td>\n",
       "      <td>0.390111</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>3.028250</td>\n",
       "      <td>0.455891</td>\n",
       "      <td>0.153899</td>\n",
       "      <td>54.396135</td>\n",
       "      <td>0.391572</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>3.054491</td>\n",
       "      <td>0.453591</td>\n",
       "      <td>0.153354</td>\n",
       "      <td>54.826087</td>\n",
       "      <td>0.386874</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>3.038269</td>\n",
       "      <td>0.454426</td>\n",
       "      <td>0.152431</td>\n",
       "      <td>54.434783</td>\n",
       "      <td>0.390495</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>3.040706</td>\n",
       "      <td>0.459284</td>\n",
       "      <td>0.154257</td>\n",
       "      <td>53.797101</td>\n",
       "      <td>0.388015</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>3.056149</td>\n",
       "      <td>0.457460</td>\n",
       "      <td>0.157503</td>\n",
       "      <td>54.415459</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>3.103407</td>\n",
       "      <td>0.444636</td>\n",
       "      <td>0.162756</td>\n",
       "      <td>58.053140</td>\n",
       "      <td>0.389885</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>3.136397</td>\n",
       "      <td>0.440102</td>\n",
       "      <td>0.162692</td>\n",
       "      <td>57.729469</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>3.107071</td>\n",
       "      <td>0.454279</td>\n",
       "      <td>0.156047</td>\n",
       "      <td>54.111111</td>\n",
       "      <td>0.388935</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>3.131789</td>\n",
       "      <td>0.455617</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>54.497585</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>3.080790</td>\n",
       "      <td>0.456674</td>\n",
       "      <td>0.157359</td>\n",
       "      <td>53.932367</td>\n",
       "      <td>0.393163</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>3.133226</td>\n",
       "      <td>0.456812</td>\n",
       "      <td>0.164724</td>\n",
       "      <td>53.748792</td>\n",
       "      <td>0.392870</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>3.135850</td>\n",
       "      <td>0.456417</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>54.048309</td>\n",
       "      <td>0.390103</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>3.186902</td>\n",
       "      <td>0.457343</td>\n",
       "      <td>0.156949</td>\n",
       "      <td>54.009662</td>\n",
       "      <td>0.391038</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>3.196839</td>\n",
       "      <td>0.457080</td>\n",
       "      <td>0.158987</td>\n",
       "      <td>53.864734</td>\n",
       "      <td>0.391377</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>3.223418</td>\n",
       "      <td>0.457130</td>\n",
       "      <td>0.159821</td>\n",
       "      <td>53.724638</td>\n",
       "      <td>0.389994</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>3.242137</td>\n",
       "      <td>0.457031</td>\n",
       "      <td>0.160679</td>\n",
       "      <td>53.574879</td>\n",
       "      <td>0.396876</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>3.268343</td>\n",
       "      <td>0.456689</td>\n",
       "      <td>0.158865</td>\n",
       "      <td>53.739130</td>\n",
       "      <td>0.397687</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>3.274740</td>\n",
       "      <td>0.455183</td>\n",
       "      <td>0.158295</td>\n",
       "      <td>53.990338</td>\n",
       "      <td>0.391649</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>3.277523</td>\n",
       "      <td>0.456562</td>\n",
       "      <td>0.157788</td>\n",
       "      <td>53.830918</td>\n",
       "      <td>0.392378</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\", load_in_4bit=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "    \n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=256)\n",
    "    \n",
    "    # Ensure that padding tokens are not included in the labels\n",
    "    # Convert to tensors\n",
    "    labels = torch.tensor(inputs[\"input_ids\"]).clone()\n",
    "    # Replace padding tokens with -100 so they are ignored by the loss function\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=2,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=16,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.1,  # Dropout rate for LoRA\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Financial risk analysis for: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function - FIXED\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a34411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704d7821e8cf43e9b181d626c2483ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 3:06:58, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Edit Distance</th>\n",
       "      <th>Bert Score</th>\n",
       "      <th>Win Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.076955</td>\n",
       "      <td>0.387371</td>\n",
       "      <td>0.120454</td>\n",
       "      <td>55.623188</td>\n",
       "      <td>0.300789</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.796875</td>\n",
       "      <td>0.471336</td>\n",
       "      <td>0.151778</td>\n",
       "      <td>51.318841</td>\n",
       "      <td>0.398342</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.689005</td>\n",
       "      <td>0.485840</td>\n",
       "      <td>0.185971</td>\n",
       "      <td>48.879227</td>\n",
       "      <td>0.419948</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.650057</td>\n",
       "      <td>0.494347</td>\n",
       "      <td>0.192610</td>\n",
       "      <td>48.275362</td>\n",
       "      <td>0.429897</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.639529</td>\n",
       "      <td>0.499595</td>\n",
       "      <td>0.200151</td>\n",
       "      <td>48.434783</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.636445</td>\n",
       "      <td>0.501358</td>\n",
       "      <td>0.200856</td>\n",
       "      <td>48.985507</td>\n",
       "      <td>0.443428</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.649966</td>\n",
       "      <td>0.500601</td>\n",
       "      <td>0.201657</td>\n",
       "      <td>49.106280</td>\n",
       "      <td>0.441134</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.654553</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>0.204564</td>\n",
       "      <td>48.864734</td>\n",
       "      <td>0.445346</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\", load_in_4bit=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Ensure that padding tokens are not included in the labels\n",
    "    # Convert to tensors\n",
    "    labels = torch.tensor(inputs[\"input_ids\"]).clone()\n",
    "    # Replace padding tokens with -100 so they are ignored by the loss function\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=16,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.2,  # Dropout rate for LoRA\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Provide a detailed financial risk analysis report for the following data: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral_test_1\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function - FIXED\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86050a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\danie\\anaconda5\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\danie\\anaconda5\\lib\\site-packages (0.19.1)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cudatoolkit==11.6 (from versions: none)\n",
      "ERROR: No matching distribution found for cudatoolkit==11.6\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio cudatoolkit==11.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2aa1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba7e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d60c3b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3de8d698",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (248968045.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    device = 'cuda' if torch.cuda.is_available()\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0af5b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b9899e5195495ea3a80195fd3b4390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `include_inputs_for_metrics` is deprecated and will be removed in version 5 of 🤗 Transformers. Please use `include_for_metrics` list argument instead.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 7,242,584,064\n",
      "Trainable parameters: 851,968\n",
      "Starting training with 827 examples\n",
      "\n",
      "Epoch\tTraining Loss\tValidation Loss\tRougeL\tBleu\tEdit Distance\tBert Score\tWin Rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:54: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='2550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  11/2550 00:26 < 2:05:42, 0.34 it/s, Epoch 0.19/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "CustomTrainer.log() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 269\u001b[0m\n\u001b[0;32m    266\u001b[0m trainer\u001b[38;5;241m.\u001b[39madd_callback(MetricsLogger())\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m    272\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mistral\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2246\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2247\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2248\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2249\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2250\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:2627\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m   2626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(\n\u001b[0;32m   2628\u001b[0m         tr_loss,\n\u001b[0;32m   2629\u001b[0m         grad_norm,\n\u001b[0;32m   2630\u001b[0m         model,\n\u001b[0;32m   2631\u001b[0m         trial,\n\u001b[0;32m   2632\u001b[0m         epoch,\n\u001b[0;32m   2633\u001b[0m         ignore_keys_for_eval,\n\u001b[0;32m   2634\u001b[0m         start_time,\n\u001b[0;32m   2635\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m   2636\u001b[0m     )\n\u001b[0;32m   2637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Anaconda5\\Lib\\site-packages\\transformers\\trainer.py:3092\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[0;32m   3089\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step\n\u001b[0;32m   3090\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_flos()\n\u001b[1;32m-> 3092\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(logs, start_time)\n\u001b[0;32m   3094\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n",
      "\u001b[1;31mTypeError\u001b[0m: CustomTrainer.log() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers.trainer_callback import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Custom callback to track and log training loss with evaluation metrics\n",
    "class TrainLossCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training_loss = 0.0\n",
    "        self.step_count = 0\n",
    "        \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # Track loss from training steps\n",
    "        if logs is not None and \"loss\" in logs and state.is_local_process_zero:\n",
    "            self.training_loss += logs[\"loss\"]\n",
    "            self.step_count += 1\n",
    "            \n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        # Add training loss to evaluation metrics\n",
    "        if metrics is not None and self.step_count > 0:\n",
    "            # Calculate average training loss since last evaluation\n",
    "            avg_train_loss = self.training_loss / self.step_count if self.step_count > 0 else 0\n",
    "            metrics[\"train_loss\"] = avg_train_loss\n",
    "            \n",
    "            # Reset for next evaluation interval\n",
    "            self.training_loss = 0.0\n",
    "            self.step_count = 0\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\", load_in_4bit=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "    \n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=256)\n",
    "    \n",
    "    # Ensure that padding tokens are not included in the labels\n",
    "    # Convert to tensors\n",
    "    labels = torch.tensor(inputs[\"input_ids\"]).clone()\n",
    "    # Replace padding tokens with -100 so they are ignored by the loss function\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=2,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=16,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.1,  # Dropout rate for LoRA\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Financial risk analysis for: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments with increased logging frequency\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,  # Log frequently to capture more training loss data points\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    "    # Make sure we include loss in logs\n",
    "    include_inputs_for_metrics=True,\n",
    "    metric_for_best_model=\"eval_loss\",  # Use eval loss to determine best model\n",
    "    greater_is_better=False,            # Lower loss is better\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize loss tracking callback\n",
    "train_loss_callback = TrainLossCallback()\n",
    "\n",
    "# Custom Trainer class to ensure training loss is tracked\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.train_loss_history = []\n",
    "        \n",
    "    def log(self, logs):\n",
    "        \"\"\"Override log to capture training loss\"\"\"\n",
    "        if \"loss\" in logs:\n",
    "            self.train_loss_history.append(logs[\"loss\"])\n",
    "        super().log(logs)\n",
    "    \n",
    "    def evaluate(self, *args, **kwargs):\n",
    "        \"\"\"Override evaluate to include training loss in metrics\"\"\"\n",
    "        metrics = super().evaluate(*args, **kwargs)\n",
    "        \n",
    "        # Calculate average training loss since last evaluation\n",
    "        if len(self.train_loss_history) > 0:\n",
    "            avg_train_loss = sum(self.train_loss_history) / len(self.train_loss_history)\n",
    "            metrics[\"train_loss\"] = avg_train_loss\n",
    "            self.train_loss_history = []  # Reset for next evaluation\n",
    "            \n",
    "        return metrics\n",
    "\n",
    "# Initialize Custom Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[train_loss_callback],\n",
    ")\n",
    "\n",
    "# Display training information\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"Starting training with {len(tokenized_datasets['train'])} examples\")\n",
    "\n",
    "# Print header for metrics table\n",
    "print(\"\\nEpoch\\tTraining Loss\\tValidation Loss\\tRougeL\\tBleu\\tEdit Distance\\tBert Score\\tWin Rate\")\n",
    "\n",
    "# Define custom evaluation hook to display metrics in table format\n",
    "class MetricsLogger(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            # Format for table display\n",
    "            epoch = int(state.epoch)\n",
    "            train_loss = metrics.get(\"train_loss\", \"No log\")\n",
    "            eval_loss = metrics.get(\"eval_loss\", \"No log\")\n",
    "            rougel = metrics.get(\"eval_rougeL\", \"No log\")\n",
    "            bleu = metrics.get(\"eval_bleu\", \"No log\")\n",
    "            edit_distance = metrics.get(\"eval_edit_distance\", \"No log\")\n",
    "            bert_score = metrics.get(\"eval_bert_score\", \"No log\")\n",
    "            win_rate = metrics.get(\"eval_win_rate\", \"No log\")\n",
    "            \n",
    "            print(f\"{epoch}\\t{train_loss:.6f}\\t{eval_loss:.6f}\\t{rougel:.6f}\\t{bleu:.6f}\\t{edit_distance:.6f}\\t{bert_score:.6f}\\t{win_rate:.6f}\")\n",
    "\n",
    "# Add metrics logger callback\n",
    "trainer.add_callback(MetricsLogger())\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n",
    "\n",
    "# Print final message\n",
    "print(\"\\nTraining complete. Model saved to './finetuned_mistral'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a66a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0731555a4cb04d35ba3c0ae49c17ecf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7f97c8c0684720bea2fa246a8b96ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7e51bf246d442faef428ef033e02c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf6d7d315e14888ba01bdde528497ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff88f186a5c405abb709dc352c72e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7/60 02:04 < 22:04, 0.04 it/s, Epoch 0.92/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 185\u001b[0m\n\u001b[0;32m    175\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    176\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    177\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)]\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m    188\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mistral\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2556\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2549\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2550\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2554\u001b[0m )\n\u001b[0;32m   2555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2556\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2559\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2561\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2562\u001b[0m ):\n\u001b[0;32m   2563\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2564\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:3764\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3762\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3764\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\accelerate\\accelerator.py:2465\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2464\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2466\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[0;32m   2467\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\", load_in_4bit=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Keep only the 'input' and 'output' columns\n",
    "train_dataset = dataset[\"train\"][[\"input\", \"output\"]]\n",
    "test_dataset = dataset[\"test\"][[\"input\", \"output\"]]\n",
    "\n",
    "print(train_dataset[:2])\n",
    "\n",
    "# If pad_token is not defined, use eos_token as pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract 'input' and 'output' fields\n",
    "    input_text = examples['input']\n",
    "    output_text = examples['output']\n",
    "    \n",
    "    # Tokenize 'input' and 'output' pairs\n",
    "    inputs = tokenizer(input_text, padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Labels are the 'output' texts\n",
    "    labels = tokenizer(output_text, padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Ensure padding tokens are not included in the labels\n",
    "    labels = torch.tensor(labels[\"input_ids\"]).clone()\n",
    "    labels[labels == tokenizer.pad_token_id] = -100  # Replace padding tokens with -100 so they are ignored in the loss computation\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets with the new function\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=16,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.2,  # Dropout rate for LoRA\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Provide a detailed financial risk analysis report for the following data: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = tokenized_datasets.map(add_prompt, batched=True)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral_test_1\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function - FIXED\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fae17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae8d4cf15fb40bc924ab1c43f05b712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/744 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 78\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels\n\u001b[0;32m     75\u001b[0m     }\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Tokenize datasets with the new function\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m tokenized_train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m tokenized_val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     80\u001b[0m tokenized_test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    555\u001b[0m }\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:3079\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[0;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3075\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3076\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3077\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3078\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3079\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3080\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3081\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:3525\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[0;32m   3523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3524\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 3525\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m iter_outputs(shard_iterable):\n\u001b[0;32m   3526\u001b[0m         num_examples_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(i)\n\u001b[0;32m   3527\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m update_data:\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:3475\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[1;34m(shard_iterable)\u001b[0m\n\u001b[0;32m   3473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3474\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3475\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:3398\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[1;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[0;32m   3396\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[0;32m   3397\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m-> 3398\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m, in \u001b[0;36mtokenize_function\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m     58\u001b[0m output_text \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Tokenize 'input' and 'output' pairs\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Labels are the 'output' texts\u001b[39;00m\n\u001b[0;32m     64\u001b[0m labels \u001b[38;5;241m=\u001b[39m tokenizer(output_text, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2887\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2887\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2975\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   2970\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2971\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2972\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2973\u001b[0m         )\n\u001b[0;32m   2974\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 2975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2976\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2977\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2978\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2979\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2980\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2981\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2982\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2983\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2984\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   2985\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2986\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2987\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2988\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2989\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2990\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2991\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2992\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2993\u001b[0m         split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[0;32m   2994\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2995\u001b[0m     )\n\u001b[0;32m   2996\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2997\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2998\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2999\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3017\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3018\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3168\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3152\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a list of sequences or a list of pairs of sequences.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3164\u001b[0m \u001b[38;5;124;03m        details in `encode_plus`).\u001b[39;00m\n\u001b[0;32m   3165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3167\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m-> 3168\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3169\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3170\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   3171\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3172\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3173\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3174\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3175\u001b[0m )\n\u001b[0;32m   3177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m   3178\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3179\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3196\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3197\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2789\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[1;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2787\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[0;32m   2788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 2789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2792\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2793\u001b[0m     )\n\u001b[0;32m   2795\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n\u001b[0;32m   2796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2797\u001b[0m     truncation_strategy \u001b[38;5;241m!=\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE\n\u001b[0;32m   2798\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2801\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (max_length \u001b[38;5;241m%\u001b[39m pad_to_multiple_of \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2802\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Keep only the 'input' and 'output' columns\n",
    "train_dataset = dataset[\"train\"].select_columns([\"input\", \"output\"])\n",
    "test_dataset = dataset[\"test\"].select_columns([\"input\", \"output\"])\n",
    "\n",
    "# Split the train dataset into train and validation sets (90% train, 10% validation)\n",
    "train_dataset, val_dataset = train_dataset.train_test_split(test_size=0.1, seed=42).values()\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract 'input' and 'output' fields\n",
    "    input_text = examples['input']\n",
    "    output_text = examples['output']\n",
    "    \n",
    "    # Tokenize 'input' and 'output' pairs\n",
    "    inputs = tokenizer(input_text, padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Labels are the 'output' texts\n",
    "    labels = tokenizer(output_text, padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Ensure padding tokens are not included in the labels\n",
    "    labels = np.array(labels[\"input_ids\"])\n",
    "    labels = np.where(labels == tokenizer.pad_token_id, -100, labels)\n",
    "    labels[labels == tokenizer.pad_token_id] = -100  # Replace padding tokens with -100 so they are ignored in the loss computation\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets with the new function\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use fp16 during computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=32,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=64,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.5,  # Dropout rate for LoRA\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up PEFA (Prompted Embeddings for Fine-Tuning)\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Provide a detailed financial risk analysis report for the following data: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Add prompts to dataset for PEFA\n",
    "tokenized_datasets = DatasetDict({\n",
    "    'train': tokenized_train_dataset,\n",
    "    'validation': tokenized_val_dataset,\n",
    "    'test': tokenized_test_dataset\n",
    "})\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral_test_1\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2.5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function - FIXED\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],  # Validation dataset for overfitting monitoring\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "test_results = trainer.predict(tokenized_datasets[\"test\"])\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1168b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c18781f51e0450db0a908d132a6cb92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/50 2:37:11 < 13:05:58, 0.00 it/s, Epoch 1.69/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Edit Distance</th>\n",
       "      <th>Bert Score</th>\n",
       "      <th>Win Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.105600</td>\n",
       "      <td>2.205373</td>\n",
       "      <td>0.392674</td>\n",
       "      <td>0.128662</td>\n",
       "      <td>58.180723</td>\n",
       "      <td>0.279938</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 201\u001b[0m\n\u001b[0;32m    191\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    192\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    193\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)]\n\u001b[0;32m    198\u001b[0m )\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m    204\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mistralv2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2556\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2549\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2550\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2554\u001b[0m )\n\u001b[0;32m   2555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2556\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2559\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2561\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2562\u001b[0m ):\n\u001b[0;32m   2563\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2564\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:3764\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3762\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3764\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\accelerate\\accelerator.py:2465\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2464\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2466\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[0;32m   2467\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Keep only the 'input' and 'output' columns\n",
    "train_dataset = dataset[\"train\"].select_columns([\"input\", \"output\"])\n",
    "test_dataset = dataset[\"test\"].select_columns([\"input\", \"output\"])\n",
    "\n",
    "# Split the train dataset into train and validation sets (90% train, 10% validation)\n",
    "train_dataset, val_dataset = train_dataset.train_test_split(test_size=0.1, seed=42).values()\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "# Add prompt to dataset\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Provide a detailed financial risk analysis report for the following data: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Apply the prompt function\n",
    "train_dataset = train_dataset.map(add_prompt)\n",
    "val_dataset = val_dataset.map(add_prompt)\n",
    "test_dataset = test_dataset.map(add_prompt)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Ensure that padding tokens are not included in the labels\n",
    "    # Convert to tensors\n",
    "    labels = torch.tensor(inputs[\"input_ids\"]).clone()\n",
    "    # Replace padding tokens with -100 so they are ignored by the loss function\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets with the new function\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # Enable 4-bit quantization\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=32,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=64,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.5,  # Dropout rate for LoRA\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral_test_1\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2.5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.5,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,  # Validation dataset for overfitting monitoring\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistralv2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42424c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd68e717dda4b31acfde279149a231e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 06:47, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Edit Distance</th>\n",
       "      <th>Bert Score</th>\n",
       "      <th>Win Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.099700</td>\n",
       "      <td>2.205254</td>\n",
       "      <td>0.395210</td>\n",
       "      <td>0.134229</td>\n",
       "      <td>57.578313</td>\n",
       "      <td>0.284786</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.492500</td>\n",
       "      <td>1.871149</td>\n",
       "      <td>0.492941</td>\n",
       "      <td>0.171987</td>\n",
       "      <td>51.626506</td>\n",
       "      <td>0.393222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.196600</td>\n",
       "      <td>1.729598</td>\n",
       "      <td>0.509396</td>\n",
       "      <td>0.179823</td>\n",
       "      <td>51.265060</td>\n",
       "      <td>0.415003</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.014500</td>\n",
       "      <td>1.652104</td>\n",
       "      <td>0.526933</td>\n",
       "      <td>0.191453</td>\n",
       "      <td>49.168675</td>\n",
       "      <td>0.443189</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.868000</td>\n",
       "      <td>1.612033</td>\n",
       "      <td>0.527749</td>\n",
       "      <td>0.197419</td>\n",
       "      <td>49.180723</td>\n",
       "      <td>0.452007</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.788600</td>\n",
       "      <td>1.582576</td>\n",
       "      <td>0.534011</td>\n",
       "      <td>0.207210</td>\n",
       "      <td>48.397590</td>\n",
       "      <td>0.454240</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.715300</td>\n",
       "      <td>1.569524</td>\n",
       "      <td>0.530759</td>\n",
       "      <td>0.211125</td>\n",
       "      <td>47.674699</td>\n",
       "      <td>0.454567</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.635900</td>\n",
       "      <td>1.566796</td>\n",
       "      <td>0.529569</td>\n",
       "      <td>0.203628</td>\n",
       "      <td>48.240964</td>\n",
       "      <td>0.454676</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.592800</td>\n",
       "      <td>1.567090</td>\n",
       "      <td>0.524240</td>\n",
       "      <td>0.204066</td>\n",
       "      <td>48.987952</td>\n",
       "      <td>0.449475</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.327200</td>\n",
       "      <td>1.566679</td>\n",
       "      <td>0.523864</td>\n",
       "      <td>0.204685</td>\n",
       "      <td>49.096386</td>\n",
       "      <td>0.454470</td>\n",
       "      <td>0.048193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Keep only the 'input' and 'output' columns\n",
    "train_dataset = dataset[\"train\"].select_columns([\"input\", \"output\"])\n",
    "test_dataset = dataset[\"test\"].select_columns([\"input\", \"output\"])\n",
    "\n",
    "# Split the train dataset into train and validation sets (90% train, 10% validation)\n",
    "train_dataset, val_dataset = train_dataset.train_test_split(test_size=0.1, seed=42).values()\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "# Add prompt to dataset\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Provide a detailed financial risk analysis report for the following data: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Apply the prompt function\n",
    "train_dataset = train_dataset.map(add_prompt)\n",
    "val_dataset = val_dataset.map(add_prompt)\n",
    "test_dataset = test_dataset.map(add_prompt)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Ensure that padding tokens are not included in the labels\n",
    "    # Convert to tensors\n",
    "    labels = torch.tensor(inputs[\"input_ids\"]).clone()\n",
    "    # Replace padding tokens with -100 so they are ignored by the loss function\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets with the new function\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use float16 for computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # Use nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=32,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=64,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.5,  # Dropout rate for LoRA\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral_test_1\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2.5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.5,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,  # Validation dataset for overfitting monitoring\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistralv2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275e6815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4383cb8948f44ffa866a6776faeade6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 06:50, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Edit Distance</th>\n",
       "      <th>Bert Score</th>\n",
       "      <th>Win Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.105000</td>\n",
       "      <td>2.212131</td>\n",
       "      <td>0.393692</td>\n",
       "      <td>0.130002</td>\n",
       "      <td>57.963855</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.496400</td>\n",
       "      <td>1.875306</td>\n",
       "      <td>0.492893</td>\n",
       "      <td>0.176183</td>\n",
       "      <td>51.469880</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.198900</td>\n",
       "      <td>1.732040</td>\n",
       "      <td>0.512763</td>\n",
       "      <td>0.177766</td>\n",
       "      <td>50.590361</td>\n",
       "      <td>0.417269</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.015300</td>\n",
       "      <td>1.653149</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.193288</td>\n",
       "      <td>49.192771</td>\n",
       "      <td>0.444999</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.866500</td>\n",
       "      <td>1.612559</td>\n",
       "      <td>0.526720</td>\n",
       "      <td>0.200249</td>\n",
       "      <td>48.927711</td>\n",
       "      <td>0.456103</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.786200</td>\n",
       "      <td>1.582451</td>\n",
       "      <td>0.530688</td>\n",
       "      <td>0.202311</td>\n",
       "      <td>48.481928</td>\n",
       "      <td>0.452353</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.712200</td>\n",
       "      <td>1.569502</td>\n",
       "      <td>0.529723</td>\n",
       "      <td>0.209470</td>\n",
       "      <td>47.771084</td>\n",
       "      <td>0.455001</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.633800</td>\n",
       "      <td>1.566733</td>\n",
       "      <td>0.525895</td>\n",
       "      <td>0.205484</td>\n",
       "      <td>48.301205</td>\n",
       "      <td>0.453114</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.589600</td>\n",
       "      <td>1.566168</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.208796</td>\n",
       "      <td>48.578313</td>\n",
       "      <td>0.458394</td>\n",
       "      <td>0.048193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.324300</td>\n",
       "      <td>1.565607</td>\n",
       "      <td>0.526318</td>\n",
       "      <td>0.208334</td>\n",
       "      <td>48.481928</td>\n",
       "      <td>0.459216</td>\n",
       "      <td>0.048193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\utils\\save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "import torch\n",
    "from evaluate import load\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from bert_score import score as bert_score\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model_path = \"./Mistral-7B-v0.1\"  # Adjust to your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Keep only the 'input' and 'output' columns\n",
    "train_dataset = dataset[\"train\"].select_columns([\"input\", \"output\"])\n",
    "test_dataset = dataset[\"test\"].select_columns([\"input\", \"output\"])\n",
    "\n",
    "# Split the train dataset into train and validation sets (90% train, 10% validation)\n",
    "train_dataset, val_dataset = train_dataset.train_test_split(test_size=0.1, seed=42).values()\n",
    "\n",
    "# Function to format the entire 'output' into a textual description\n",
    "def format_output(output):\n",
    "    formatted_output = \"\"\n",
    "    for item in output:\n",
    "        formatted_output += f\"Analysis: {item['analysis']}\\n\"\n",
    "        \n",
    "        if item['financial_impact']:\n",
    "            financial_impact = item['financial_impact']\n",
    "            formatted_output += f\"Financial Impact: Amount: {financial_impact.get('amount', 'N/A')} \"\n",
    "            formatted_output += f\"Recurring: {financial_impact.get('recurring', 'N/A')} \"\n",
    "            formatted_output += f\"Timeframe: {financial_impact.get('timeframe', 'N/A')}\\n\"\n",
    "        \n",
    "        if item['key_metrics']:\n",
    "            key_metrics = item['key_metrics']\n",
    "            formatted_output += f\"Key Metrics: Debt Outstanding: {key_metrics.get('debt_outstanding', 'N/A')}, \"\n",
    "            formatted_output += f\"Hedge Ratio: {key_metrics.get('hedge_ratio', 'N/A')}, \"\n",
    "            formatted_output += f\"Interest Rate: {key_metrics.get('interest_rate', 'N/A')}, \"\n",
    "            formatted_output += f\"Tax Exposure: {key_metrics.get('tax_exposure', 'N/A')}\\n\"\n",
    "        \n",
    "        formatted_output += f\"Risk Categories: {', '.join(item['risk_categories'])}\\n\"\n",
    "        formatted_output += f\"Risk Severity: {item['risk_severity']}\\n\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "# Add prompt to dataset\n",
    "def add_prompt(examples):\n",
    "    prompt = \"Provide a detailed financial risk analysis report for the following data: \"\n",
    "    examples['input_text'] = [prompt + text for text in examples['input']]\n",
    "    return examples\n",
    "\n",
    "# Apply the prompt function\n",
    "train_dataset = train_dataset.map(add_prompt)\n",
    "val_dataset = val_dataset.map(add_prompt)\n",
    "test_dataset = test_dataset.map(add_prompt)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Extract analysis from the output field and tokenize the analysis\n",
    "    analysis_list = [output_item['analysis'] for output_item in examples['output']]\n",
    "    # Tokenize the analysis\n",
    "    inputs = tokenizer(analysis_list, padding=True, truncation=True, max_length=4096)\n",
    "    \n",
    "    # Ensure that padding tokens are not included in the labels\n",
    "    # Convert to tensors\n",
    "    labels = torch.tensor(inputs[\"input_ids\"]).clone()\n",
    "    # Replace padding tokens with -100 so they are ignored by the loss function\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    # Return dictionary with input_ids, attention_mask, and labels\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Tokenize datasets with the new function\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use float16 for computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # Use nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=32,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=64,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.5,  # Dropout rate for LoRA\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Define Trainer Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral_test_1\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2.5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    # Get predictions from logits\n",
    "    predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # For generative models, predictions are often logits\n",
    "    # We need to get the argmax to convert to token IDs\n",
    "    if len(predictions.shape) > 2:  # [batch, seq_len, vocab_size]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Filter out -100 padding tokens from labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Now decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Levenshtein Distance\n",
    "    edit_distance = sum([levenshtein_distance(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "    \n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    avg_bert_score = F1.mean().item()\n",
    "    \n",
    "    # Win Rate based on BERTScore\n",
    "    win_rate = sum([1 if f1 >= 0.8 else 0 for f1 in F1]) / len(F1)\n",
    "    \n",
    "    return {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"],\n",
    "        \"edit_distance\": edit_distance,\n",
    "        \"bert_score\": avg_bert_score,\n",
    "        \"win_rate\": win_rate,\n",
    "    }\n",
    "\n",
    "# Initialize Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,  # Validation dataset for overfitting monitoring\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./finetuned_mistralv2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5d96a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset (first 5 rows):\n",
      "                                               input  \\\n",
      "0  Our operations and financial results may be af...   \n",
      "1  operations, financial condition, or results of...   \n",
      "2  A. Our 2022 Annual Report on Form 10-K and our...   \n",
      "3  \"and a higher percentage of our gross profit i...   \n",
      "4  \", we are not required to provide the same lev...   \n",
      "\n",
      "                                              output  \n",
      "0  {'analysis': 'Changes in raw material prices, ...  \n",
      "1  {'analysis': 'COVID-19 pandemic has caused sig...  \n",
      "2  {'analysis': 'Ongoing impact of COVID-19 pande...  \n",
      "3  {'analysis': 'Shift in demand towards lower-ma...  \n",
      "4  {'analysis': 'Complex regulatory landscape wit...  \n",
      "\n",
      "Test Dataset (first 5 rows):\n",
      "                                               input  \\\n",
      "0  Item 7A. Quantitative and Qualitative Disclosu...   \n",
      "1  \"of $5.0 billion in 2022, $5.2 billion in 2021...   \n",
      "2  \"A further explanation of the Company’s accoun...   \n",
      "3  Accounting Standards Adopted in 2023, 2022, an...   \n",
      "4  Item 1.01. Entry into a Material Definitive Ag...   \n",
      "\n",
      "                                              output  \n",
      "0  {'analysis': '$1.4B potential loss from 10% in...  \n",
      "1  {'analysis': '$4.3B of 2022 notes remain outst...  \n",
      "2  {'analysis': 'Low liquidity risk with $150M in...  \n",
      "3  {'analysis': 'No material financial risks iden...  \n",
      "4  {'analysis': 'Acquisition of LTI poses integra...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to pandas DataFrame and select relevant columns ('input' and 'output')\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "\n",
    "# Display the first 5 rows of each dataset\n",
    "print(\"Train Dataset (first 5 rows):\")\n",
    "print(train_df[['input', 'output']].head())\n",
    "\n",
    "print(\"\\nTest Dataset (first 5 rows):\")\n",
    "print(test_df[['input', 'output']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02489708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Train Data Instance:\n",
      "input     Our operations and financial results may be affected by changes in the price of our products and services and the prices of products and services provided by our competitors. We also may be affected by changes in the prices of raw materials, labor, and other costs of producing our products and services. In addition, we may be affected by changes in the prices of products and services provided by our suppliers. The prices of our products and services are subject to a variety of factors, including the cost of raw materials, labor, and other costs of producing our products and services, the prices of products and services provided by our competitors, and the prices of products and services provided by our suppliers. If the prices of our products and services or the prices of products and services provided by our suppliers or our competitors increase, our gross profit may be negatively affected.\\n\\nSpecifically, changes in the prices of raw materials, such as commodities, can significantly impact our cost of goods sold. We use various commodities, including metals, plastics, and energy-related products, in the production of our products. The prices of these commodities can be volatile and are subject to changes in global supply and demand, as well as other factors such as global economic conditions, changes in global trade policies, and changes in global energy prices. If the prices of these commodities increase, our cost of goods sold may increase, which could negatively affect our gross profit.\\n\\nIn addition, changes in labor costs can also impact our financial results. Labor costs are a significant component of our cost of goods sold and operating expenses. Changes in labor costs, including changes in wages, benefits, and other employment-related costs, can be driven by various factors, including changes in global economic conditions, changes in global employment rates, and changes in government regulations. If labor costs increase, our cost of goods sold and operating expenses may increase, which could negatively affect our gross profit and operating income.\\n\\nWe also may be impacted by changes in the prices of products and services provided by our suppliers. We rely on various suppliers to provide us with raw materials, components, and other products and services necessary for the production of our products and services. The prices of these products and services can be volatile and are subject to changes in global supply and demand, as well as other factors such as global economic conditions, changes in global trade policies, and changes in global energy prices. If the prices of these products and services increase, our cost of goods sold may increase, which could negatively affect our gross profit.\\n\\nOur business is subject to various risks and uncertainties, including the potential impact of inflation. We may be impacted by inflation in the cost of raw materials, labor, and other costs of producing our products and services. In addition, we may be impacted by inflation in the cost of products and services provided by our suppliers and our competitors. Inflation may also cause an increase in the cost of maintaining and expanding our operations and infrastructure. We have experienced and may continue to experience fluctuations in the cost of raw materials and labor and other costs of producing our products and services. The cost of raw materials and labor and other costs of producing our products and services is subject to various factors, including changes in global economic conditions, changes in global supply and demand for raw materials and labor and other costs of producing our products and services, and the prices of products and services provided by our suppliers and our competitors. If the cost of raw materials and labor and other costs of producing our products and services increases, our gross profit may be negatively affected.\\n\\nInflation can also impact our financial results by increasing the cost of our debt. We have a significant amount of debt outstanding, and inflation can increase the cost of borrowing by increasing interest rates. If interest rates increase, our interest expense may increase, which could negatively affect our net income.\\n\\nOur business is subject to various risks and uncertainties, including the potential impact of changes in global economic conditions. We have experienced and may continue to experience fluctuations in the global economy. The global economy is subject to various factors, including changes in global supply and demand for products and services, changes in global interest rates, changes in global employment rates, changes in global government spending, changes in global consumer spending, changes in global trade policies, changes in global political policies, changes in global energy prices, and changes in global commodity prices. The global economy may be negatively affected by changes in global interest rates, changes in global trade policies, and changes in global energy prices, among other factors.\\n\\nChanges in global economic conditions can also impact our financial results by affecting the demand for our products and services. We operate in a variety of markets, including markets that are sensitive to changes in global economic conditions. If the global economy experiences a downturn, the demand for our products and services may decrease, which could negatively affect our revenue and gross profit.\\n\\nIn addition, changes in global economic conditions can impact our financial results by affecting the value of our assets. We have a significant amount of assets, including property, plant, and equipment, and investments in joint ventures and other companies. The value of these assets can be impacted by changes in global economic conditions, including changes in interest rates, changes in global trade policies, and changes in global energy prices. If the value of our assets decreases, our net worth may decrease, which could negatively affect our financial condition.\\n\\nWe continue to monitor changes in global economic conditions and take steps to mitigate the potential impact on our business. However, we cannot predict with certainty the impact of changes in global economic conditions on our financial results.\n",
      "output                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'analysis': 'Changes in raw material prices, labor costs, and supplier prices may negatively affect gross profit.', 'critical_dates': None, 'financial_impact': None, 'key_metrics': None, 'risk_categories': ['MARKET', 'OPERATIONAL'], 'risk_severity': 'MEDIUM'}\n",
      "Name: 0, dtype: object\n",
      "\n",
      "One Test Data Instance:\n",
      "input     Item 7A. Quantitative and Qualitative Disclosures About Market Risk\\n\\nWe are exposed to market risk from changes in interest rates and foreign currency exchange rates. We manage our exposure to interest rate risk through our investment portfolio and borrowings. We use derivatives to manage our exposure to foreign currency exchange rate risk. We do not engage in speculative trading activities with derivatives. Our exposure to market risk for changes in interest rates and foreign currency exchange rates has not materially increased during the year ended December 31, 2022.\\n\\nInterest Rate Risk\\n\\nWe are exposed to interest rate risk due to our investments in marketable securities and borrowings. As of December 31, 2022, our investment portfolio consisted of approximately $2.4 billion in cash and cash equivalents, $1.4 billion in commercial paper, and $1.4 billion in marketable securities, with an average yield of 4.5%. Our marketable securities portfolio is comprised of high-quality, short-term investments, including U.S. Treasury securities, U.S. government agency securities, and corporate debt securities. As of December 31, 2022, the average duration of our marketable securities portfolio was 1.4 years, with a range of maturities from a few months to three years.\\n\\nOur borrowings consisted of approximately $3.3 billion in commercial paper and $1.4 billion in long-term debt, with an average interest rate of 2.6% as of December 31, 2022. Our commercial paper is used to finance our working capital needs, while our long-term debt is used to finance our strategic initiatives and capital expenditures. We have a well-diversified debt portfolio with a range of maturities from a few months to 10 years.\\n\\nTo quantify the potential impact of changes in interest rates on our investment portfolio and borrowings, we performed a sensitivity analysis as of December 31, 2022. A 10% increase in interest rates would result in a loss of approximately $1.4 million for our investments in marketable securities and a gain of approximately $5.6 million for our borrowings, with an average duration of 1.4 years. A 10% decrease in interest rates would result in a gain of approximately $1.4 million for our investments in marketable securities and a loss of approximately $5.6 million for our borrowings, with an average duration of 1.4 years. These estimates are based on the assumption that the interest rate changes are instantaneous and that the interest rates remain constant over the duration of the investments and borrowings.\\n\\nForeign Currency Exchange Rate Risk\\n\\nWe are exposed to foreign currency exchange rate risk due to our sales and purchases of products and services in foreign currencies. We also have investments in and borrowings denominated in foreign currencies. We use derivatives to manage our exposure to foreign currency exchange rate risk. Our derivatives are primarily in the form of forward contracts and option contracts, which are used to hedge our foreign currency exposures. As of December 31, 2022, our foreign currency exposure consisted of approximately $1.4 billion in cash and cash equivalents, $1.1 billion in commercial paper, and $1.1 billion in long-term debt, with an average foreign currency exchange rate of 1.00.\\n\\nA 10% change in the value of the U.S. dollar relative to the foreign currencies in which we operate would result in a gain or loss of approximately $1.4 billion, $1.1 billion, and $1.1 billion, respectively, for our cash and cash equivalents, commercial paper, and long-term debt. These estimates are based on the assumption that the foreign currency exchange rate changes are instantaneous and that the exchange rates remain constant over the duration of the investments and borrowings.\\n\\nTo further mitigate our foreign currency exchange rate risk, we have implemented a hedging program that uses derivatives to hedge a portion of our foreign currency exposures. As of December 31, 2022, we had outstanding derivatives with a notional value of approximately $1.2 billion, which were used to hedge our foreign currency exposures. These derivatives are primarily in the form of forward contracts and option contracts, which are used to hedge our foreign currency exposures.\\n\\nIn addition to our hedging program, we also manage our foreign currency exchange rate risk through our operating activities. We have a diversified revenue base, with sales in multiple countries and regions, which helps to reduce our exposure to any one particular currency. We also have a significant portion of our costs denominated in the same currency as our revenues, which helps to further reduce our exposure to foreign currency exchange rate risk.\\n\\nOverall, we believe that our exposure to market risk from changes in interest rates and foreign currency exchange rates is manageable, and we have implemented various strategies to mitigate these risks. We will continue to monitor our exposure to market risk and adjust our strategies as necessary to ensure that our financial performance is not materially impacted by changes in interest rates and foreign currency exchange rates.\\n\\nAs part of our ongoing risk management process, we regularly review our investment portfolio and borrowings to ensure that they remain aligned with our risk management objectives. We also regularly review our hedging program to ensure that it remains effective in managing our foreign currency exchange rate risk. We believe that our risk management strategies have been effective in managing our exposure to market risk, and we will continue to monitor and adjust these strategies as necessary to ensure that our financial performance is not materially impacted by changes in interest rates and foreign currency exchange rates.\\n\\nIn conclusion, we are exposed to market risk from changes in interest rates and foreign currency exchange rates, but we have implemented various strategies to mitigate these risks. We believe that our exposure to market risk is manageable, and we will continue to monitor and adjust our risk management strategies as necessary to ensure that our financial performance is not materially impacted by changes in interest rates and foreign currency exchange rates.\n",
      "output                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        {'analysis': '$1.4B potential loss from 10% interest rate increase; $4.7B debt outstanding with 2.6% average interest rate', 'critical_dates': None, 'financial_impact': {'amount': 1400.0, 'recurring': False, 'timeframe': '2022'}, 'key_metrics': {'debt_outstanding': 4700.0, 'hedge_ratio': None, 'interest_rate': 2.6, 'tax_exposure': None}, 'risk_categories': ['INTEREST_RATE', 'MARKET'], 'risk_severity': 'HIGH'}\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas options to display full content\n",
    "pd.set_option('display.max_colwidth', None)  # No truncation for column content\n",
    "\n",
    "# Convert to pandas DataFrame and select relevant columns ('input' and 'output')\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "\n",
    "# Get one data instance from the train dataset\n",
    "one_train_instance = train_df[['input', 'output']].iloc[0]\n",
    "print(\"One Train Data Instance:\")\n",
    "print(one_train_instance)\n",
    "\n",
    "# Get one data instance from the test dataset\n",
    "one_test_instance = test_df[['input', 'output']].iloc[0]\n",
    "print(\"\\nOne Test Data Instance:\")\n",
    "print(one_test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "val_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Load local Mistral tokenizer and model\n",
    "model_path = \"./Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Mistral uses eos as pad\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use float16 for computation\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for better performance\n",
    "    bnb_4bit_quant_type=\"nf4\"  # Use nf4 quantization type\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,  # Fix: use quantization_config instead of config\n",
    "    torch_dtype=torch.float16  # Use mixed precision for faster computation\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=32,  # Rank of the low-rank adaptation matrices\n",
    "    lora_alpha=64,  # Scaling factor for the low-rank matrices\n",
    "    lora_dropout=0.5,  # Dropout rate for LoRA\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "# Prompt formatting: simulate system + user + assistant style\n",
    "SYSTEM_MESSAGE = (\n",
    "    \"You are an expert financial risk analyst. Analyze the provided text for financial risks, \"\n",
    "    \"and output a structured assessment in JSON format including risk detection, specific risk flags, \"\n",
    "    \"financial exposure details, and analysis notes.\"\n",
    ")\n",
    "\n",
    "def format_prompt(example):\n",
    "    return {\n",
    "        \"text\": f\"<s>[INST] <<SYS>>\\n{SYSTEM_MESSAGE}\\n<</SYS>>\\n\\n{example['input']} [/INST] {example['output']}</s>\"\n",
    "    }\n",
    "\n",
    "train_data = train_df[[\"input\", \"output\"]].apply(format_prompt, axis=1)\n",
    "val_data = val_df[[\"input\", \"output\"]].apply(format_prompt, axis=1)\n",
    "\n",
    "# Tokenize\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = list(map(tokenize_fn, train_data.to_list()))\n",
    "val_dataset = list(map(tokenize_fn, val_data.to_list()))\n",
    "\n",
    "# Trainer setup\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_mistral_finetuned_risk\",  # Output directory for fine-tuned model\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=2.5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",  # Optional: use tensorboard for logging\n",
    "    gradient_accumulation_steps=16,  # Adjust batch size for large models\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    prediction_loss_only=False,  # We need predictions for metric calculation\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Fine-tune\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "save_directory = \"./mistral-risk-finetuned\"\n",
    "\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loading tokenizer...\n",
      "Setting up quantization...\n",
      "Loading model with quantization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de79ad8db1c64b27ad29f7c3ae7231d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring LoRA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 7,283,675,136 || trainable%: 0.5758\n",
      "Processing training data...\n",
      "Processing validation data...\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 27:17, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.657300</td>\n",
       "      <td>0.700955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./mistral-risk-finetuned-final\n",
      "Creating merged model for easier inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\accelerate\\utils\\modeling.py:1569: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b44dfa7d924b5f8b0cb28767f76b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\accelerate\\utils\\modeling.py:1569: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "We need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules need to be offloaded: base_model.model.model.layers.13, base_model.model.model.layers.14, base_model.model.model.layers.15, base_model.model.model.layers.16, base_model.model.model.layers.17, base_model.model.model.layers.18, base_model.model.model.layers.19, base_model.model.model.layers.20, base_model.model.model.layers.21, base_model.model.model.layers.22, base_model.model.model.layers.23, base_model.model.model.layers.24, base_model.model.model.layers.25, base_model.model.model.layers.26, base_model.model.model.layers.27, base_model.model.model.layers.28, base_model.model.model.layers.29, base_model.model.model.layers.30, base_model.model.model.layers.31, base_model.model.model.norm, base_model.model.model.rotary_emb, base_model.model.lm_head.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 175\u001b[0m\n\u001b[0;32m    168\u001b[0m base_model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    169\u001b[0m     model_path,\n\u001b[0;32m    170\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Load the PEFT adapter\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPeftModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# Merge weights and save\u001b[39;00m\n\u001b[0;32m    178\u001b[0m merged_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmerge_and_unload()\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\peft_model.py:537\u001b[0m, in \u001b[0;36mPeftModel.from_pretrained\u001b[1;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     model \u001b[38;5;241m=\u001b[39m MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config\u001b[38;5;241m.\u001b[39mtask_type](\n\u001b[0;32m    530\u001b[0m         model,\n\u001b[0;32m    531\u001b[0m         config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    534\u001b[0m         low_cpu_mem_usage\u001b[38;5;241m=\u001b[39mlow_cpu_mem_usage,\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 537\u001b[0m load_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_adapter(\n\u001b[0;32m    538\u001b[0m     model_id,\n\u001b[0;32m    539\u001b[0m     adapter_name,\n\u001b[0;32m    540\u001b[0m     is_trainable\u001b[38;5;241m=\u001b[39mis_trainable,\n\u001b[0;32m    541\u001b[0m     autocast_adapter_dtype\u001b[38;5;241m=\u001b[39mautocast_adapter_dtype,\n\u001b[0;32m    542\u001b[0m     low_cpu_mem_usage\u001b[38;5;241m=\u001b[39mlow_cpu_mem_usage,\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    544\u001b[0m )\n\u001b[0;32m    546\u001b[0m \u001b[38;5;66;03m# 1. Remove VB-LoRA vector bank, since it's a shared parameter set via the VBLoRAModel\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;66;03m# 2. Remove the prompt encoder, as it does not need to be part of the checkpoint\u001b[39;00m\n\u001b[0;32m    548\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    549\u001b[0m     k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m load_result\u001b[38;5;241m.\u001b[39mmissing_keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvblora_vector_bank\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k\n\u001b[0;32m    550\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\peft_model.py:1338\u001b[0m, in \u001b[0;36mPeftModel.load_adapter\u001b[1;34m(self, model_id, adapter_name, is_trainable, torch_device, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, **kwargs)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_offload(offload_index, adapters_weights)\n\u001b[0;32m   1336\u001b[0m dispatch_model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffload_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m offload_index\n\u001b[1;32m-> 1338\u001b[0m dispatch_model(\n\u001b[0;32m   1339\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1340\u001b[0m     device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[0;32m   1341\u001b[0m     offload_dir\u001b[38;5;241m=\u001b[39moffload_dir,\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdispatch_model_kwargs,\n\u001b[0;32m   1343\u001b[0m )\n\u001b[0;32m   1345\u001b[0m hook \u001b[38;5;241m=\u001b[39m AlignDevicesHook(io_same_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name]\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\accelerate\\big_modeling.py:383\u001b[0m, in \u001b[0;36mdispatch_model\u001b[1;34m(model, device_map, main_device, state_dict, offload_dir, offload_index, offload_buffers, skip_keys, preload_module_classes, force_hooks)\u001b[0m\n\u001b[0;32m    381\u001b[0m disk_modules \u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name, device \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offload_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m offload_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(disk_modules) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to be offloaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(disk_modules)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m     )\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mlen\u001b[39m(disk_modules) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m offload_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(offload_dir) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(offload_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m    391\u001b[0m ):\n\u001b[0;32m    392\u001b[0m     disk_state_dict \u001b[38;5;241m=\u001b[39m extract_submodules_state_dict(model\u001b[38;5;241m.\u001b[39mstate_dict(), disk_modules)\n",
      "\u001b[1;31mValueError\u001b[0m: We need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules need to be offloaded: base_model.model.model.layers.13, base_model.model.model.layers.14, base_model.model.model.layers.15, base_model.model.model.layers.16, base_model.model.model.layers.17, base_model.model.model.layers.18, base_model.model.model.layers.19, base_model.model.model.layers.20, base_model.model.model.layers.21, base_model.model.model.layers.22, base_model.model.model.layers.23, base_model.model.model.layers.24, base_model.model.model.layers.25, base_model.model.model.layers.26, base_model.model.model.layers.27, base_model.model.model.layers.28, base_model.model.model.layers.29, base_model.model.model.layers.30, base_model.model.model.layers.31, base_model.model.model.norm, base_model.model.model.rotary_emb, base_model.model.lm_head."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"gretelai/gretel-financial-risk-analysis-v1\")\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "val_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Load local Mistral tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "model_path = \"./Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Mistral uses eos as pad\n",
    "\n",
    "# Quantization configuration\n",
    "print(\"Setting up quantization...\")\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Load model weights in 2-bit precision (instead of 4-bit)\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Compute in float16 for better speed and memory usage\n",
    "    bnb_4bit_use_double_quant=True,  # Double quantization for improved model efficiency\n",
    "    bnb_4bit_quant_type=\"nf4\"  # Using nf4 type for improved performance (could be adjusted for 2-bit)\n",
    ")\n",
    "\n",
    "# Load the base model with quantization\n",
    "print(\"Loading model with quantization...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "print(\"Configuring LoRA...\")\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=16,  # Reduced rank for better stability\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.5,  # Reduced dropout for better stability\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # Removed lm_head as it can cause issues with Mistral architecture\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # Print which parameters will be trained\n",
    "\n",
    "# Prompt formatting: simulate system + user + assistant style\n",
    "SYSTEM_MESSAGE = (\n",
    "    \"You are an expert financial risk analyst. Analyze the provided text for financial risks, \"\n",
    "    \"and output a structured assessment in JSON format including risk detection, specific risk flags, \"\n",
    "    \"financial exposure details, and analysis notes.\"\n",
    ")\n",
    "\n",
    "# Create proper tokenized datasets\n",
    "def preprocess_function(examples):\n",
    "    formatted_prompts = []\n",
    "    for i in range(len(examples[\"input\"])):\n",
    "        prompt = f\"<s>[INST] <<SYS>>\\n{SYSTEM_MESSAGE}\\n<</SYS>>\\n\\n{examples['input'][i]} [/INST] {examples['output'][i]}</s>\"\n",
    "        formatted_prompts.append(prompt)\n",
    "    \n",
    "    # Tokenize all prompts at once for efficiency\n",
    "    tokenized = tokenizer(\n",
    "        formatted_prompts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,  # Increased to handle longer context\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Convert to proper format for Trainer\n",
    "    result = {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": tokenized[\"input_ids\"].clone()\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Processing training data...\")\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "print(\"Processing validation data...\")\n",
    "val_dataset = dataset[\"test\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    remove_columns=dataset[\"test\"].column_names\n",
    ")\n",
    "\n",
    "# Set up training arguments with appropriate values for the task\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mistral_risk_finetuned\",\n",
    "    eval_strategy=\"epochs\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"epochs\",\n",
    "    save_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,  # Reduced to prevent OOM errors\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=6,  # Reduced to prevent overfitting\n",
    "    weight_decay=0.5,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,  # Only keep the 3 best checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_accumulation_steps=16,  # Effectively increases batch size\n",
    "    fp16=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# DataCollator for causal language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Not using masked language modeling\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Fine-tune\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "save_directory = \"./mistral-risk-finetuned-final\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the model adapter weights (LoRA)\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")\n",
    "\n",
    "# Merge adapter weights with base model for inference (optional)\n",
    "print(\"Creating merged model for easier inference...\")\n",
    "merged_model_path = \"./mistral-risk-merged\"\n",
    "os.makedirs(merged_model_path, exist_ok=True)\n",
    "\n",
    "# # Load the base model again\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_path,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16\n",
    "# )\n",
    "\n",
    "# # Load the PEFT adapter\n",
    "# model = PeftModel.from_pretrained(base_model, save_directory)\n",
    "\n",
    "# # Merge weights and save\n",
    "# merged_model = model.merge_and_unload()\n",
    "# merged_model.save_pretrained(merged_model_path)\n",
    "# tokenizer.save_pretrained(merged_model_path)\n",
    "# print(f\"Merged model saved to {merged_model_path}\")\n",
    "\n",
    "# # Example inference code\n",
    "# print(\"Testing the model with an example...\")\n",
    "# example_text = \"\"\"\n",
    "#     The Company has entered into a five-year contract to purchase raw materials\n",
    "#     from a single supplier in a volatile market. The contract requires minimum\n",
    "#     purchases of $10M annually with no cancellation clause. Recent market analysis\n",
    "#     suggests potential price fluctuations of up to 40% in the next year.\n",
    "#     \"\"\"\n",
    "\n",
    "# prompt = f\"<s>[INST] <<SYS>>\\n{SYSTEM_MESSAGE}\\n<</SYS>>\\n\\n{example_text} [/INST]\"\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = merged_model.generate(\n",
    "#         input_ids=inputs[\"input_ids\"],\n",
    "#         attention_mask=inputs[\"attention_mask\"],\n",
    "#         max_new_tokens=512,\n",
    "#         temperature=0.7,\n",
    "#         top_p=0.9,\n",
    "#         do_sample=True\n",
    "#     )\n",
    "\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "# print(\"Generated response:\")\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa9815d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading dataset: gretelai/gretel-financial-risk-analysis-v1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     37\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m }\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sample_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 42\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Dataset loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training samples, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m validation samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m💾 Sample data saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sample_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define paths and constants\n",
    "MODEL_PATH = \"./Mistral-7B-v0.1\"\n",
    "DATASET_NAME = \"gretelai/gretel-financial-risk-analysis-v1\"\n",
    "OUTPUT_DIR = f\"./mistral-risk-finetuned-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "MERGED_MODEL_PATH = f\"{OUTPUT_DIR}-merged\"\n",
    "CHECKPOINT_FILE = f\"{OUTPUT_DIR}/checkpoint.json\"\n",
    "LOG_DIR = f\"{OUTPUT_DIR}/logs\"\n",
    "\n",
    "# Ensure directories exist\n",
    "for directory in [OUTPUT_DIR, MERGED_MODEL_PATH, LOG_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# System message for financial risk analysis\n",
    "SYSTEM_MESSAGE = \"\"\"You are an expert financial risk analyst. Analyze the provided text for financial risks,\n",
    "and output a structured assessment in JSON format including risk detection, specific risk flags,\n",
    "financial exposure details, and analysis notes.\"\"\"\n",
    "\n",
    "print(f\"🔄 Loading dataset: {DATASET_NAME}\")\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "val_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Save sample data for reference\n",
    "sample_data = {\n",
    "    \"train_samples\": train_df.head(5).to_dict('records'),\n",
    "    \"val_samples\": val_df.head(5).to_dict('records')\n",
    "}\n",
    "with open(f\"{OUTPUT_DIR}/sample_data.json\", \"w\") as f:\n",
    "    json.dump(sample_data, f, indent=2)\n",
    "\n",
    "print(f\"📊 Dataset loaded: {len(train_df)} training samples, {len(val_df)} validation samples\")\n",
    "print(f\"💾 Sample data saved to {OUTPUT_DIR}/sample_data.json\")\n",
    "\n",
    "# Check and display some data statistics\n",
    "print(\"\\n📈 Data Statistics:\")\n",
    "print(f\"Average input length: {train_df['input'].str.len().mean():.1f} chars\")\n",
    "print(f\"Average output length: {train_df['output'].str.len().mean():.1f} chars\")\n",
    "print(f\"Max input length: {train_df['input'].str.len().max()} chars\")\n",
    "print(f\"Max output length: {train_df['output'].str.len().max()} chars\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(f\"\\n🔤 Loading tokenizer from {MODEL_PATH}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Setup quantization configuration\n",
    "print(\"🧮 Setting up quantization...\")\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load the base model with quantization\n",
    "print(\"🤖 Loading model with quantization...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "print(\"🛠️ Configuring LoRA...\")\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=32,  # Rank\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\", \n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "trainable_params, all_params = model.get_nb_trainable_parameters()\n",
    "print(f\"🧠 Trainable parameters: {trainable_params:,} ({trainable_params/all_params:.2%} of {all_params:,} total)\")\n",
    "\n",
    "# Save the LoRA config for future reference\n",
    "with open(f\"{OUTPUT_DIR}/lora_config.json\", \"w\") as f:\n",
    "    config_dict = {k: v for k, v in lora_config.__dict__.items() if not k.startswith('_')}\n",
    "    json.dump(config_dict, f, indent=2, default=str)\n",
    "\n",
    "# Format and preprocess data\n",
    "def format_prompt(row):\n",
    "    return f\"<s>[INST] <<SYS>>\\n{SYSTEM_MESSAGE}\\n<</SYS>>\\n\\n{row['input']} [/INST] {row['output']}</s>\"\n",
    "\n",
    "# Test a sample formatted prompt\n",
    "sample_prompt = format_prompt(train_df.iloc[0])\n",
    "print(f\"\\n📝 Sample formatted prompt:\\n{sample_prompt[:500]}...\\n\")\n",
    "\n",
    "# Process datasets with proper batching\n",
    "def preprocess_function(examples):\n",
    "    # Format all examples\n",
    "    formatted_prompts = [format_prompt({\"input\": inp, \"output\": out}) \n",
    "                         for inp, out in zip(examples[\"input\"], examples[\"output\"])]\n",
    "    \n",
    "    # Tokenize all prompts\n",
    "    tokenized = tokenizer(\n",
    "        formatted_prompts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=2048,  # Adjust based on available memory and data length\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Set up labels for causal LM (same as input_ids)\n",
    "    result = {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": tokenized[\"input_ids\"].clone()\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"🔄 Processing training data...\")\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Processing train dataset\"\n",
    ")\n",
    "\n",
    "print(\"🔄 Processing validation data...\")\n",
    "val_dataset = dataset[\"test\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    "    desc=\"Processing validation dataset\"\n",
    ")\n",
    "\n",
    "# Calculate and show token statistics\n",
    "train_lengths = [len(x) for x in train_dataset[\"input_ids\"]]\n",
    "val_lengths = [len(x) for x in val_dataset[\"input_ids\"]]\n",
    "\n",
    "print(f\"\\n📊 Token Statistics:\")\n",
    "print(f\"Average training sequence length: {np.mean(train_lengths):.1f} tokens\")\n",
    "print(f\"Average validation sequence length: {np.mean(val_lengths):.1f} tokens\")\n",
    "print(f\"Max training sequence length: {np.max(train_lengths)} tokens\")\n",
    "print(f\"Max validation sequence length: {np.max(val_lengths)} tokens\")\n",
    "\n",
    "# Save token length distribution for reference\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_lengths, bins=50, alpha=0.7, label='Training')\n",
    "plt.hist(val_lengths, bins=50, alpha=0.7, label='Validation')\n",
    "plt.title('Sequence Length Distribution')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.savefig(f\"{LOG_DIR}/token_distribution.png\")\n",
    "\n",
    "# Save checkpoint information\n",
    "checkpoint_info = {\n",
    "    \"model_path\": MODEL_PATH,\n",
    "    \"dataset\": DATASET_NAME,\n",
    "    \"train_samples\": len(train_dataset),\n",
    "    \"val_samples\": len(val_dataset),\n",
    "    \"max_seq_length\": max(np.max(train_lengths), np.max(val_lengths)),\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"lora_config\": config_dict\n",
    "}\n",
    "with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "    json.dump(checkpoint_info, f, indent=2)\n",
    "\n",
    "# Set up training arguments - optimized for stable training\n",
    "print(\"\\n⚙️ Setting up training arguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=LOG_DIR,\n",
    "    logging_steps=10,\n",
    "    report_to=\"tensorboard\",\n",
    "    fp16=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,  # Important for custom datasets\n",
    ")\n",
    "\n",
    "# Print training config for reference\n",
    "train_config = {\n",
    "    \"epochs\": training_args.num_train_epochs,\n",
    "    \"batch_size\": training_args.per_device_train_batch_size,\n",
    "    \"gradient_accumulation\": training_args.gradient_accumulation_steps,\n",
    "    \"effective_batch\": training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps,\n",
    "    \"learning_rate\": training_args.learning_rate,\n",
    "    \"warmup_ratio\": training_args.warmup_ratio,\n",
    "    \"weight_decay\": training_args.weight_decay,\n",
    "    \"scheduler\": training_args.lr_scheduler_type,\n",
    "}\n",
    "print(\"\\n🔧 Training Configuration:\")\n",
    "for k, v in train_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Set up data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Setup Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"\\n🚀 Starting training...\\n\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned adapter\n",
    "print(f\"\\n💾 Saving LoRA adapter to {OUTPUT_DIR}\")\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# Create merged model for inference\n",
    "print(f\"\\n🔄 Creating merged model for easier inference...\")\n",
    "\n",
    "# Load the base model again\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load and merge the adapter\n",
    "adapter_model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n",
    "merged_model = adapter_model.merge_and_unload()\n",
    "\n",
    "# Save the merged model\n",
    "print(f\"💾 Saving merged model to {MERGED_MODEL_PATH}\")\n",
    "merged_model.save_pretrained(MERGED_MODEL_PATH)\n",
    "tokenizer.save_pretrained(MERGED_MODEL_PATH)\n",
    "\n",
    "# Test inference with sample inputs\n",
    "test_cases = [\n",
    "    # Case 1: High financial risk scenario\n",
    "    \"\"\"\n",
    "    The Company has entered into a five-year contract to purchase raw materials\n",
    "    from a single supplier in a volatile market. The contract requires minimum\n",
    "    purchases of $10M annually with no cancellation clause. Recent market analysis\n",
    "    suggests potential price fluctuations of up to 40% in the next year.\n",
    "    \"\"\",\n",
    "\n",
    "    # Case 2: Moderate financial risk scenario\n",
    "    \"\"\"\n",
    "    Company XYZ announced a major expansion into emerging markets, requiring\n",
    "    $50M in upfront capital expenditure. The project will be funded through\n",
    "    a combination of variable-rate loans (60%) and existing cash reserves.\n",
    "    Market analysts expect interest rates to rise by 2% over the next year.\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "print(\"\\n🧪 Testing the model with sample cases...\")\n",
    "results = []\n",
    "\n",
    "for i, test_case in enumerate(test_cases):\n",
    "    print(f\"\\nTest case {i+1}:\")\n",
    "    print(f\"{test_case[:100]}...\")\n",
    "    \n",
    "    prompt = f\"<s>[INST] <<SYS>>\\n{SYSTEM_MESSAGE}\\n<</SYS>>\\n\\n{test_case} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(merged_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = merged_model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    response = generated_text.split(\"[/INST]\")[1].strip().replace(\"</s>\", \"\")\n",
    "    \n",
    "    results.append({\n",
    "        \"input\": test_case,\n",
    "        \"output\": response\n",
    "    })\n",
    "    \n",
    "    print(f\"Response: {response[:100]}...\")\n",
    "\n",
    "# Save test results\n",
    "with open(f\"{OUTPUT_DIR}/test_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Fine-tuning complete!\")\n",
    "print(f\"📁 Model outputs saved to: {OUTPUT_DIR}\")\n",
    "print(f\"📁 Merged model saved to: {MERGED_MODEL_PATH}\")\n",
    "print(f\"📊 Logs available at: {LOG_DIR}\")\n",
    "print(f\"🧪 Test results saved to: {OUTPUT_DIR}/test_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8613f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading dataset: gretelai/gretel-financial-risk-analysis-v1\n",
      "📊 Dataset loaded: 827 training samples, 207 validation samples\n",
      "💾 Sample data saved to ./mistral-risk-finetuned-20250509-154450/sample_data.json\n",
      "\n",
      "📈 Data Statistics:\n",
      "Average input length: 5753.6 chars\n",
      "Average output length: 6.0 chars\n",
      "Max input length: 12013 chars\n",
      "Max output length: 6 chars\n",
      "\n",
      "🔤 Loading tokenizer from ./Mistral-7B-v0.1\n",
      "🧮 Setting up quantization...\n",
      "🤖 Loading model with quantization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2074172828254322b32ab196a648090c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Configuring LoRA...\n",
      "🧠 Trainable parameters: 41,943,040 (0.58% of 7,283,675,136 total)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LoraRuntimeConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 150\u001b[0m\n\u001b[0;32m    147\u001b[0m             config_dict[k] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/lora_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 150\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNumpyEncoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Format and preprocess data\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_prompt\u001b[39m(row):\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m, in \u001b[0;36mNumpyEncoder.default\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(obj)\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[43mLoraRuntimeConfig\u001b[49m):\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdefault(obj)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LoraRuntimeConfig' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define paths and constants\n",
    "MODEL_PATH = \"./Mistral-7B-v0.1\"\n",
    "DATASET_NAME = \"gretelai/gretel-financial-risk-analysis-v1\"\n",
    "OUTPUT_DIR = f\"./mistral-risk-finetuned-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "MERGED_MODEL_PATH = f\"{OUTPUT_DIR}-merged\"\n",
    "CHECKPOINT_FILE = f\"{OUTPUT_DIR}/checkpoint.json\"\n",
    "LOG_DIR = f\"{OUTPUT_DIR}/logs\"\n",
    "\n",
    "# Ensure directories exist\n",
    "for directory in [OUTPUT_DIR, MERGED_MODEL_PATH, LOG_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# System message for financial risk analysis\n",
    "SYSTEM_MESSAGE = \"\"\"You are an expert financial risk analyst. Analyze the provided text for financial risks,\n",
    "and output a structured assessment in JSON format including risk detection, specific risk flags,\n",
    "financial exposure details, and analysis notes.\"\"\"\n",
    "\n",
    "print(f\"🔄 Loading dataset: {DATASET_NAME}\")\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "val_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Save sample data for reference\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer,)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating,)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, (np.bool_,)):\n",
    "            return bool(obj)\n",
    "        elif isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        elif isinstance(obj, LoraRuntimeConfig):\n",
    "            return obj.__dict__\n",
    "        return super().default(obj)\n",
    "\n",
    "# Convert DataFrame to JSON-serializable format\n",
    "def df_to_serializable(df):\n",
    "    records = []\n",
    "    for _, row in df.head(5).iterrows():\n",
    "        record = {}\n",
    "        for column, value in row.items():\n",
    "            if isinstance(value, (np.ndarray, np.integer, np.floating, np.bool_)):\n",
    "                if isinstance(value, np.ndarray):\n",
    "                    record[column] = value.tolist()\n",
    "                elif isinstance(value, np.integer):\n",
    "                    record[column] = int(value)\n",
    "                elif isinstance(value, np.floating):\n",
    "                    record[column] = float(value)\n",
    "                elif isinstance(value, np.bool_):\n",
    "                    record[column] = bool(value)\n",
    "            else:\n",
    "                record[column] = value\n",
    "        records.append(record)\n",
    "    return records\n",
    "\n",
    "sample_data = {\n",
    "    \"train_samples\": df_to_serializable(train_df),\n",
    "    \"val_samples\": df_to_serializable(val_df)\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/sample_data.json\", \"w\") as f:\n",
    "    json.dump(sample_data, f, indent=2, cls=NumpyEncoder)\n",
    "\n",
    "print(f\"📊 Dataset loaded: {len(train_df)} training samples, {len(val_df)} validation samples\")\n",
    "print(f\"💾 Sample data saved to {OUTPUT_DIR}/sample_data.json\")\n",
    "\n",
    "# Check and display some data statistics\n",
    "print(\"\\n📈 Data Statistics:\")\n",
    "print(f\"Average input length: {train_df['input'].str.len().mean():.1f} chars\")\n",
    "print(f\"Average output length: {train_df['output'].str.len().mean():.1f} chars\")\n",
    "print(f\"Max input length: {train_df['input'].str.len().max()} chars\")\n",
    "print(f\"Max output length: {train_df['output'].str.len().max()} chars\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(f\"\\n🔤 Loading tokenizer from {MODEL_PATH}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Setup quantization configuration\n",
    "print(\"🧮 Setting up quantization...\")\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load the base model with quantization\n",
    "print(\"🤖 Loading model with quantization...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Apply LoRA configuration\n",
    "print(\"🛠️ Configuring LoRA...\")\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=16,  # Rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\", \n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Integrate LoRA into the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "trainable_params, all_params = model.get_nb_trainable_parameters()\n",
    "print(f\"🧠 Trainable parameters: {trainable_params:,} ({trainable_params/all_params:.2%} of {all_params:,} total)\")\n",
    "\n",
    "# Save the LoRA config for future reference\n",
    "# Convert LoRA config to serializable format\n",
    "config_dict = {k: v for k, v in lora_config.__dict__.items() if not k.startswith('_')}\n",
    "# Convert any numpy values to Python native types\n",
    "for k, v in config_dict.items():\n",
    "    if isinstance(v, (np.integer, np.floating, np.ndarray, np.bool_)):\n",
    "        if isinstance(v, np.ndarray):\n",
    "            config_dict[k] = v.tolist()\n",
    "        else:\n",
    "            config_dict[k] = v.item()\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/lora_config.json\", \"w\") as f:\n",
    "    json.dump(config_dict, f, indent=2, cls=NumpyEncoder)\n",
    "\n",
    "# Format and preprocess data\n",
    "def format_prompt(row):\n",
    "    return f\"<s>[INST] <<SYS>>\\n{SYSTEM_MESSAGE}\\n<</SYS>>\\n\\n{row['input']} [/INST] {row['output']}</s>\"\n",
    "\n",
    "# Test a sample formatted prompt\n",
    "sample_prompt = format_prompt(train_df.iloc[0])\n",
    "print(f\"\\n📝 Sample formatted prompt:\\n{sample_prompt[:500]}...\\n\")\n",
    "\n",
    "# Process datasets with proper batching\n",
    "def preprocess_function(examples):\n",
    "    # Format all examples\n",
    "    formatted_prompts = [format_prompt({\"input\": inp, \"output\": out}) \n",
    "                         for inp, out in zip(examples[\"input\"], examples[\"output\"])]\n",
    "    \n",
    "    # Tokenize all prompts\n",
    "    tokenized = tokenizer(\n",
    "        formatted_prompts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=2048,  # Adjust based on available memory and data length\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Set up labels for causal LM (same as input_ids)\n",
    "    result = {\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": tokenized[\"input_ids\"].clone()\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"🔄 Processing training data...\")\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Processing train dataset\"\n",
    ")\n",
    "\n",
    "print(\"🔄 Processing validation data...\")\n",
    "val_dataset = dataset[\"test\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    "    desc=\"Processing validation dataset\"\n",
    ")\n",
    "\n",
    "# Calculate and show token statistics\n",
    "train_lengths = [len(x) for x in train_dataset[\"input_ids\"]]\n",
    "val_lengths = [len(x) for x in val_dataset[\"input_ids\"]]\n",
    "\n",
    "print(f\"\\n📊 Token Statistics:\")\n",
    "print(f\"Average training sequence length: {np.mean(train_lengths):.1f} tokens\")\n",
    "print(f\"Average validation sequence length: {np.mean(val_lengths):.1f} tokens\")\n",
    "print(f\"Max training sequence length: {np.max(train_lengths)} tokens\")\n",
    "print(f\"Max validation sequence length: {np.max(val_lengths)} tokens\")\n",
    "\n",
    "# Save token length distribution for reference\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_lengths, bins=50, alpha=0.7, label='Training')\n",
    "plt.hist(val_lengths, bins=50, alpha=0.7, label='Validation')\n",
    "plt.title('Sequence Length Distribution')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.savefig(f\"{LOG_DIR}/token_distribution.png\")\n",
    "\n",
    "# Save checkpoint information\n",
    "checkpoint_info = {\n",
    "    \"model_path\": MODEL_PATH,\n",
    "    \"dataset\": DATASET_NAME,\n",
    "    \"train_samples\": len(train_dataset),\n",
    "    \"val_samples\": len(val_dataset),\n",
    "    \"max_seq_length\": max(np.max(train_lengths), np.max(val_lengths)),\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"lora_config\": config_dict\n",
    "}\n",
    "with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "    json.dump(checkpoint_info, f, indent=2, cls=NumpyEncoder)\n",
    "\n",
    "# Set up training arguments - optimized for stable training\n",
    "print(\"\\n⚙️ Setting up training arguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=LOG_DIR,\n",
    "    logging_steps=10,\n",
    "    report_to=\"tensorboard\",\n",
    "    fp16=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,  # Important for custom datasets\n",
    ")\n",
    "\n",
    "# Print training config for reference\n",
    "train_config = {\n",
    "    \"epochs\": training_args.num_train_epochs,\n",
    "    \"batch_size\": training_args.per_device_train_batch_size,\n",
    "    \"gradient_accumulation\": training_args.gradient_accumulation_steps,\n",
    "    \"effective_batch\": training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps,\n",
    "    \"learning_rate\": training_args.learning_rate,\n",
    "    \"warmup_ratio\": training_args.warmup_ratio,\n",
    "    \"weight_decay\": training_args.weight_decay,\n",
    "    \"scheduler\": training_args.lr_scheduler_type,\n",
    "}\n",
    "print(\"\\n🔧 Training Configuration:\")\n",
    "for k, v in train_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Set up data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Setup Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"\\n🚀 Starting training...\\n\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned adapter\n",
    "print(f\"\\n💾 Saving LoRA adapter to {OUTPUT_DIR}\")\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# Create merged model for inference\n",
    "print(f\"\\n🔄 Creating merged model for easier inference...\")\n",
    "\n",
    "# Load the base model again\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load and merge the adapter\n",
    "adapter_model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n",
    "merged_model = adapter_model.merge_and_unload()\n",
    "\n",
    "# Save the merged model\n",
    "print(f\"💾 Saving merged model to {MERGED_MODEL_PATH}\")\n",
    "merged_model.save_pretrained(MERGED_MODEL_PATH)\n",
    "tokenizer.save_pretrained(MERGED_MODEL_PATH)\n",
    "\n",
    "# Test inference with sample inputs\n",
    "test_cases = [\n",
    "    # Case 1: High financial risk scenario\n",
    "    \"\"\"\n",
    "    The Company has entered into a five-year contract to purchase raw materials\n",
    "    from a single supplier in a volatile market. The contract requires minimum\n",
    "    purchases of $10M annually with no cancellation clause. Recent market analysis\n",
    "    suggests potential price fluctuations of up to 40% in the next year.\n",
    "    \"\"\",\n",
    "\n",
    "    # Case 2: Moderate financial risk scenario\n",
    "    \"\"\"\n",
    "    Company XYZ announced a major expansion into emerging markets, requiring\n",
    "    $50M in upfront capital expenditure. The project will be funded through\n",
    "    a combination of variable-rate loans (60%) and existing cash reserves.\n",
    "    Market analysts expect interest rates to rise by 2% over the next year.\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "print(\"\\n🧪 Testing the model with sample cases...\")\n",
    "results = []\n",
    "\n",
    "for i, test_case in enumerate(test_cases):\n",
    "    print(f\"\\nTest case {i+1}:\")\n",
    "    print(f\"{test_case[:100]}...\")\n",
    "    \n",
    "    prompt = f\"<s>[INST] <<SYS>>\\n{SYSTEM_MESSAGE}\\n<</SYS>>\\n\\n{test_case} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(merged_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = merged_model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    response = generated_text.split(\"[/INST]\")[1].strip().replace(\"</s>\", \"\")\n",
    "    \n",
    "    results.append({\n",
    "        \"input\": test_case,\n",
    "        \"output\": response\n",
    "    })\n",
    "    \n",
    "    print(f\"Response: {response[:100]}...\")\n",
    "\n",
    "# Save test results\n",
    "with open(f\"{OUTPUT_DIR}/test_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2, cls=NumpyEncoder)\n",
    "\n",
    "print(f\"\\n✅ Fine-tuning complete!\")\n",
    "print(f\"📁 Model outputs saved to: {OUTPUT_DIR}\")\n",
    "print(f\"📁 Merged model saved to: {MERGED_MODEL_PATH}\")\n",
    "print(f\"📊 Logs available at: {LOG_DIR}\")\n",
    "print(f\"🧪 Test results saved to: {OUTPUT_DIR}/test_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
